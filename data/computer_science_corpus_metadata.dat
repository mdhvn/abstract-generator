(dp0
Vhttp://arxiv.org/abs/0906.2824v1
p1
(dp2
S'category'
p3
Vcs.AI
p4
sS'title'
p5
VWhat Does Artificial Life Tell Us About Death?
p6
sS'summary'
p7
VShort philosophical essay
p8
ssVhttp://arxiv.org/abs/cs/0508065v1
p9
(dp10
S'category'
p11
Vcs.DL
p12
sS'title'
p13
VRepresenting Digital Assets using MPEG-21 Digital Item Declaration
p14
sS'summary'
p15
VVarious XML-based approaches aimed at representing compound digital assets\u000ahave emerged over the last several years. Approaches that are of specific\u000arelevance to the digital library community include the Metadata Encoding and\u000aTransmission Standard (METS), the IMS Content Packaging XML Binding, and the\u000aXML Formatted Data Units (XFDU) developed by CCSDS Panel 2. The MPEG-21 Digital\u000aItem Declaration (MPEG-21 DID) is another standard specifying the\u000arepresentation of digital assets in XML that, so far, has received little\u000aattention in the digital library community. This article gives a brief insight\u000ainto the MPEG-21 standardization effort, highlights the major characteristics\u000aof the MPEG-21 DID Abstract Model, and describes the MPEG-21 Digital Item\u000aDeclaration Language (MPEG-21 DIDL), an XML syntax for the representation of\u000adigital assets based on the MPEG-21 DID Abstract Model. Also, it briefly\u000ademonstrates the potential relevance of MPEG-21 DID to the digital library\u000acommunity by describing its use in the aDORe repository environment at the\u000aResearch Library of the Los Alamos National Laboratory (LANL) for the\u000arepresentation of digital assets.
p16
ssVhttp://arxiv.org/abs/1312.6948v1
p17
(dp18
S'category'
p19
Vcs.CL
p20
sS'title'
p21
VDescription Logics based Formalization of Wh-Queries
p22
sS'summary'
p23
VThe problem of Natural Language Query Formalization (NLQF) is to translate a\u000agiven user query in natural language (NL) into a formal language so that the\u000asemantic interpretation has equivalence with the NL interpretation.\u000aFormalization of NL queries enables logic based reasoning during information\u000aretrieval, database query, question-answering, etc. Formalization also helps in\u000aWeb query normalization and indexing, query intent analysis, etc. In this paper\u000awe are proposing a Description Logics based formal methodology for wh-query\u000aintent (also called desire) identification and corresponding formal\u000atranslation. We evaluated the scalability of our proposed formalism using\u000aMicrosoft Encarta 98 query dataset and OWL-S TC v.4.0 dataset.
p24
ssVhttp://arxiv.org/abs/1408.3452v1
p25
(dp26
S'category'
p27
Vcs.CR
p28
sS'title'
p29
VA Note on the Bellare-Rivest Protocol for Translucent Cryptography
p30
sS'summary'
p31
VWe remark that the Bellare-Rivest protocol for translucent cryptography [J.\u000aCryptology (1999) 12: 117-139] can not truly enable the government to decrypt\u000apartial encrypted communications.
p32
ssVhttp://arxiv.org/abs/1105.1534v1
p33
(dp34
g3
Vcs.NE
p35
sg5
VTaking the redpill: Artificial Evolution in native x86 systems
p36
sg7
VIn analogon to successful artificial evolution simulations as Tierra or\u000aavida, this text presents a way to perform artificial evolution in a native x86\u000asystem. The implementation of the artificial chemistry and first results of\u000astatistical experiments are presented.
p37
ssVhttp://arxiv.org/abs/1202.6009v1
p38
(dp39
S'category'
p40
Vcs.AI
p41
sS'summary'
p42
VThe purpose of statistical disclosure control (SDC) of microdata, a.k.a. data\u000aanonymization or privacy-preserving data mining, is to publish data sets\u000acontaining the answers of individual respondents in such a way that the\u000arespondents corresponding to the released records cannot be re-identified and\u000athe released data are analytically useful. SDC methods are either based on\u000amasking the original data, generating synthetic versions of them or creating\u000ahybrid versions by combining original and synthetic data. The choice of SDC\u000amethods for categorical data, especially nominal data, is much smaller than the\u000achoice of methods for numerical data. We mitigate this problem by introducing a\u000anumerical mapping for hierarchical nominal data which allows computing means,\u000avariances and covariances on them.
p43
sS'title'
p44
VMarginality: a numerical mapping for enhanced treatment of nominal and\u000a  hierarchical attributes
p45
ssVhttp://arxiv.org/abs/1610.07554v1
p46
(dp47
S'category'
p48
Vmath.ST
p49
sS'title'
p50
VSome Relationships and Properties of the Hypergeometric Distribution
p51
sS'summary'
p52
VThe binomial and Poisson distributions have interesting relationships with\u000athe beta and gamma distributions, respectively, which involve their cumulative\u000adistribution functions and the use of conjugate priors in Bayesian statistics.\u000aWe briefly discuss these relationships and some properties resulting from them\u000awhich play an important role in the construction of exact nested two-sided\u000aconfidence intervals and the computation of two-tailed P-values. The purpose of\u000athis article is to show that such relationships also exist between the\u000ahypergeometric distribution and a special case of the Polya (or beta-binomial)\u000adistribution, and to derive some properties of the hypergeometric distribution\u000aresulting from these relationships.\u000a  KEY WORDS: Beta, binomial, gamma, Poisson, and Polya (or beta-binomial)\u000adistributions; Conjugate prior distribution; Cumulative distribution function;\u000aPosterior distribution.
p53
ssVhttp://arxiv.org/abs/1305.4665v4
p54
(dp55
S'category'
p56
Vcond-mat.mes-hall
p57
sS'summary'
p58
VFirst of all, we reconsider the tight - binding model of monolayer graphene,\u000ain which the variations of the hopping parameters are allowed. We demonstrate\u000athat the emergent 2D Weitzenbock geometry as well as the emergent U(1) gauge\u000afield appear. The emergent gauge field is equal to the linear combination of\u000athe components of the zweibein. Therefore, we actually deal with the gauge\u000afixed version of the emergent 2+1 D teleparallel gravity. In particular, we\u000awork out the case, when the variations of the hopping parameters are due to the\u000aelastic deformations, and relate the elastic deformations with the emergent\u000azweibein. Next, we investigate the tight - binding model with the varying\u000aintralayer hopping parameters for the multilayer graphene with the ABC\u000astacking. In this case the emergent 2D Weitzenbock geometry and the emergent\u000aU(1) gauge field appear as well, the emergent low energy effective field theory\u000ahas the anisotropic scaling.
p59
sS'title'
p60
VEmergent Horava gravity in graphene
p61
ssVhttp://arxiv.org/abs/cs/0602059v1
p62
(dp63
g11
Vcs.DL
p64
sg13
VD2D: Digital Archive to MPEG-21 DIDL
p65
sg15
VDigital Archive to MPEG-21 DIDL (D2D) analyzes the contents of the digital\u000aarchive and produces an MPEG-21 Digital Item Declaration Language (DIDL)\u000aencapsulating the analysis results. DIDL is an extensible XML-based language\u000athat aggregates resources and the metadata. We provide a brief report on\u000aseveral analysis techniques applied on the digital archive by the D2D and\u000aprovide an evaluation of its run-time performance.
p66
ssVhttp://arxiv.org/abs/1703.04075v2
p67
(dp68
S'category'
p69
Vcs.LO
p70
sS'summary'
p71
VWe propose a definition of computable manifold by introducing computability\u000aas a structure that we impose to a given topological manifold, just in the same\u000away as differentiability or piecewise linearity are defined for smooth and PL\u000amanifolds respectively. Using the framework of computable topology and Type-2\u000atheory of effectivity, we develop computable versions of all the basic concepts\u000aneeded to define manifolds, like computable atlases and (computably) compatible\u000acomputable atlases. We prove that given a computable atlas $\u005cPhi$ defined on a\u000aset $M$, we can construct a computable topological space $(M, \u005ctau_\u005cPhi,\u000a\u005cbeta_\u005cPhi, \u005cnu_\u005cPhi)$, where $\u005ctau_\u005cPhi$ is the topology on $M$ induced by\u000a$\u005cPhi$ and that the equivalence class of this computable space characterizes\u000athe computable structure determined by $\u005cPhi$. The concept of computable\u000asubmanifold is also investigated. We show that any compact computable manifold\u000awhich satisfies a computable version of the $T_2$-separation axiom, can be\u000aembedded as a computable submanifold of some euclidean space $\u005cmathbb{R}^{q}$,\u000awith a computable embedding, where $\u005cmathbb{R}^{q}$ is equipped with its usual\u000atopology and some canonical computable encoding of all open rational balls.
p72
sS'title'
p73
VComputable structures on topological manifolds
p74
ssVhttp://arxiv.org/abs/1212.1119v1
p75
(dp76
g19
Vcond-mat.stat-mech
p77
sg21
VEulerian Field-Theoretic Closure Formalisms for Fluid Turbulence
p78
sg23
VThe formalisms of Wyld [2] and Martin, Siggia, and Rose (MSR) [3] address the\u000aclosure problem of a statistical treatment of homogeneous isotropic turbulence\u000a(HIT) based on techniques primarily developed for quantum field theory. In the\u000aWyld formalism, there is a well-known double-counting problem, for which an\u000a{\u005cit ad hoc} solution was suggested by Lee [44]. We show how to implement this\u000acorrection in a more natural way from the basic equations of the formalism.\u000aThis leads to what we call the "Improved Wyld-Lee Renormalized Perturbation\u000aTheory". MSR had noted that their formalism had more vertex functions than\u000aWyld's formalism and based on this felt Wyld's formalism was incorrect. However\u000aa careful comparison of both formalisms here shows that the Wyld formalism\u000afollows a different procedure to that of the MSR formalism and so the treatment\u000aof vertex corrections appears in different ways in the two formalisms. Taking\u000athat into account, along with clarifications made to both formalisms, we find\u000athat they are equivalent and we demonstrate this up to fourth order.
p79
ssVhttp://arxiv.org/abs/1201.0143v1
p80
(dp81
S'category'
p82
Vmath.PR
p83
sS'summary'
p84
VWe construct two different Stein characterizations of discrete distributions\u000aand use these to provide a natural connection between Stein characterizations\u000afor discrete distributions and discrete information functionals.
p85
sS'title'
p86
VDiscrete Stein characterizations and discrete information distances
p87
ssVhttp://arxiv.org/abs/0901.0131v1
p88
(dp89
g69
Vcs.DC
p90
sg71
VCloud Computing has become another buzzword after Web 2.0. However, there are\u000adozens of different definitions for Cloud Computing and there seems to be no\u000aconsensus on what a Cloud is. On the other hand, Cloud Computing is not a\u000acompletely new concept; it has intricate connection to the relatively new but\u000athirteen-year established Grid Computing paradigm, and other relevant\u000atechnologies such as utility computing, cluster computing, and distributed\u000asystems in general. This paper strives to compare and contrast Cloud Computing\u000awith Grid Computing from various angles and give insights into the essential\u000acharacteristics of both.
p91
sg73
VCloud Computing and Grid Computing 360-Degree Compared
p92
ssVhttp://arxiv.org/abs/0912.1092v1
p93
(dp94
g27
Vcs.CR
p95
sg29
VModern Symmetric Cryptography methodologies and its applications
p96
sg31
VNowadays, using cryptographic systems play an effective role in security and\u000asafety technologies. One of the most applied kind of cryptography is Symmetric\u000aCryptography and its applications. New aspects of symmetric Cryptography\u000amethodologies and applications has been presented by this paper. Security-based\u000anetworks and some complex technologies such as RFID and parallel security\u000asettings has been intro-duced by using Symmetric Cryptography is the main base\u000aof discussion in this paper. Designing an unique protocol for Symmetric\u000aCryptography in security networks elements is our focus. Reviewing benefits of\u000ausing these methodologies has been pre-sented and discussed in this paper.
p97
ssVhttp://arxiv.org/abs/1111.4065v1
p98
(dp99
S'category'
p100
Vmath.NT
p101
sS'summary'
p102
VIn this paper, we present k sequences of Generalized Van der Laan Polynomials\u000aand Generalized Perrin Polynomials using Genaralized Fibonacci and Lucas\u000aPolynomials. We give some properties of these polynomials. We also obtain\u000ageneralized order-k Van der Laan Numbers, k sequences of generalized order-k\u000aVan der Laan Numbers, generalized order-k Perrin Numbers and k sequences of\u000ageneralized order-k Perrin Numbers. In addition, we examine the relationship\u000abetween them.
p103
sS'title'
p104
Vk Sequences of Generalized Van der Laan and Generalized Perrin\u000a  Polynomials
p105
ssVhttp://arxiv.org/abs/0903.2693v1
p106
(dp107
g27
Vcs.CR
p108
sg29
VA Pseudo DNA Cryptography Method
p109
sg31
VThe DNA cryptography is a new and very promising direction in cryptography\u000aresearch. DNA can be used in cryptography for storing and transmitting the\u000ainformation, as well as for computation. Although in its primitive stage, DNA\u000acryptography is shown to be very effective. Currently, several DNA computing\u000aalgorithms are proposed for quite some cryptography, cryptanalysis and\u000asteganography problems, and they are very powerful in these areas. However, the\u000ause of the DNA as a means of cryptography has high tech lab requirements and\u000acomputational limitations, as well as the labor intensive extrapolation means\u000aso far. These make the efficient use of DNA cryptography difficult in the\u000asecurity world now. Therefore, more theoretical analysis should be performed\u000abefore its real applications.\u000a  In this project, We do not intended to utilize real DNA to perform the\u000acryptography process; rather, We will introduce a new cryptography method based\u000aon central dogma of molecular biology. Since this method simulates some\u000acritical processes in central dogma, it is a pseudo DNA cryptography method.\u000aThe theoretical analysis and experiments show this method to be efficient in\u000acomputation, storage and transmission; and it is very powerful against certain\u000aattacks. Thus, this method can be of many uses in cryptography, such as an\u000aenhancement insecurity and speed to the other cryptography methods. There are\u000aalso extensions and variations to this method, which have enhanced security,\u000aeffectiveness and applicability.
p110
ssVhttp://arxiv.org/abs/gr-qc/9908034v1
p111
(dp112
g100
Vgr-qc
p113
sg102
VA sequence of generalizations of Cartan's conservation of torsion theorem is\u000agiven for n-dimensional differentiable manifolds having a general linear\u000aconnection.
p114
sg104
VA Sequence of Generalizations of Cartan's Conservation of Torsion\u000a  Theorem
p115
ssVhttp://arxiv.org/abs/math/0609831v3
p116
(dp117
g100
Vmath.AC
p118
sg102
VIn this paper we present the notions of trail (pseudo-)division, generalized\u000asubresultants and generalized subresultant algorithm.
p119
sg104
VGeneralized subresultants and generalized subresultant algorithm
p120
ssVhttp://arxiv.org/abs/1311.3896v1
p121
(dp122
g48
Vmath.PR
p123
sg50
VRates of convergence towards the Fréchet distribution
p124
sg52
VWe develop Stein's method for the Fr\u005c'echet distribution and apply it to\u000acompute rates of convergence in distribution of renormalized sample maxima to\u000athe Fr\u005c'echet distribution.
p125
ssVhttp://arxiv.org/abs/1203.4667v2
p126
(dp127
g69
Vcs.CC
p128
sg71
VThe Church-Turing thesis states that any sufficiently powerful computational\u000amodel which captures the notion of algorithm is computationally equivalent to\u000athe Turing machine. This equivalence usually holds both at a computability\u000alevel and at a computational complexity level modulo polynomial reductions.\u000aHowever, the situation is less clear in what concerns models of computation\u000ausing real numbers, and no analog of the Church-Turing thesis exists for this\u000acase. Recently it was shown that some models of computation with real numbers\u000awere equivalent from a computability perspective. In particular it was shown\u000athat Shannon's General Purpose Analog Computer (GPAC) is equivalent to\u000aComputable Analysis. However, little is known about what happens at a\u000acomputational complexity level. In this paper we shed some light on the\u000aconnections between this two models, from a computational complexity level, by\u000ashowing that, modulo polynomial reductions, computations of Turing machines can\u000abe simulated by GPACs, without the need of using more (space) resources than\u000athose used in the original Turing computation, as long as we are talking about\u000abounded computations. In other words, computations done by the GPAC are as\u000aspace-efficient as computations done in the context of Computable Analysis.
p129
sg73
VTuring machines can be efficiently simulated by the General Purpose\u000a  Analog Computer
p130
ssVhttp://arxiv.org/abs/1307.1371v1
p131
(dp132
g11
Vcs.DM
p133
sg13
VOn digital simply connected spaces and manifolds: a digital simply\u000a  connected 3-manifold is the digital 3-sphere
p134
sg15
VIn the framework of digital topology, we study structural and topological\u000aproperties of digital n-dimensional manifolds. We introduce the notion of\u000asimple connectedness of a digital space and prove that if M and N are homotopy\u000aequivalent digital spaces and M is simply connected, then so is N. We show that\u000aa simply connected digital 2-manifold is the digital 2-sphere and a simply\u000aconnected digital 3-manifold is the digital 3-sphere. This property can be\u000aconsidered as a digital form of the Poincar\u005c'e conjecture for continuous\u000athree-manifolds.
p135
ssVhttp://arxiv.org/abs/1311.0716v1
p136
(dp137
g3
Vcs.AI
p138
sg5
VArtificial Intelligence in Humans
p139
sg7
VIn this paper, I put forward that in many instances, thinking mechanisms are\u000aequivalent to artificial intelligence modules programmed into the human mind.
p140
ssVhttp://arxiv.org/abs/1107.1126v2
p141
(dp142
g82
Vmath-ph
p143
sg84
VIt is suggest that a new fractal model for the Yang-Fourier transforms of\u000adiscrete approximation based on local fractional calculus and the Discrete\u000aYang-Fourier transforms are investigated in detail.
p144
sg86
VA New Viewpoint to the Discrete Approximation: Discrete Yang-Fourier\u000a  Transforms of Discrete-time Fractal Signal
p145
ssVhttp://arxiv.org/abs/1312.0730v1
p146
(dp147
g82
Vmath.DG
p148
sg84
VWe introduce the discrete Einstein metrics as critical points of discrete\u000aenergy on triangulated 3-manifolds, and study them by discrete curvature flow\u000aof second (fourth) order. We also study the convergence of the discrete\u000acurvature flow. Discrete curvature flow of second order is an analogue of\u000asmooth Ricci flow.
p149
sg86
V3-Dimensional Discrete curvature flows and discrete Einstein metric
p150
ssVhttp://arxiv.org/abs/gr-qc/0412031v1
p151
(dp152
g19
Vgr-qc
p153
sg21
VDynamics of a Spherical Null Shell within the Distributional Formalism
p154
sg23
VDynamics of a null thin shell immersed in a generic spherically symmetric\u000aspacetime is obtained within the distributional formalism. It has been shown\u000athat the distributional formalism leads to the same result as in the\u000aconventional formalism.
p155
ssVhttp://arxiv.org/abs/1412.0143v1
p156
(dp157
g11
Vcs.CG
p158
sg13
VTopology preserving representations of compact 2D manifolds by digital\u000a  2-surfaces. Compressed digital models and digital weights of compact 2D\u000a  manifolds. Classification of closed surfaces by digital tools
p159
sg15
VUsing digital topology approach, we construct digital models of closed\u000asurfaces as the intersection graphs of LCL covers of the surfaces. It is proved\u000athat digital models of closed surfaces are digital 2-dimensional surfaces\u000apreserving the geometry and topology of their continuous counterparts. In the\u000aframework of the proposed models, we show that for any closed surface there\u000aexists a compressed model of this surface with the minimal number of points.\u000a  Key words: Closed Surface; Digital space; Cover; Graph; Digital model;\u000aMedical imaging;
p160
ssVhttp://arxiv.org/abs/1207.3992v1
p161
(dp162
g56
Vastro-ph.SR
p163
sg58
VThe interaction between emerging active regions and the pre-existing coronal\u000amagnetic field is important to understand better the mechanisms of storage and\u000arelease of magnetic energy from the convection zone to the high corona. We are\u000aaiming at describing the first steps of the emergence of an active region\u000awithin a pre-existing quiet-Sun corona in terms of the thermal and magnetic\u000astructure. We use unprecedented spatial, temporal and spectral coverage from\u000athe Atmospheric Imager Assembly (AIA) and from the Helioseismic and Magnetic\u000aImager (HMI) on board the Solar Dynamics Observatory (SDO). Starting on 30 May\u000a2010 at 17:00 UT and for 8 hours, we follow the emergence of the active region\u000aAR11076 within a quiet-Sun region. Using several SDO/AIA filters covering\u000atemperatures from 50000K to 10 MK, we show that the emerging process is\u000acharacterised by a thermal shield at the interface between the emerging flux\u000aand pre-existing quiet-Sun corona. The active region 11076 can be considered as\u000aa peculiar example of emerging active region as (i) the polarities emerge in a\u000aphotospheric quiet-Sun region near a supergranular-like distribution, (ii) the\u000apolarities forming the bipolar emerging structure do not rotate with respect to\u000aeach other indicating a small amount of twist in the emerging flux bundle.\u000aThere is a thermal shield formed at the interface between the emerging active\u000aregion and the pre-existing quiet-Sun region. The thermal shielding structure\u000adeduced from all SDO/AIA channels exhibits a strong asymmetry between the two\u000apolarities of the active region suggesting that the heating mechanism for one\u000apolarity is more likely to be magnetic reconnection, whilst it is due to\u000aincreasing magnetic pressure for the opposite polarity.
p164
sg60
VThermal Shielding of an Emerging Active Region
p165
ssVhttp://arxiv.org/abs/1311.6900v1
p166
(dp167
g82
Vmath.NA
p168
sg84
VThis paper discusses the computation of derivatives for optimization problems\u000agoverned by linear hyperbolic systems of partial differential equations (PDEs)\u000athat are discretized by the discontinuous Galerkin (dG) method. An efficient\u000aand accurate computation of these derivatives is important, for instance, in\u000ainverse problems and optimal control problems. This computation is usually\u000abased on an adjoint PDE system, and the question addressed in this paper is how\u000athe discretization of this adjoint system should relate to the dG\u000adiscretization of the hyperbolic state equation. Adjoint-based derivatives can\u000aeither be computed before or after discretization; these two options are often\u000areferred to as the optimize-then-discretize and discretize-then-optimize\u000aapproaches. We discuss the relation between these two options for dG\u000adiscretizations in space and Runge-Kutta time integration. Discretely exact\u000adiscretizations for several hyperbolic optimization problems are derived,\u000aincluding the advection equation, Maxwell's equations and the coupled\u000aelastic-acoustic wave equation. We find that the discrete adjoint equation\u000ainherits a natural dG discretization from the discretization of the state\u000aequation and that the expressions for the discretely exact gradient often have\u000ato take into account contributions from element faces. For the coupled\u000aelastic-acoustic wave equation, the correctness and accuracy of our derivative\u000aexpressions are illustrated by comparisons with finite difference gradients.\u000aThe results show that a straightforward discretization of the continuous\u000agradient differs from the discretely exact gradient, and thus is not consistent\u000awith the discretized objective. This inconsistency may cause difficulties in\u000athe convergence of gradient based algorithms for solving optimization problems.
p169
sg86
VDiscretely exact derivatives for hyperbolic PDE-constrained optimization\u000a  problems discretized by the discontinuous Galerkin method
p170
ssVhttp://arxiv.org/abs/0804.1133v1
p171
(dp172
g69
Vcs.NE
p173
sg71
VThis effort examines the intersection of the emerging field of quantum\u000acomputing and the more established field of evolutionary computation. The goal\u000ais to understand what benefits quantum computing might offer to computational\u000aintelligence and how computational intelligence paradigms might be implemented\u000aas quantum programs to be run on a future quantum computer. We critically\u000aexamine proposed algorithms and methods for implementing computational\u000aintelligence paradigms, primarily focused on heuristic optimization methods\u000aincluding and related to evolutionary computation, with particular regard for\u000atheir potential for eventual implementation on quantum computing hardware.
p174
sg73
VProspective Algorithms for Quantum Evolutionary Computation
p175
ssVhttp://arxiv.org/abs/1111.4450v1
p176
(dp177
g27
Vcs.CR
p178
sg29
VFull Restoration of Visual Encrypted Color Images
p179
sg31
VWhile strictly black and white images have been the basis for visual\u000acryptography, there has been a lack of an easily implemented format for colour\u000aimages. This paper establishes a simple, yet secure way of implementing visual\u000acryptography with colour, assuming a binary data representation.
p180
ssVhttp://arxiv.org/abs/1204.3677v1
p181
(dp182
g40
Vcs.DB
p183
sg42
VData Cleaning is a long standing problem, which is growing in importance with\u000athe mass of uncurated web data. State of the art approaches for handling\u000ainconsistent data are systems that learn and use conditional functional\u000adependencies (CFDs) to rectify data. These methods learn data\u000apatterns--CFDs--from a clean sample of the data and use them to rectify the\u000adirty/inconsistent data. While getting a clean training sample is feasible in\u000aenterprise data scenarios, it is infeasible in web databases where there is no\u000aseparate curated data. CFD based methods are unfortunately particularly\u000asensitive to noise; we will empirically demonstrate that the number of CFDs\u000alearned falls quite drastically with even a small amount of noise. In order to\u000aovercome this limitation, we propose a fully probabilistic framework for\u000acleaning data. Our approach involves learning both the generative and error\u000a(corruption) models of the data and using them to clean the data. For\u000agenerative models, we learn Bayes networks from the data. For error models, we\u000aconsider a maximum entropy framework for combing multiple error processes. The\u000agenerative and error models are learned directly from the noisy data. We\u000apresent the details of the framework and demonstrate its effectiveness in\u000arectifying web data.
p184
sg44
VBayesian Data Cleaning for Web Data
p185
ssVhttp://arxiv.org/abs/0708.1986v1
p186
(dp187
g69
Vquant-ph
p188
sg71
VQuantum computer possesses quantum parallelism and offers great computing\u000apower over classical computer \u005ccite{er1,er2}. As is well-know, a moving quantum\u000aobject passing through a double-slit exhibits particle wave duality. A quantum\u000acomputer is static and lacks this duality property. The recently proposed\u000aduality computer has exploited this particle wave duality property, and it may\u000aoffer additional computing power \u005ccite{r1}. Simply put it, a duality computer\u000ais a moving quantum computer passing through a double-slit. A duality computer\u000aoffers the capability to perform separate operations on the sub-waves coming\u000aout of the different slits, in the so-called duality parallelism. Here we show\u000athat an $n$-dubit duality computer can be modeled by an $(n+1)$-qubit quantum\u000acomputer. In a duality mode, computing operations are not necessarily unitary.\u000aA $n$-qubit quantum computer can be used as an $n$-bit reversible classical\u000acomputer and is energy efficient. Our result further enables a $(n+1)$-qubit\u000aquantum computer to run classical algorithms in a $O(2^n)$-bit classical\u000acomputer. The duality mode provides a natural link between classical computing\u000aand quantum computing. Here we also propose a recycling computing mode in which\u000aa quantum computer will continue to compute until the result is obtained. These\u000atwo modes provide new tool for algorithm design. A search algorithm for the\u000aunsorted database search problem is designed.
p189
sg73
VDuality and Recycling Computing in Quantum Computers
p190
ssVhttp://arxiv.org/abs/cs/0701087v2
p191
(dp192
g3
Vcs.MA
p193
sg5
VArtificiality in Social Sciences
p194
sg7
VThis text provides with an introduction to the modern approach of\u000aartificiality and simulation in social sciences. It presents the relationship\u000abetween complexity and artificiality, before introducing the field of\u000aartificial societies which greatly benefited from the computer power fast\u000aincrease, gifting social sciences with formalization and experimentation tools\u000apreviously owned by "hard" sciences alone. It shows that as "a new way of doing\u000asocial sciences", artificial societies should undoubtedly contribute to a\u000arenewed approach in the study of sociality and should play a significant part\u000ain the elaboration of original theories of social phenomena.
p195
ssVhttp://arxiv.org/abs/1509.01213v1
p196
(dp197
g3
Vq-fin.GN
p198
sg5
VImpact of Artificial Intelligence on Economic Theory
p199
sg7
VArtificial intelligence has impacted many aspects of human life. This paper\u000astudies the impact of artificial intelligence on economic theory. In particular\u000awe study the impact of artificial intelligence on the theory of bounded\u000arationality, efficient market hypothesis and prospect theory.
p200
ssVhttp://arxiv.org/abs/1503.00673v4
p201
(dp202
g56
Vcs.OH
p203
sg58
VThere is considerable and growing interest in the emergence of novel\u000atechnologies, especially from the policy-making perspective. Yet as an area of\u000astudy, emerging technologies lacks key foundational elements, namely a\u000aconsensus on what classifies a technology as 'emergent' and strong research\u000adesigns that operationalize central theoretical concepts. The present paper\u000aaims to fill this gap by developing a definition of 'emerging technologies' and\u000alinking this conceptual effort with the development of a framework for the\u000aoperationalisation of technological emergence. The definition is developed by\u000acombining a basic understanding of the term and in particular the concept of\u000a'emergence' with a review of key innovation studies dealing with definitional\u000aissues of technological emergence. The resulting definition identifies five\u000aattributes that feature in the emergence of novel technologies. These are: (i)\u000aradical novelty, (ii) relatively fast growth, (iii) coherence, (iv) prominent\u000aimpact, and (v) uncertainty and ambiguity. The framework for operationalising\u000aemerging technologies is then elaborated on the basis of the proposed\u000aattributes. To do so, we identify and review major empirical approaches (mainly\u000ain, although not limited to, the scientometric domain) for the detection and\u000astudy of emerging technologies (these include indicators and trend analysis,\u000acitation analysis, co-word analysis, overlay mapping, and combinations thereof)\u000aand elaborate on how these can be used to operationalise the different\u000aattributes of emergence.
p204
sg60
VWhat Is an Emerging Technology?
p205
ssVhttp://arxiv.org/abs/1401.5465v3
p206
(dp207
g40
Vcs.DB
p208
sg42
VData generation is a key issue in big data benchmarking that aims to generate\u000aapplication-specific data sets to meet the 4V requirements of big data.\u000aSpecifically, big data generators need to generate scalable data (Volume) of\u000adifferent types (Variety) under controllable generation rates (Velocity) while\u000akeeping the important characteristics of raw data (Veracity). This gives rise\u000ato various new challenges about how we design generators efficiently and\u000asuccessfully. To date, most existing techniques can only generate limited types\u000aof data and support specific big data systems such as Hadoop. Hence we develop\u000aa tool, called Big Data Generator Suite (BDGS), to efficiently generate\u000ascalable big data while employing data models derived from real data to\u000apreserve data veracity. The effectiveness of BDGS is demonstrated by developing\u000asix data generators covering three representative data types (structured,\u000asemi-structured and unstructured) and three data sources (text, graph, and\u000atable data).
p209
sg44
VBDGS: A Scalable Big Data Generator Suite in Big Data Benchmarking
p210
ssVhttp://arxiv.org/abs/1205.3915v1
p211
(dp212
g100
Vmath.GN
p213
sg102
VIn this work, we will introduce the notion of generalized topological groups\u000ausing generalized topological structure and generalized continuity defined by\u000a?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\u000astructures and connectedness properties of this structures are given. Keywords:\u000aGeneralized topology; generalized continuity; generalized topological groups;\u000ageneralized connectedness.
p214
sg104
VOn generalized topological groups
p215
ssVhttp://arxiv.org/abs/1109.3850v1
p216
(dp217
g11
Vcs.CV
p218
sg13
VOn the digital homology groups of digital images
p219
sg15
VIn this article we study the digital homology groups of digital images which\u000aare based on the singular homology groups of topological spaces in algebraic\u000atopology. Specifically, we define a digitally standard $n$-simplex, a digitally\u000asingular $n$-simplex, and the digital homology groups of digital images with\u000a$k$-adjacency relations. We then construct a covariant functor from a category\u000aof digital images and digitally continuous functions to the one of abelian\u000agroups and group homomorphisms, and investigate some fundamental and\u000ainteresting properties of digital homology groups of digital images, such as\u000athe digital version of the dimension axiom which is one of the\u000aEilenberg-Steenrod axioms.
p220
ssVhttp://arxiv.org/abs/1601.02334v1
p221
(dp222
g40
Vastro-ph.IM
p223
sg42
VThe Large sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) is the\u000alargest optical telescope in China. In last four years, the LAMOST telescope\u000ahas published four editions data (pilot data release, data release 1, data\u000arelease 2 and data release 3). To archive and release these data (raw data,\u000acatalog, spectrum etc), we have set up a data cycle management system,\u000aincluding the transfer of data, archiving, backup. And through the evolution of\u000afour software versions, mature established data release system.
p224
sg44
VThe LAMOST Data Archive and Data Release
p225
ssVhttp://arxiv.org/abs/1309.5134v1
p226
(dp227
g19
Vcs.OH
p228
sg21
VFormal Contexts, Formal Concept Analysis, and Galois Connections
p229
sg23
VFormal concept analysis (FCA) is built on a special type of Galois\u000aconnections called polarities. We present new results in formal concept\u000aanalysis and in Galois connections by presenting new Galois connection results\u000aand then applying these to formal concept analysis. We also approach FCA from\u000athe perspective of collections of formal contexts. Usually, when doing FCA, a\u000aformal context is fixed. We are interested in comparing formal contexts and\u000aasking what criteria should be used when determining when one formal context is\u000abetter than another formal context. Interestingly, we address this issue by\u000astudying sets of polarities.
p230
ssVhttp://arxiv.org/abs/1212.5683v1
p231
(dp232
g19
Vmath.PR
p233
sg21
VA Mixed Generalized Multifractal Formalism For Vector Valued Measures
p234
sg23
VWe introduce a mixed generalized multifractal formalism which extends the\u000amixed multifractal formalism introduced by L. Olsen based on generalizations of\u000athe Hausdorff and packing measures. The validity of such a formalism is proved\u000ain some special cases.
p235
ssVhttp://arxiv.org/abs/1202.0949v1
p236
(dp237
g100
Vstat.ME
p238
sg102
VA general approach for Bayesian filtering of multi-object systems is studied,\u000awith particular emphasis on the model where each object generates observations\u000aindependently of other objects. The approach is based on variational calculus\u000aapplied to generating functionals, using the general version of Faa di Bruno's\u000aformula for Gateaux differentials. This result enables us to determine some\u000ageneral formulae for the updated generating functional after the application of\u000aa multi-object analogue of Bayes' rule.
p239
sg104
VBayesian filtering for multi-object systems with independently generated\u000a  observations
p240
ssVhttp://arxiv.org/abs/0705.3601v1
p241
(dp242
g19
Vquant-ph
p243
sg21
VSpin Description in the Star Product and the Path Integral Formalism
p244
sg23
VThe spin can be described in the star product formalism by extending the\u000abosonic Moyal product in the fermionic sector. The fermionic star product is\u000athen the Clifford product of geometric algebra and it is possible to formulate\u000athe fermionic star product formalism in analogy to the bosonic star product\u000aformalism. For the fermionic star product description of spin, one can then\u000aestablish the relation to other approaches that describe spin with fermionic\u000avariables, i.e. the operator formalism and the path integral formalism. It is\u000ashown that the fermionic star product formalism and the fermionic path integral\u000aformalism are related in analogy to their bosonic counterparts.
p245
ssVhttp://arxiv.org/abs/cs/0411091v2
p246
(dp247
g11
Vcs.DL
p248
sg13
VPrinciples for Digital Preservation
p249
sg15
VThe immense investments in creating and disseminating digitally represented\u000ainformation have not been accompanied by commensurate effort to ensure the\u000alongevity of information of permanent interest. Asserted difficulties with\u000along-term digital preservation prove to be largely underestimation of what\u000atechnology can provide. We show how to clarify prominent misunderstandings and\u000asketch a 'Trustworthy Digital Object (TDO)' method that solves all the\u000apublished technical challenges.
p250
ssVhttp://arxiv.org/abs/1312.2447v1
p251
(dp252
g69
Vcs.GL
p253
sg71
VWe need much better understanding of information processing and computation\u000aas its primary form. Future progress of new computational devices capable of\u000adealing with problems of big data, internet of things, semantic web, cognitive\u000arobotics and neuroinformatics depends on the adequate models of computation. In\u000athis article we first present the current state of the art through\u000asystematization of existing models and mechanisms, and outline basic structural\u000aframework of computation. We argue that defining computation as information\u000aprocessing, and given that there is no information without (physical)\u000arepresentation, the dynamics of information on the fundamental level is\u000aphysical/ intrinsic/ natural computation. As a special case, intrinsic\u000acomputation is used for designed computation in computing machinery. Intrinsic\u000anatural computation occurs on variety of levels of physical processes,\u000acontaining the levels of computation of living organisms (including highly\u000aintelligent animals) as well as designed computational devices. The present\u000aarticle offers a typology of current models of computation and indicates future\u000apaths for the advancement of the field; both by the development of new\u000acomputational models and by learning from nature how to better compute using\u000adifferent mechanisms of intrinsic computation.
p254
sg73
VTypologies of Computation and Computational Models
p255
ssVhttp://arxiv.org/abs/1306.1730v1
p256
(dp257
g40
Vcs.DB
p258
sg42
VMetadata represents the information about data to be stored in Data\u000aWarehouses.It is a mandatory element of Data Warehouse to build an efficient\u000aData Warehouse.Metadata helps in data integration,lineage,data quality and\u000apopulating transformed data into data warehouse.Spatial data warehouses are\u000abased on spatial data mostly collected from Geographical Information\u000aSystems(GIS)and the transactional systems that are specific to an application\u000aor enterprise.Metadata design and deployment is the most critical phase in\u000abuilding of data warehouse where it is mandatory to bring the spatial\u000ainformation and data modeling together.In this paper,we present a holistic\u000ametadata framework that drives metadata creation for spatial data warehouse.\u000aTheoretically, the proposed metadata framework improves the efficiency of\u000aaccessing of data in response to frequent queries on SDWs.In other words, the\u000aproposed framework decreases the response time of the query and accurate\u000ainformation is fetched from Data Warehouse including the spatial information.
p259
sg44
VA Conceptual Metadata Framework for Spatial Data Warehouse
p260
ssVhttp://arxiv.org/abs/hep-th/9503177v1
p261
(dp262
g19
Vhep-th
p263
sg21
VHigher Derivatives and Canonical Formalism
p264
sg23
VA canonical formalism for higher-derivative theories is presented on the\u000abasis of Dirac's method for constrained systems. It is shown that this\u000aformalism shares a path integral expression with Ostrogradski's canonical\u000aformalism.
p265
ssVhttp://arxiv.org/abs/1101.4236v1
p266
(dp267
g27
Vcs.CR
p268
sg29
VIndexing Properties of Primitive Pythagorean Triples for Cryptography\u000a  Applications
p269
sg31
VThis paper presents new properties of Primitive Pythagorean Triples (PPT)\u000athat have relevance in applications where events of different probability need\u000ato be generated and in cryptography.
p270
ssVhttp://arxiv.org/abs/astro-ph/0702666v1
p271
(dp272
g56
Vastro-ph
p273
sg58
VWe study the emergence of magnetic flux from the near-surface layers of the\u000asolar convection zone into the photosphere. To model magnetic flux emergence,\u000awe carried out a set of numerical radiative magnetohydrodynamics simulations.\u000aOur simulations take into account the effects of compressibility, energy\u000aexchange via radiative transfer, and partial ionization in the equation of\u000astate. All these physical ingredients are essential for a proper treatment of\u000athe problem. Furthermore, the inclusion of radiative transfer allows us to\u000adirectly compare the simulation results with actual observations of emerging\u000aflux. We find that the interaction between the magnetic flux tube and the\u000aexternal flow field has an important influence on the emergent morphology of\u000athe magnetic field. Depending on the initial properties of the flux tube (e.g.\u000afield strength, twist, entropy etc.), the emergence process can also modify the\u000alocal granulation pattern. The emergence of magnetic flux tubes with a flux of\u000a$10^{19}$ Mx disturbs the granulation and leads to the transient appearance of\u000aa dark lane, which is coincident with upflowing material. These results are\u000aconsistent with observed properties of emerging magnetic flux.
p274
sg60
VMagnetic flux emergence in granular convection: Radiative MHD\u000a  simulations and observational signatures
p275
ssVhttp://arxiv.org/abs/math/0501381v1
p276
(dp277
g82
Vmath.CV
p278
sg84
VIt is shown that discrete analogs of z^c and log(z) have the same asymptotic\u000abehavior as their smooth counterparts. These discrete maps are described in\u000aterms of special solutions of discrete Painleve-II equations, asymptotics of\u000athese solutions providing the behaviour of discrete z^c and log(z) at infinity.
p279
sg86
VAsymptotic behavior of discrete holomorphic maps z^c, log(z) and\u000a  discrete Painleve transcedents
p280
ssVhttp://arxiv.org/abs/cs/0112017v1
p281
(dp282
g11
Vcs.DL
p283
sg13
VUsing Structural Metadata to Localize Experience of Digital Content
p284
sg15
VWith the increasing technical sophistication of both information consumers\u000aand providers, there is increasing demand for more meaningful experiences of\u000adigital information. We present a framework that separates digital object\u000aexperience, or rendering, from digital object storage and manipulation, so the\u000arendering can be tailored to particular communities of users. Our framework\u000aalso accommodates extensible digital object behaviors and interoperability. The\u000atwo key components of our approach are 1) exposing structural metadata\u000aassociated with digital objects -- metadata about the labeled access points\u000awithin a digital object and 2) information intermediaries called context\u000abrokers that match structural characteristics of digital objects with\u000amechanisms that produce behaviors. These context brokers allow for localized\u000arendering of digital information stored externally.
p285
ssVhttp://arxiv.org/abs/1111.2567v1
p286
(dp287
g100
Vmath.NT
p288
sg102
VIn this paper, we present a new generalization of the Lucas numbers by matrix\u000arepresentation using Genaralized Lucas Polynomials. We give some properties of\u000athis new generalization and some relations between the generalized order-k\u000aLucas numbers and generalized order-k Fibonacci numbers. In addition, we obtain\u000aBinet formula and combinatorial representation for generalized order-k Lucas\u000anumbers by using properties of generalized Fibonacci numbers.
p289
sg104
VGeneralized Lucas Numbers and Relations with Generalized Fibonacci\u000a  Numbers
p290
ssVhttp://arxiv.org/abs/cs/0604004v1
p291
(dp292
g11
Vcs.DM
p293
sg13
VThe Poincare conjecture for digital spaces. Properties of digital\u000a  n-dimensional disks and spheres
p294
sg15
VMotivated by the Poincare conjecture, we study properties of digital\u000an-dimensional spheres and disks, which are digital models of their continuous\u000acounterparts. We introduce homeomorphic transformations of digital manifolds,\u000awhich retain the connectedness, the dimension, the Euler characteristics and\u000athe homology groups of manifolds. We find conditions where an n-dimensional\u000adigital manifold is the n-dimensional digital sphere and discuss the link\u000abetween continuous closed n-manifolds and their digital models.
p295
ssVhttp://arxiv.org/abs/0709.3587v1
p296
(dp297
g40
Vcs.NE
p298
sg42
VIn data analysis new forms of complex data have to be considered like for\u000aexample (symbolic data, functional data, web data, trees, SQL query and\u000amultimedia data, ...). In this context classical data analysis for knowledge\u000adiscovery based on calculating the center of gravity can not be used because\u000ainput are not $\u005cmathbb{R}^p$ vectors. In this paper, we present an application\u000aon real world symbolic data using the self-organizing map. To this end, we\u000apropose an extension of the self-organizing map that can handle symbolic data.
p299
sg44
VSelf-organizing maps and symbolic data
p300
ssVhttp://arxiv.org/abs/1703.09489v1
p301
(dp302
g100
Vmath.GT
p303
sg102
VWe define the generalized connected sum for generic closed plane curves,\u000ageneralizing the strange sum defined by Arnold, and completely describe how the\u000aArnold invariants $J^{\u005cpm}$ and $\u005cmathit{St}$ behave under the generalized\u000aconnected sums.
p304
sg104
VGeneralized connected sum formula for the Arnold invariants of generic\u000a  plane curves
p305
ssVhttp://arxiv.org/abs/1312.0156v1
p306
(dp307
g40
Vcs.DB
p308
sg42
VRecent technology breakthroughs have enabled data collection of unprecedented\u000ascale, rate, variety and complexity that has led to an explosion in data\u000amanagement requirements. Existing theories and techniques are not adequate to\u000afulfil these requirements. We endeavour to rethink the way data management\u000aresearch is being conducted and we propose to work towards modular data\u000amanagement that will allow for unification of the expression of data management\u000aproblems and systematization of their solution. The core of such an approach is\u000athe novel notion of a datom, i.e. a data management atom, which encapsulates\u000ageneric data management provision. The datom is the foundation for comparison,\u000acustomization and re-usage of data management problems and solutions. The\u000aproposed approach can signal a revolution in data management research and a\u000along anticipated evolution in data management engineering.
p309
sg44
VDatom: Towards modular data management
p310
ssVhttp://arxiv.org/abs/math/0503179v2
p311
(dp312
g100
Vmath.GM
p313
sg102
VThis paper proposes a generalized ABC conjecture and assuming its validity\u000asettles a generalized version of Fermats last theorem.
p314
sg104
VOn a Possible Generalization of Fermats Last Theorem
p315
ssVhttp://arxiv.org/abs/1307.7943v1
p316
(dp317
g40
Vcs.PF
p318
sg42
VNow we live in an era of big data, and big data applications are becoming\u000amore and more pervasive. How to benchmark data center computer systems running\u000abig data applications (in short big data systems) is a hot topic. In this\u000apaper, we focus on measuring the performance impacts of diverse applications\u000aand scalable volumes of data sets on big data systems. For four typical data\u000aanalysis applications---an important class of big data applications, we find\u000atwo major results through experiments: first, the data scale has a significant\u000aimpact on the performance of big data systems, so we must provide scalable\u000avolumes of data sets in big data benchmarks. Second, for the four applications,\u000aeven all of them use the simple algorithms, the performance trends are\u000adifferent with increasing data scales, and hence we must consider not only\u000avariety of data sets but also variety of applications in benchmarking big data\u000asystems.
p319
sg44
VThe Implications of Diverse Applications and Scalable Data Sets in\u000a  Benchmarking Big Data Systems
p320
ssVhttp://arxiv.org/abs/1506.02198v1
p321
(dp322
g48
Vmath.PR
p323
sg50
VG-casual Stable Probability Distributions
p324
sg52
VA generalization of stable and casual stable probability distribution is\u000aproposed. The notion of $\u005cgo G$-casual stability can be used to introduce\u000adiscrete analogues of stable distributions on the sent $\u005cmathbb Z$ of integers.\u000aIn contrary to limit definition of stable distributions on $\u005cmathbb Z$ our has\u000aalgebraic character. Examples of corresponding limit theorems are given.\u000a  Keywords: stable distributions; casual stable distribution; discrete stable\u000adistributions; limit theorems
p325
ssVhttp://arxiv.org/abs/1402.5282v1
p326
(dp327
g48
Vstat.CO
p328
sg50
VThe Compound Class of Linear Failure Rate-Power Series Distributions:\u000a  Model, Properties and Applications
p329
sg52
VWe introduce in this paper a new class of distributions which generalizes the\u000alinear failure rate (LFR) distribution and is obtained by compounding the LFR\u000adistribution and power series (PS) class of distributions. This new class of\u000adistributions is called the linear failure rate-power series (LFRPS)\u000adistributions and contains some new distributions such as linear failure rate\u000ageometric (LFRG) distribution, linear failure rate Poisson (LFRP) distribution,\u000alinear failure rate logarithmic (LFRL) distribution, linear failure rate\u000abinomial (LFRB) distribution and Raylight-power series (RPS) class of\u000adistributions. Some former works such as exponential-power series (EPS) class\u000aof distributions, exponential geometric (EG) distribution, exponential Poisson\u000a(EP) distribution and exponential logarithmic (EL) distribution are special\u000acases of the new proposed model.\u000a  The ability of the LFRPS class of distributions is in covering five possible\u000ahazard rate function i.e., increasing, decreasing, upside-down bathtub\u000a(unimodal), bathtub and increasing-decreasing-increasing shaped. Several\u000aproperties of the LFRPS distributions such as moments, maximum likelihood\u000aestimation procedure via an EM-algorithm and inference for a large sample, are\u000adiscussed in this paper. In order to show the flexibility and potentiality of\u000athe new class of distributions, the fitted results of the new class of\u000adistributions and some its submodels are compared using a real data set.
p330
ssVhttp://arxiv.org/abs/physics/0007090v3
p331
(dp332
g27
Vphysics.gen-ph
p333
sg29
VEntanglement versus disentanglement: Quantum Cryptography
p334
sg31
VIn quantum information, the role of entanglement and disentanglement is\u000aitself a subject of research and debate. Earlier works on quantum cryptography\u000ahave almost established that entanglement has no special advantage in quantum\u000acryptography. In this paper we reveal that entanglement is better ingredient\u000athan disentanglement for our alternative quantum cryptography.
p335
ssVhttp://arxiv.org/abs/cs/0603067v1
p336
(dp337
g27
Vcs.CR
p338
sg29
VImplementing the Three-Stage Quantum Cryptography Protocol
p339
sg31
VWe present simple implementations of Kak's three-stage quantum cryptography\u000aprotocol. The case where the transformation is applied to more than one qubit\u000aat the same time is also considered.
p340
ssVhttp://arxiv.org/abs/cond-mat/0410515v1
p341
(dp342
g82
Vcond-mat.other
p343
sg84
VWe introduce the generalized spatial discretization of the\u000aKardar-Parisi-Zhang (KPZ) equation in 1+1 dimensions. We solve exactly the\u000asteady state probability density function for the discrete heights of the\u000ainterface, for any discretization scheme. We show that the discretization\u000aprescription is a consequence of each particular model. From the ballistic\u000adeposition model we derive the discretization prescription of the corresponding\u000aKPZ equation.
p344
sg86
VGeneralized discretization of the Kardar-Parisi-Zhang equation
p345
ssVhttp://arxiv.org/abs/nlin/0609011v1
p346
(dp347
g56
Vnlin.AO
p348
sg58
VSince its application to systems, emergence has been explained in terms of\u000alevels of observation. This approach has led to confusion, contradiction,\u000aincoherence and at times mysticism. When the idea of level is replaced by a\u000aframework of scope, resolution and state, this confusion is dissolved. We find\u000athat emergent properties are determined by the relationship between the scope\u000aof macrostate and microstate descriptions. This establishes a normative\u000adefinition of emergent properties and emergence that makes sense of previous\u000adescriptive definitions of emergence. In particular, this framework sheds light\u000aon which classes of emergent properties are epistemic and which are\u000aontological, and identifies fundamental limits to our ability to capture\u000aemergence in formal systems.
p349
sg60
VEmergence is coupled to scope, not level
p350
ssVhttp://arxiv.org/abs/cs/0603046v1
p351
(dp352
g27
Vcs.CR
p353
sg29
VTrusted Certificates in Quantum Cryptography
p354
sg31
VThis paper analyzes the performance of Kak's three stage quantum\u000acryptographic protocol based on public key cryptography against a\u000aman-in-the-middle attack. A method for protecting against such an attack is\u000apresented using certificates distributed by a trusted third party.
p355
ssVhttp://arxiv.org/abs/1010.2541v1
p356
(dp357
g11
Vmath.HO
p358
sg13
VDIGITAL ERA: Universal Bimagic Squares
p359
sg15
VIn this short note we have produced different kinds of bimagic squares using\u000aonly the digits 0, 1, 2, 5 and 8. The universal bimagic squares presented are\u000aof order 8x8, 9x9, 16x16 and 25x25. In order to bring universal bimagic square\u000aof order 8x8, we used only the digits 2 and 5. For the order 9x9, we used only\u000athe digits 2, 5 and 8. For the universal bimagic square of order 16x16 we used\u000athe digits 1, 2, 5 and 8 and finally for the order 25x25, we used five digits\u000a0, 1, 2, 5 and 8. In order to produce these universal bimagic squares we have\u000aused the digits in the digital form.
p360
ssVhttp://arxiv.org/abs/1307.1938v1
p361
(dp362
g56
Vastro-ph.SR
p363
sg58
VThe subsurface properties of active regions prior to their appearance at the\u000asolar surface may shed light on the process of active region formation.\u000aHelioseismic holography has been applied to samples taken from two populations\u000aof regions on the Sun (pre-emergence and without emergence), each sample having\u000aover 100 members, that were selected to minimize systematic bias, as described\u000ain Paper I (Leka et al., 2012). Paper II (Birch et al., 2012) showed that there\u000aare statistically significant signatures in the average helioseismic properties\u000athat precede the formation of an active region. This paper describes a more\u000adetailed analysis of the samples of pre-emergence regions and regions without\u000aemergence, based on discriminant analysis. The property that is best able to\u000adistinguish the populations is found to be the surface magnetic field, even a\u000aday before the emergence time. However, after accounting for the correlations\u000abetween the surface field and the quantities derived from helioseismology,\u000athere is still evidence of a helioseismic precursor to active region emergence\u000athat is present for at least a day prior to emergence.
p364
sg60
VHelioseismology of Pre-Emerging Active Regions III: Statistical Analysis
p365
ssVhttp://arxiv.org/abs/hep-th/9905071v1
p366
(dp367
g19
Vhep-th
p368
sg21
V11-dimensional curved backgrounds for supermembrane in superspace
p369
sg23
VWe compute part of the superfield in terms of the component fields of\u000a11-dimensional on-shell supergravity by using `Gauge completion' in 2nd-order\u000aformalism. The result is the same as was derived recently in 1.5-order\u000aformalism by B. de Wit, K. Peeters and J. Plefka. We use 2nd-order formalism\u000abecause in order to hold $\u005ckappa $-invariance generally 2nd-order formalism is\u000amore hopeful and simpler than 1.5-order formalism.
p370
ssVhttp://arxiv.org/abs/gr-qc/9908033v1
p371
(dp372
g100
Vgr-qc
p373
sg102
VA simple formula is given for generating Chern characters by repeated\u000aexterior differentiation for n-dimensional differentiable manifolds having a\u000ageneral linear connection.
p374
sg104
VA Simple Formula for Generating Chern Characters by Repeated Exterior\u000a  Differentiation
p375
ssVhttp://arxiv.org/abs/nlin/0506028v1
p376
(dp377
g56
Vnlin.AO
p378
sg58
VThe knowledge of the different types of emergence is essential if we want to\u000aunderstand and master complex systems in science and engineering, respectively.\u000aThis paper specifies a universal taxonomy and comprehensive classification of\u000athe major types and forms of emergence in Multi-Agent Systems, from simple\u000atypes of intentional and predictable emergence in machines to more complex\u000aforms of weak, multiple and strong emergence.
p379
sg60
VTypes and Forms of Emergence
p380
ssVhttp://arxiv.org/abs/quant-ph/0003151v1
p381
(dp382
g69
Vquant-ph
p383
sg71
VThis paper investigates a variety of unconventional quantum computation\u000adevices, including fermionic quantum computers and computers that exploit\u000anonlinear quantum mechanics. It is shown that unconventional quantum computing\u000adevices can in principle compute some quantities more rapidly than\u000a`conventional' quantum computers.
p384
sg73
VUnconventional Quantum Computing Devices
p385
ssVhttp://arxiv.org/abs/1412.6703v2
p386
(dp387
g3
Vcs.AI
p388
sg5
VQuantifying Natural and Artificial Intelligence in Robots and Natural\u000a  Systems with an Algorithmic Behavioural Test
p389
sg7
VOne of the most important aims of the fields of robotics, artificial\u000aintelligence and artificial life is the design and construction of systems and\u000amachines as versatile and as reliable as living organisms at performing high\u000alevel human-like tasks. But how are we to evaluate artificial systems if we are\u000anot certain how to measure these capacities in living systems, let alone how to\u000adefine life or intelligence? Here I survey a concrete metric towards measuring\u000aabstract properties of natural and artificial systems, such as the ability to\u000areact to the environment and to control one's own behaviour.
p390
ssVhttp://arxiv.org/abs/1106.1955v1
p391
(dp392
g56
Vastro-ph.SR
p393
sg58
VWe studied 101 flux emergence events ranging from small ephemeral regions to\u000alarge emerging flux regions which were observed with Hinode Solar Optical\u000aTelescope filtergram. We investigated how the total magnetic flux of the\u000aemergence event controls the nature of emergence. To determine the modes of\u000aemergences, horizontal velocity fields of global motion of the magnetic patches\u000ain the flux emerging sites were measured by the local correlation tracking.\u000aBetween two main polarities of the large emerging flux regions with more than\u000aaround 2 \u005ctimes 10^19 Mx, there were the converging flows of anti-polarity\u000amagnetic patches. On the other hand, small ephemeral regions showed no\u000aconverging flow but simple diverging pattern. When we looked into the detailed\u000afeatures in the emerging sites, irrespective of the total flux and the spatial\u000asize, all the emergence events were observed to consist of single or multiple\u000aelementary emergence unit(s). The typical size of unitary emergence is 4 Mm and\u000aconsistent with the simulation results. From the statistical study of the flux\u000aemergence events, the maximum spatial distance between two main polarities, the\u000amagnetic flux growth rate and the mean separation speed were found to follow\u000athe power-law functions of the total magnetic flux with the indices of 0.27,\u000a0.57, and -0.16, respectively. From the discussion on the observed power-law\u000arelations, we got a physical view of solar flux emergence that emerging\u000amagnetic fields float and evolve balancing to the surrounding turbulent\u000aatmosphere. Key words: Sun: magnetic fields - Sun: emerging flux - Sun:\u000aphotosphere - Sun: chromosphere
p394
sg60
VStatistical Study on the Nature of Solar Flux Emergence
p395
ssVhttp://arxiv.org/abs/0901.0317v1
p396
(dp397
g3
Vcs.NE
p398
sg5
VDesign of a P System based Artificial Graph Chemistry
p399
sg7
VArtificial Chemistries (ACs) are symbolic chemical metaphors for the\u000aexploration of Artificial Life, with specific focus on the origin of life. In\u000athis work we define a P system based artificial graph chemistry to understand\u000athe principles leading to the evolution of life-like structures in an AC set up\u000aand to develop a unified framework to characterize and classify symbolic\u000aartificial chemistries by devising appropriate formalism to capture semantic\u000aand organizational information. An extension of P system is considered by\u000aassociating probabilities with the rules providing the topological framework\u000afor the evolution of a labeled undirected graph based molecular reaction\u000asemantics.
p400
ssVhttp://arxiv.org/abs/1302.5342v1
p401
(dp402
g11
Vcs.DM
p403
sg13
VThe Jordan-Brouwer theorem for the digital normal n-space Zn
p404
sg15
VIn this paper we investigate properties of digital spaces which are\u000arepresented by graphs. We find conditions for digital spaces to be digital\u000an-manifolds and n-spheres. We study properties of partitions of digital spaces\u000aand prove a digital analog of the Jordan-Brouwer theorem for the normal digital\u000an-space Zn.
p405
ssVhttp://arxiv.org/abs/1703.06340v1
p406
(dp407
g100
Vmath.CA
p408
sg102
VWe consider the spherical mean generated by a multidimensional generalized\u000atranslation and general Euler-Poisson-Darboux equation corresponding to this\u000amean. The Asgeirsson property of solutions of the ultrahyperbolic equation that\u000aincludes singular differential Bessel operators acting by each variable is\u000aprovided.
p409
sg104
VWeighted spherical means generated by generalized translation and\u000a  general Euler-Poisson-Darboux equation
p410
ssVhttp://arxiv.org/abs/1203.2000v1
p411
(dp412
g40
Vcs.DB
p413
sg42
VDue to recent advances in data collection techniques, massive amounts of data\u000aare being collected at an extremely fast pace. Also, these data are potentially\u000aunbounded. Boundless streams of data collected from sensors, equipments, and\u000aother data sources are referred to as data streams. Various data mining tasks\u000acan be performed on data streams in search of interesting patterns. This paper\u000astudies a particular data mining task, clustering, which can be used as the\u000afirst step in many knowledge discovery processes. By grouping data streams into\u000ahomogeneous clusters, data miners can learn about data characteristics which\u000acan then be developed into classification models for new data or predictive\u000amodels for unknown events. Recent research addresses the problem of data-stream\u000amining to deal with applications that require processing huge amounts of data\u000asuch as sensor data analysis and financial applications. For such analysis,\u000asingle-pass algorithms that consume a small amount of memory are critical.
p414
sg44
VOverview of streaming-data algorithms
p415
ssVhttp://arxiv.org/abs/math/0409415v1
p416
(dp417
g82
Vmath.DS
p418
sg84
VThis paper applies the recently developed theory of discrete nonholonomic\u000amechanics to the study of discrete nonholonomic left-invariant dynamics on Lie\u000agroups. The theory is illustrated with the discrete versions of two classical\u000anonholonomic systems, the Suslov top and the Chaplygin sleigh. The preservation\u000aof the reduced energy by the discrete flow is observed and the discrete\u000amomentum conservation is discussed.
p419
sg86
VDiscrete Nonholonomic LL Systems on Lie Groups
p420
ssVhttp://arxiv.org/abs/cs/0401002v1
p421
(dp422
g27
Vcs.CR
p423
sg29
VA Comparison of Cryptography Courses
p424
sg31
VThe author taught two courses on cryptography, one at Duke University aimed\u000aat non-mathematics majors and one at Rose-Hulman Institute of Technology aimed\u000aat mathematics and computer science majors. Both tried to incorporate technical\u000aand societal aspects of cryptography, with varying emphases. This paper will\u000adiscuss the strengths and weaknesses of both courses and compare the\u000adifferences in the author's approach.
p425
ssVhttp://arxiv.org/abs/1201.0205v1
p426
(dp427
g56
Vcs.NI
p428
sg58
VAccess control is an issue of paramount importance in cyber-physical systems\u000a(CPS). In this paper, an access control scheme, namely FEAC, is presented for\u000aCPS. FEAC can not only provide the ability to control access to data in normal\u000asituations, but also adaptively assign emergency-role and permissions to\u000aspecific subjects and inform subjects without explicit access requests to\u000ahandle emergency situations in a proactive manner. In FEAC, emergency-group and\u000aemergency-dependency are introduced. Emergencies are processed in sequence\u000awithin the group and in parallel among groups. A priority and dependency model\u000acalled PD-AGM is used to select optimal response-action execution path aiming\u000ato eliminate all emergencies that occurred within the system. Fault-tolerant\u000aaccess control polices are used to address failure in emergency management. A\u000acase study of the hospital medical care application shows the effectiveness of\u000aFEAC.
p429
sg60
VA Fault-Tolerant Emergency-Aware Access Control Scheme for\u000a  Cyber-Physical Systems
p430
ssVhttp://arxiv.org/abs/1308.1806v1
p431
(dp432
g69
Vcs.DC
p433
sg71
VThrough the 1990s to 2012 the internet changed the world of computing\u000adrastically. It started its journey with parallel computing after it advanced\u000ato distributed computing and further to grid computing. And in present scenario\u000ait creates a new world which is pronounced as a Cloud Computing [1]. These all\u000athree terms have different meanings. Cloud computing is based on backward\u000acomputing schemes like cluster computing, distributed computing, grid computing\u000aand utility computing. The basic concept of cloud computing is virtualization.\u000aIt provides virtual hardware and software resources to various requesting\u000aprograms. This paper gives a detailed description about cluster computing, grid\u000acomputing and cloud computing and gives an insight of some implementations of\u000athe same. We try to list the inspirations for the advent of all these\u000atechnologies. We also account for some present scenario faults of grid\u000acomputing and also discuss new cloud computing projects which are being managed\u000aby the Government of India for learning. The paper also reviews the existing\u000awork and covers (analytically), to some extent, some innovative ideas that can\u000abe implemented.
p434
sg73
VA Survey of Current Trends in Distributed, Grid and Cloud Computing
p435
ss.