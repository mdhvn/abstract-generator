Title:  PreCog: Improving Crowdsourced Data Quality

('Precog', 618.826412308259)
('feedback', 248.67919004335695)
('quality', 244.63456268998326)
('text', 158.03755716766753)
('reviews', 135.85684738974928)
('pre-hoc', 105.20049009240402)
('features', 99.81319400063212)
('explanation', 86.97173274258002)
('Amazon', 81.72822626032315)
('low-quality', 80.44743360007367)
('TCruise', 74.25916947699108)
('trustworthiness', 71.31250281129468)
('segment', 69.07755278982138)
('document', 68.10685521693597)
('helpfulness', 68.07090535390849)
('qij', 68.07090535390849)
('segments', 67.092479544276)
('crowdsourcing', 66.1007887089638)
('corpus', 65.84537853451215)
('review', 62.76807858492991)
('segment-level', 61.8826412308259)
('FEF', 61.8826412308259)
('FEFs', 61.8826412308259)
('In', 61.69009906983513)
('constraints', 56.33032693519351)
('crowd', 56.102664593254595)
('document-level', 55.69437710774331)
('feature', 55.451774444795625)
('product', 55.451774444795625)
('responsibility', 55.3876411463652)
('crowdsourced', 54.97168225293202)
('segmentation', 54.72088902275941)
('interface', 53.75278407684165)
('The', 52.67918572255584)
('acquisition', 52.54772170709137)
('perturbations', 52.095331408022126)
('documents', 51.986038541995896)
('d', 51.63477756740116)
('profiles', 50.055462645829486)
('host', 50.055462645829486)
('Segment-Predict-Explain', 49.50611298466072)
('FEATURE', 49.50611298466072)
('Airbnb', 49.50611298466072)
('post-hoc', 49.47451402763882)
('data', 49.213449819756114)
('score', 48.16462684895568)
('labels', 47.95790545596741)
('forest', 46.701843577327516)
('2016', 45.747713916956386)
('perturbation', 44.6418336583069)
('We', 44.3614195558365)
('scores', 44.1665846874966)
('LIWC', 43.31784886157813)
('CREATE', 43.23618940259931)
('topics', 41.74726696938817)
('control', 41.58883083359672)
('custom', 41.31469979452329)
('worker', 40.07333185232471)
('prediction', 39.14394658089878)
('writing', 38.91820298110626)
('user', 38.816242111356935)
('improve', 38.626509898418405)
('emotion', 38.432168357866054)
('rating', 37.13572066704308)
('unhelpful', 37.12958473849554)
('Ipeirotis', 37.12958473849554)
('multi-paragraph', 37.12958473849554)
('post-feedback', 37.12958473849554)
('vij', 37.12958473849554)
('DDL', 37.12958473849554)
('rubric', 37.12958473849554)
('Sfdi', 37.12958473849554)
('domains', 36.972292832050954)
('Quality', 35.33326774999728)
('training', 35.15559323737951)
('e.g.', 33.7981961611161)
('prescriptive', 33.6281473131328)
('fi', 33.27106466687737)
('workers', 31.46856805319832)
('utility', 31.17263854637882)
('constraint', 31.13456238488501)
('minp', 30.94132061541295)
('Subjectivity', 30.94132061541295)
('product_id', 30.94132061541295)
('Informativeness', 30.94132061541295)
('coders', 30.562501204840572)
('across', 30.459910976876934)
('topic', 30.459910976876934)
('57', 29.933606208922598)
('Participants', 29.739466694345516)
('high-quality', 29.100689277811085)
('profile', 29.029630625767844)
('label', 28.563919505370855)
('explanations', 28.219447943362347)
('attribute', 28.214442932076903)
('laptop', 28.051332296627297)
('existing', 27.725887222397812)
('J.', 27.725887222397812)
('val', 27.509804872023434)
('rental', 27.48584112646601)
('Dij', 27.48584112646601)
('coder', 27.48584112646601)
('submission', 27.47189763588117)
('can', 27.032740041837865)
('impact', 26.876392038420825)
('table', 26.876392038420825)
('high', 26.366694928034633)
('attributes', 26.366694928034633)
('Ti', 25.490971452296158)
('input', 25.268082639366526)
("''", 24.95329850015803)
('``', 24.95329850015803)
('interfaces', 24.953298500158027)
('developer', 24.887436430425893)
('friendliness', 24.75305649233036)
('att', 24.75305649233036)
('Sed', 24.75305649233036)
('Doc+TCruise', 24.75305649233036)
('Prescriptive', 24.75305649233036)
('TopicTiling', 24.75305649233036)
('featureCnt', 24.75305649233036)
('CHECK', 24.75305649233036)
('TKDE', 24.75305649233036)
('Readability', 24.75305649233036)
('AirBnB', 24.75305649233036)
('predicting', 24.72833962686653)
('model', 24.260151319598084)
('For', 24.260151319598084)
('measures', 24.141568686511505)
('Feedback', 23.57107080990532)
('task', 23.56700413903814)
('domain', 23.56700413903814)
('automatically', 23.292873099964716)
('2015', 23.292873099964716)
('jargon', 22.92483739335286)
('def', 22.839974938621918)
('customized', 22.532130774077405)
('path', 22.18070977791825)
('low', 22.18070977791825)
('content', 22.18070977791825)
('generate', 22.18070977791825)
('perturbed', 22.033596236321266)
('Profiles', 21.98867290117281)
('LDA', 21.98867290117281)
('helpful', 21.972245773362197)
('integrity', 21.66440160881768)
("'s", 21.487562597358306)
('prior', 21.405011639608446)
('paths', 21.405011639608446)
('library', 21.405011639608446)
('Explanation', 21.242476210246796)
('USING', 21.242476210246796)
('classifier', 20.970125914877936)
('minutes', 20.970125914877936)
('users', 20.922692861643302)
('p', 20.873633484694086)
('--', 20.873633484694086)
('functions', 20.873633484694086)
('M.', 20.79441541679836)
('using', 20.79441541679836)
('S.', 20.79441541679836)
('revisions', 20.37500080322705)
('grading', 20.37500080322705)
('PF', 20.37500080322705)
('1', 20.101268236238415)
('improves', 19.879253198304003)
('developers', 19.832493408393514)
('survey', 19.709354161508603)
('generates', 19.45910149055313)
('Figure', 19.408121055678468)
('predictive', 19.408121055678468)
('effective', 19.313254949209202)
('SIGMOD', 19.313254949209202)
('optimizations', 19.033312448851596)
('predicted', 18.95635140771547)
('A.', 18.714973875118524)
('influence', 18.71497387511852)
('models', 18.676408907357867)
('err', 18.56479236924777)
('pre-feedback', 18.56479236924777)
('Ability', 18.56479236924777)
('INTERFACE', 18.56479236924777)
('Parameswaran', 18.56479236924777)
('len_extracton', 18.56479236924777)
('textLen', 18.56479236924777)
('next-best', 18.56479236924777)
('Hancock', 18.56479236924777)
('EXPLANATION', 18.56479236924777)
('1.7x', 18.56479236924777)
('numeric_exp', 18.56479236924777)
('quora', 18.56479236924777)
('Ghose', 18.56479236924777)
('beige', 18.56479236924777)
('TCruise-based', 18.56479236924777)
('MTurk', 18.56479236924777)
('KDD', 18.33986991468229)
('essay', 18.33986991468229)
('Krause', 18.33986991468229)
('literature', 18.021826694558577)
('random', 18.021826694558577)
('measure', 18.021826694558577)
('default', 17.954645502230758)
('experiments', 17.91759469228055)
('social', 17.91759469228055)
('U', 17.703817036775103)
('balanced', 17.66663387499864)
('Rn', 17.66663387499864)
('Host', 17.626876989057013)
('actionable', 17.626876989057013)
('len', 17.626876989057013)
('analysis', 17.577796618689757)
('A', 17.328679513998633)
('used', 17.328679513998633)
('baseline', 17.16993602242573)
('customize', 16.993980968197437)
('violations', 16.993980968197437)
('Social', 16.785266909588593)
('comments', 16.635532333438686)
('Text', 16.635532333438686)
('Widom', 16.491504675879607)
('7.2.2', 16.491504675879607)
('14.3', 16.491504675879607)
('username', 16.491504675879607)
('F', 16.479184330021646)
('key', 16.479184330021646)
('ratings', 16.443495456693245)
('phone', 16.29048269010741)
('opinion', 16.24830120661326)
('tree', 16.125835223052494)
('return', 16.125835223052494)
('pattern', 16.125835223052494)
('improving', 16.11809565095832)
('threshold', 16.11809565095832)
('improvements', 16.11809565095832)
('average', 16.094379124341003)
('vote', 16.029332740929885)
('Turk', 16.029332740929885)
('median', 16.029332740929885)
('R.', 15.942385152878742)
('foreign', 15.890269151739728)
('ON', 15.677471079645748)
('acquire', 15.677471079645748)
('guidelines', 15.45521226679158)
('acquired', 15.45521226679158)
('94', 15.389696144769221)
('statements', 15.380572041353537)
('describe', 15.380572041353537)
('instance', 15.380572041353537)
('votes', 15.281250602420286)
('Garcia-Molina', 15.281250602420286)
('outlier', 15.281250602420286)
('vector', 15.249237972318797)
('work', 15.249237972318797)
('50', 15.249237972318797)
('function', 15.249237972318797)
('opinions', 14.978661367769954)
('mapped', 14.909439898728003)
('participants', 14.909439898728003)
('82', 14.909439898728003)
('2x', 14.854288266817232)
('C.', 14.556090791758852)
('improvement', 14.55609079175885)
('seeks', 14.550344638905543)
('Mechanical', 14.550344638905543)
('Crowd', 14.41206313419977)
('classification', 14.33407575382444)
('improved', 14.33407575382444)
('K.', 14.281959752685427)
('2011', 14.281959752685427)
('identify', 13.862943611198906)
('may', 13.862943611198906)
('distribution', 13.862943611198906)
('media', 13.815510557964275)
('overly', 13.754902436011717)
('Product', 13.735948817940585)
('maximal', 13.621371043387192)
('primary', 13.621371043387192)
('assigned', 13.621371043387192)
('products', 13.621371043387192)
('experiment', 13.621371043387192)
('coherent', 13.54025100551105)
('arrows', 13.54025100551105)
('customer', 13.469183319945897)
('predicts', 13.469183319945897)
('uniqueness', 13.328818040700815)
('forum', 13.220157741792761)
('facet', 13.220157741792761)
('data-driven', 13.220157741792761)
('cleaning', 13.220157741792761)
('matches', 13.195286648076292)
('age', 13.195286648076292)
('specific', 13.183347464017316)
('B.', 13.183347464017316)
('approaches', 13.183347464017316)
('Section', 13.183347464017316)
('based', 13.16979643063896)
('use', 13.16979643063896)
('4', 13.16979643063896)
('two', 13.16979643063896)
('confidence', 13.032386152085929)
('tasks', 12.875503299472802)
('trained', 12.824746787307683)
('outperformed', 12.745485726148079)
('holistic', 12.745485726148079)
('interpretable', 12.745485726148079)
('participant', 12.712215321391783)
('collecting', 12.541976863716599)
('D.', 12.476649250079015)
('Although', 12.476649250079015)
('condition', 12.476649250079015)
('help', 12.476649250079015)
('set', 12.476649250079015)
('Y.', 12.476649250079015)
('compute', 12.476649250079015)
('trees', 12.476649250079014)
('identifies', 12.424533248940001)
('85', 12.424533248940001)
('Benevolence', 12.37652824616518)
('Fminp', 12.37652824616518)
('AngularJS', 12.37652824616518)
('getFeedback', 12.37652824616518)
('Post-hoc', 12.37652824616518)
('Friendliness', 12.37652824616518)
('top-K', 12.37652824616518)
('Informativity', 12.37652824616518)
('feats=', 12.37652824616518)
('explanation_function', 12.37652824616518)
('Usher', 12.37652824616518)
('sortedTopics', 12.37652824616518)
('thresh', 12.37652824616518)
('sage', 12.37652824616518)
('Yelp', 12.37652824616518)
('Zappos', 12.37652824616518)
('multi-feature', 12.37652824616518)
('Pre-hoc', 12.37652824616518)
('Provost', 12.37652824616518)
('uage', 12.37652824616518)
('att1', 12.37652824616518)
('attn', 12.37652824616518)
('CROWD', 12.37652824616518)
('reviews.review', 12.37652824616518)
('Hearst', 12.37652824616518)
('Burstein', 12.37652824616518)
('qual_udf', 12.37652824616518)
('Segmenter', 12.37652824616518)
('review_feats', 12.37652824616518)
('Crowdsourced', 12.37652824616518)
('WindowDiff', 12.37652824616518)
('Polyzotis', 12.37652824616518)
('Purple', 12.37652824616518)
('qualreview', 12.37652824616518)
('free-form', 12.37652824616518)
('|p|2', 12.37652824616518)
('interfaces.js', 12.37652824616518)
('Readability/Grammar', 12.37652824616518)
('Mudambi', 12.37652824616518)
('Packt', 12.37652824616518)
('text=', 12.37652824616518)
('autocomplete', 12.37652824616518)
('Residents', 12.37652824616518)
('1.9x', 12.37652824616518)
('up-votes', 12.37652824616518)
('McAuley', 12.37652824616518)
('Aji', 12.37652824616518)
('Coleman-Liau', 12.37652824616518)
('Indirect', 12.37652824616518)
('topically', 12.37652824616518)
('Done', 12.37652824616518)
('data-quality', 12.37652824616518)
('tenants', 12.37652824616518)
('Kulik', 12.37652824616518)
('youtube', 12.37652824616518)
('autoincrement', 12.37652824616518)
('Schuff', 12.37652824616518)
('AirBnb', 12.37652824616518)
('HIT', 12.37652824616518)
('airbnb', 12.37652824616518)
('crowd-sourced', 12.37652824616518)
('Reddit', 12.37652824616518)
('stats', 12.37652824616518)
('foreign-key', 12.37652824616518)
('Kraska', 12.37652824616518)
('SegmentPredict-Explain', 12.37652824616518)
('Topic', 12.332621592519935)
('Label', 12.332621592519935)
('reviewer', 12.332621592519935)
('spelling', 12.332621592519935)
('types', 12.084735175349207)
('Our', 12.084735175349207)
('M', 12.084735175349207)
('T.', 12.084735175349207)
('customization', 12.021999555697413)
('offline', 12.021999555697413)
('competence', 12.021999555697413)
('pi', 11.989476363991853)
('depicts', 11.982929094215963)
('approach', 11.78350206951907)
('P.', 11.78350206951907)
('I', 11.78350206951907)
('portions', 11.777755916665761)
('highlighted', 11.777755916665761)
('errors', 11.675460894331879)
('55', 11.675460894331879)
('online', 11.675460894331879)
('textual', 11.561487031584658)
('randomly', 11.51292546497023)
('collected', 11.51292546497023)
('Linguistic', 11.419987469310959)
('workflow', 11.419987469310959)
('Overall', 11.332853376224865)
('evaluate', 11.266065387038703)
('budget', 11.140716200112923)
('Tan', 11.140716200112923)
('Franklin', 11.140716200112923)
('G.', 11.090354888959125)
('syntactic', 11.090354888959125)
('grammar', 11.090354888959125)
('focus', 11.090354888959125)
('5', 11.090354888959125)
('simple', 11.090354888959125)
('subset', 11.090354888959125)
('well', 11.090354888959125)
('UIST', 10.994336450586404)
('Minority', 10.994336450586404)
('Rudin', 10.994336450586404)
('Segment', 10.994336450586404)
('Try', 10.994336450586404)
('angry', 10.994336450586404)
('Crowdsourcing', 10.994336450586404)
('Blei', 10.994336450586404)
('7.2.1', 10.994336450586404)
('Explain', 10.994336450586404)
('Likert', 10.994336450586404)
('prescribe', 10.994336450586404)
('female', 10.994336450586404)
('reducing', 10.986122886681098)
('records', 10.986122886681098)
('message', 10.986122886681098)
('N.', 10.986122886681098)
('design', 10.986122886681098)
('Problem', 10.986122886681098)
('conditions', 10.986122886681098)
('peer', 10.912758479179157)
('Zheng', 10.912758479179157)
('Marcus', 10.912758479179157)
('window', 10.83220080440884)
('specifications', 10.83220080440884)
('47', 10.75055681536833)
('sample', 10.75055681536833)
('VLDB', 10.666044184468241)
('Reviews', 10.666044184468241)
('WWW', 10.666044184468241)
('unclear', 10.666044184468241)
('mining', 10.556229318461034)
('splits', 10.489522684399441)
('90', 10.39720770839918)
('0', 10.39720770839918)
('61', 10.39720770839918)
('To', 10.39720770839918)
('value', 10.39720770839918)
('arg', 10.30196161345544)
('plots', 10.30196161345544)
('https', 10.259797429846147)
('bias', 10.259797429846147)
('79', 10.259797429846147)
('user-generated', 10.187500401613525)
('content-specific', 10.187500401613525)
('edits', 10.187500401613525)
('end-to-end', 10.187500401613525)
('Subjective', 10.187500401613525)
('ages', 10.187500401613525)
('recruited', 10.187500401613525)
('emphasizes', 9.996613530525611)
('95', 9.939626599152001)
('p2', 9.939626599152001)
('collect', 9.939626599152001)
('research', 9.887510598012987)
('algorithm', 9.887510598012987)
('2012', 9.887510598012987)
('length', 9.887510598012987)
('TABLE', 9.774289614064447)
('naive', 9.774289614064447)
('push', 9.774289614064447)
('Ma', 9.774289614064447)
('s.t', 9.774289614064447)
('Existing', 9.774289614064447)
('categories', 9.729550745276565)
('accuracy', 9.729550745276565)
('column', 9.729550745276565)
('provide', 9.704060527839234)
('L.', 9.704060527839234)
('order', 9.704060527839234)
('systems', 9.704060527839234)
('individual', 9.704060527839234)
('2014', 9.704060527839234)
('final', 9.704060527839234)
('define', 9.704060527839234)
('will', 9.704060527839234)
('database', 9.656627474604601)
('bound', 9.656627474604601)
('contrast', 9.656627474604601)
('targeted', 9.656627474604601)
('decision', 9.656627474604601)
('widget', 9.608042089466514)
('NAACL', 9.608042089466514)
('PVLDB', 9.608042089466514)
('augments', 9.608042089466514)
('Setup', 9.608042089466514)
('Karger', 9.608042089466514)
('male', 9.608042089466514)
('perturb', 9.608042089466514)
('Strongly', 9.608042089466514)
('mined', 9.608042089466514)
('asked', 9.591581091193483)
('dynamically', 9.591581091193483)
('67', 9.591581091193483)
('84', 9.591581091193483)
('2017', 9.534161491043838)
('Automated', 9.534161491043838)
('submitted', 9.210340371976184)
('downstream', 9.169934957341145)
('sliding', 9.169934957341145)
('Store', 9.169934957341145)
('EC', 9.169934957341145)
('trains', 9.169934957341145)
('Boyd', 9.169934957341145)
('python', 9.169934957341145)
('Cao', 9.169934957341145)
('Segmentation', 9.169934957341145)
('leverages', 9.169934957341145)
('Document', 9.13356731317027)
('first', 9.010913347279288)
('3', 9.010913347279288)
('number', 9.010913347279288)
('system', 9.010913347279288)
('supports', 8.958797346140274)
('challenges', 8.958797346140274)
('express', 8.958797346140274)
('error', 8.958797346140274)
('id', 8.83331693749932)
('Survey', 8.83331693749932)
('boolean', 8.83331693749932)
('assess', 8.83331693749932)
('Improvement', 8.813438494528507)
('categorize', 8.813438494528507)
('inclusive', 8.813438494528507)
('open-ended', 8.813438494528507)
('Classifier', 8.813438494528507)
('prospective', 8.813438494528507)
('TF-IDF', 8.813438494528507)
('four', 8.788898309344878)
('Wang', 8.788898309344878)
('techniques', 8.788898309344878)
('bottom', 8.788898309344878)
('level', 8.788898309344878)
('62', 8.788898309344878)
('majority', 8.788898309344878)
('simply', 8.788898309344878)
('p1', 8.788898309344878)
('application', 8.788898309344878)
('generated', 8.788898309344878)
('related', 8.788898309344878)
('category', 8.788898309344878)
('computes', 8.788898309344878)
('fair', 8.671115273688493)
('dominant', 8.671115273688493)
('skills', 8.49964003216865)
('assessment', 8.49964003216865)
('92', 8.49964003216865)
('perceived', 8.49964003216865)
('comment', 8.49964003216865)
('rated', 8.496990484098719)
('Check', 8.496990484098719)
('Jr', 8.496990484098719)
('spam', 8.496990484098719)
('Developers', 8.496990484098719)
('sentiment', 8.496990484098719)
('semantic', 8.317766166719343)
('new', 8.317766166719343)
('estimate', 8.317766166719343)
('top', 8.317766166719343)
('detection', 8.317766166719343)
('amount', 8.317766166719343)
('completed', 8.317766166719343)
('q', 8.317766166719343)
('displayed', 8.317766166719343)
('2', 8.317766166719343)
('64', 8.317766166719343)
('assigns', 8.317766166719343)
('test', 8.317766166719343)
('evaluation', 8.317766166719343)
('component', 8.317766166719343)
('6', 8.317766166719343)
('reduce', 8.317766166719343)
('7', 8.317766166719343)
('entry', 8.317766166719343)
('agreement', 8.317766166719343)
('names', 8.317766166719343)
('collection', 8.317766166719343)
('2013', 8.317766166719343)
('problem', 8.317766166719343)
('contribute', 8.317766166719343)
('compared', 8.317766166719343)
('discount', 8.221747728346623)
('submitting', 8.221747728346623)
('Feng', 8.221747728346623)
('stars', 8.221747728346623)
('domain-specific', 8.221747728346623)
('emails', 8.221747728346623)
('summarize', 8.12415060330663)
('style', 8.12415060330663)
('predictions', 8.12415060330663)
('word', 8.047189562170502)
('human', 8.047189562170502)
('learning', 8.047189562170502)
('hard', 8.047189562170502)
('AND', 8.047189562170502)
('entire', 8.047189562170502)
('implement', 8.047189562170502)
('overall', 8.047189562170502)
('recommender', 8.014666370464942)
('pre', 8.014666370464942)
('Generator', 8.014666370464942)
('thresholds', 8.014666370464942)
('pressing', 8.014666370464942)
('hint', 8.014666370464942)
('Fp', 8.014666370464942)
('Bernstein', 8.014666370464942)
("user's", 8.014666370464942)
('FROM', 8.014666370464942)
('backend', 8.014666370464942)
('owned', 8.014666370464942)
('Get', 8.014666370464942)
('revise', 8.014666370464942)
('FOR', 7.917171988845775)
('speech', 7.917171988845775)
('86', 7.917171988845775)
('Li', 7.783640596221253)
('picking', 7.783640596221253)
('suggest', 7.783640596221253)
('grammatical', 7.783640596221253)
('1-7', 7.783640596221253)
('criteria', 7.783640596221253)
('specify', 7.783640596221253)
('acquiring', 7.783640596221253)
('novel', 7.783640596221253)
('proxy', 7.783640596221253)
('generating', 7.783640596221253)
('O.', 7.783640596221253)
('ACL', 7.783640596221253)
('suggests', 7.783640596221253)
('challenge', 7.783640596221253)
('ICDE', 7.783640596221253)
('constrain', 7.783640596221253)
('violation', 7.783640596221253)
('Interface', 7.694848072384611)
('change', 7.690286020676768)
('provides', 7.690286020676768)
('uses', 7.690286020676768)
('F.', 7.690286020676768)
('Finally', 7.690286020676768)
('H.', 7.6246189861593985)
('shown', 7.6246189861593985)
('10', 7.6246189861593985)
('payment', 7.613324979540639)
('SIGKDD', 7.613324979540639)
('76', 7.4547199493640015)
('77', 7.4547199493640015)
('73', 7.4547199493640015)
('71', 7.4547199493640015)
('complementary', 7.4547199493640015)
('81', 7.4547199493640015)
('fine-grained', 7.427144133408616)
('refine', 7.427144133408616)
('Ng', 7.427144133408616)
('bind', 7.427144133408616)
('Jordan', 7.275172319452771)
('AAAI', 7.275172319452771)
('Zhao', 7.275172319452771)
('Constraints', 7.275172319452771)
('violates', 7.275172319452771)
('Acquisition', 7.275172319452771)
('Cost', 7.275172319452771)
('labeled', 7.193685818395112)
('automated', 7.193685818395112)
('83', 7.193685818395112)
('report', 7.16703787691222)
('ensure', 7.16703787691222)
('management', 7.16703787691222)
('submit', 7.110696122978827)
('categorical', 7.110696122978827)
('Writing', 7.110696122978827)
('surveyed', 7.110696122978827)
('learns', 7.110696122978827)
('ambiguous', 7.110696122978827)
("'m", 6.9930151229329605)
('Prediction', 6.9930151229329605)
('collects', 6.9930151229329605)
('scan', 6.9930151229329605)
('button', 6.9930151229329605)
('depict', 6.9930151229329605)
('changes', 6.931471805599453)
('Table', 6.931471805599453)
('three', 6.931471805599453)
('address', 6.931471805599453)
('increase', 6.931471805599453)
('8', 6.931471805599453)
('point', 6.931471805599453)
('defines', 6.931471805599453)
('also', 6.931471805599453)
('combining', 6.907755278982138)
('75', 6.907755278982138)
('scoring', 6.8679744089702925)
('asking', 6.8679744089702925)
('Similarity', 6.8679744089702925)
('contributors', 6.8679744089702925)
('int', 6.8679744089702925)
('complements', 6.734591659972948)
('wrote', 6.734591659972948)
('recommend', 6.664409020350408)
('latency', 6.664409020350408)
('250', 6.664409020350408)
('asks', 6.664409020350408)
('competitive', 6.664409020350408)
('similarity', 6.591673732008658)
('extent', 6.591673732008658)
('along', 6.591673732008658)
('directly', 6.591673732008658)
('Each', 6.591673732008658)
('63', 6.591673732008658)
('takes', 6.591673732008658)
('rather', 6.591673732008658)
('X.', 6.591673732008658)
('least', 6.591673732008658)
('common', 6.591673732008658)
('exponential', 6.591673732008658)
('32', 6.591673732008658)
('write', 6.591673732008658)
('tests', 6.591673732008658)
('Thus', 6.591673732008658)
('granularity', 6.516193076042964)
('Qi', 6.516193076042964)
('validate', 6.516193076042964)
('Further', 6.437751649736401)
('typical', 6.437751649736401)
('60', 6.437751649736401)
('minimum', 6.437751649736401)
('generation', 6.437751649736401)
('Han', 6.437751649736401)
('Fan', 6.437751649736401)
('levels', 6.437751649736401)
('identified', 6.437751649736401)
('providing', 6.437751649736401)
('q0', 6.437751649736401)
('increases', 6.437751649736401)
('0.05', 6.3561076606958915)
('Hu', 6.3561076606958915)
('examining', 6.3561076606958915)
('Media', 6.3561076606958915)
('vs', 6.3561076606958915)
('noisy', 6.3561076606958915)
('statistically', 6.270988431858299)
('informed', 6.270988431858299)
('psychology', 6.270988431858299)
('WORK', 6.270988431858299)
('infer', 6.270988431858299)
('must', 6.238324625039508)
('one', 6.238324625039508)
('different', 6.238324625039508)
('form', 6.238324625039508)
('This', 6.238324625039508)
('present', 6.238324625039508)
('However', 6.238324625039508)
('contribution', 6.238324625039507)
('numerical', 6.238324625039507)
('56', 6.238324625039507)
('refers', 6.238324625039507)
('helps', 6.238324625039507)
('naturally', 6.238324625039507)
('between-subjects', 6.18826412308259)
('EXPLAIN', 6.18826412308259)
('Human-powered', 6.18826412308259)
('micro-blog', 6.18826412308259)
('consolidates', 6.18826412308259)
('undercover', 6.18826412308259)
('Document-level', 6.18826412308259)
('Agichtein', 6.18826412308259)
('nodeId=201929730', 6.18826412308259)
('ReactJS', 6.18826412308259)
('FoxType', 6.18826412308259)
('iCrowd', 6.18826412308259)
('71.3', 6.18826412308259)
('A~s', 6.18826412308259)
('Intuition', 6.18826412308259)
('feature-oriented', 6.18826412308259)
('-uf', 6.18826412308259)
('Texttiling', 6.18826412308259)
('21,26,22,23', 6.18826412308259)
('quora.com/What-percentageof-questions-on-Quora-have-no-answers', 6.18826412308259)
('=8.2', 6.18826412308259)
('Argonaut', 6.18826412308259)
('10/hr', 6.18826412308259)
('len=10', 6.18826412308259)
('users.age', 6.18826412308259)
('Koedinger', 6.18826412308259)
('SNAM', 6.18826412308259)
('pre-populated', 6.18826412308259)
('Pennebaker', 6.18826412308259)
('3.9x', 6.18826412308259)
('Crowd-based', 6.18826412308259)
('Joglekar', 6.18826412308259)
('hand-segmented', 6.18826412308259)
('HICSS', 6.18826412308259)
('shopper', 6.18826412308259)
('Ackerman', 6.18826412308259)
('single-feature', 6.18826412308259)
('Seg+Krause', 6.18826412308259)
('boostrap', 6.18826412308259)
('Somasundaran', 6.18826412308259)
('yelp.com/guidelines', 6.18826412308259)
('Elhadad', 6.18826412308259)
('Soylent', 6.18826412308259)
('//www.imdb.com/title/tt0181689/', 6.18826412308259)
('maxv', 6.18826412308259)
('C.-Y', 6.18826412308259)
('Boomerang', 6.18826412308259)
('Farra', 6.18826412308259)
('amazon', 6.18826412308259)
('err=None', 6.18826412308259)
('Deco', 6.18826412308259)
('lowquality', 6.18826412308259)
('Niculae', 6.18826412308259)
('Perer', 6.18826412308259)
('Crowddb', 6.18826412308259)
('wikipedia', 6.18826412308259)
('//www.amazon.com/gp/help/customer/display', 6.18826412308259)
('Low-quality', 6.18826412308259)
('reddit', 6.18826412308259)
('precogs', 6.18826412308259)
('Panovich', 6.18826412308259)
('Madnani', 6.18826412308259)
('information/not', 6.18826412308259)
('Muchnik', 6.18826412308259)
('+15', 6.18826412308259)
('S.-M.', 6.18826412308259)
('Apriori', 6.18826412308259)
('Tourangeau', 6.18826412308259)
('Incentive', 6.18826412308259)
('exp_func', 6.18826412308259)
('38.8', 6.18826412308259)
('Smus', 6.18826412308259)
('Snormdfi', 6.18826412308259)
('Kossmann', 6.18826412308259)
('topk', 6.18826412308259)
('multi-method', 6.18826412308259)
('applicationdependent', 6.18826412308259)
('topK', 6.18826412308259)
('2|F', 6.18826412308259)
('Policies_and_guidelines', 6.18826412308259)
('buyers', 6.18826412308259)
('Bosu', 6.18826412308259)
('Deriving', 6.18826412308259)
('hay', 6.18826412308259)
('customizations', 6.18826412308259)
('Minqing', 6.18826412308259)
('pre-submission', 6.18826412308259)
('2.6x', 6.18826412308259)
('perturbation-based', 6.18826412308259)
('Recompute', 6.18826412308259)
('deception', 6.18826412308259)
('Amatriain', 6.18826412308259)
('Ustun', 6.18826412308259)
('Automating', 6.18826412308259)
('Hyona', 6.18826412308259)
('Couper', 6.18826412308259)
('3-20', 6.18826412308259)
('obfuscation', 6.18826412308259)
('qik', 6.18826412308259)
('Gionis', 6.18826412308259)
('71.1', 6.18826412308259)
('Nejdl', 6.18826412308259)
('webserver', 6.18826412308259)
('qi1', 6.18826412308259)
('Archak', 6.18826412308259)
(':15-24', 6.18826412308259)
('reviews.rating', 6.18826412308259)
('23,60', 6.18826412308259)
('hovers', 6.18826412308259)
('pre-segmented', 6.18826412308259)
('AskScience', 6.18826412308259)
('gold-standard', 6.18826412308259)
('Snormdi', 6.18826412308259)
('QASCA', 6.18826412308259)
('crowdsources', 6.18826412308259)
('Rubric', 6.18826412308259)
('Crowell', 6.18826412308259)
('Host-Profile', 6.18826412308259)
("Precog's", 6.18826412308259)
('Heaton', 6.18826412308259)
('Loria', 6.18826412308259)
('valn', 6.18826412308259)
('filtering/ranking', 6.18826412308259)
('Rivers', 6.18826412308259)
('Donato', 6.18826412308259)
('ICITS', 6.18826412308259)
('flavors', 6.18826412308259)
('fuction', 6.18826412308259)
('MindTrek', 6.18826412308259)
('crazy', 6.18826412308259)
('Sfd', 6.18826412308259)
('//cudbg.github.io/Dialectic', 6.18826412308259)
('re-asking', 6.18826412308259)
('emotional/biased', 6.18826412308259)
('//www.nfcworld.com/nfc-phones-list/', 6.18826412308259)
('Connors', 6.18826412308259)
('Morton', 6.18826412308259)
('auto-complete', 6.18826412308259)
('e-rater', 6.18826412308259)
('feats', 6.18826412308259)
('Kaakinen', 6.18826412308259)
('Verdines', 6.18826412308259)
('support.office.com', 6.18826412308259)
('segment-predict-explain', 6.18826412308259)
('0.055', 6.18826412308259)
('x1=', 6.18826412308259)
('Milo', 6.18826412308259)
('Segment-PredictExplain', 6.18826412308259)
('4,25,58,89', 6.18826412308259)
('product_exp', 6.18826412308259)
('gamification', 6.18826412308259)
('zappos', 6.18826412308259)
('Gunning', 6.18826412308259)
('Mishne', 6.18826412308259)
('shoppers', 6.18826412308259)
('PRECOG', 6.18826412308259)
('Submit', 6.18826412308259)
('Cappe', 6.18826412308259)
('subtopic', 6.18826412308259)
('nuanced', 6.18826412308259)
('Boim', 6.18826412308259)
('Forensic', 6.18826412308259)
('users_age_domain', 6.18826412308259)
('Vader', 6.18826412308259)
('Supersparse', 6.18826412308259)
('121-128', 6.18826412308259)
('9,12,24,29,39,80,98', 6.18826412308259)
('HSD', 6.18826412308259)
('Self-disclosure', 6.18826412308259)
('Cucchiarelli', 6.18826412308259)
('readmission', 6.18826412308259)
('Chklovski', 6.18826412308259)
('obfuscates', 6.18826412308259)
('Markowitz', 6.18826412308259)
('INFORMS', 6.18826412308259)
('Trushkowsky', 6.18826412308259)
('Karrer', 6.18826412308259)
('gamefulness', 6.18826412308259)
('Guyon', 6.18826412308259)
('posthoc', 6.18826412308259)
('Segmenting', 6.18826412308259)
('Biran', 6.18826412308259)
('|Dij', 6.18826412308259)
('2.4x', 6.18826412308259)
('Chelaru', 6.18826412308259)
('Pantel', 6.18826412308259)
('multi-attribute', 6.18826412308259)
('renters', 6.18826412308259)
('=33', 6.18826412308259)
('=32', 6.18826412308259)
('suggest_new_prod_feats', 6.18826412308259)
('SEGMENT-PREDICT-EXPLAIN', 6.18826412308259)
('emotion=30', 6.18826412308259)
('PREDICT', 6.18826412308259)
('expository', 6.18826412308259)
('high-concentration', 6.18826412308259)
('ANOVAs', 6.18826412308259)
('Danescu-Niculescu-Mizil', 6.18826412308259)
('reallocating', 6.18826412308259)
('~si', 6.18826412308259)
('non-authors', 6.18826412308259)
('13.6/hr', 6.18826412308259)
('post-study', 6.18826412308259)
('accuracy6', 6.18826412308259)
('Unanswered', 6.18826412308259)
('6=0', 6.18826412308259)
('substitutable', 6.18826412308259)
('Disagree', 6.18826412308259)
('Ouzzani', 6.18826412308259)
('72.5', 6.18826412308259)
('1021-0', 6.18826412308259)
('Verroios', 6.18826412308259)
('diatribe', 6.18826412308259)
(':435-445', 6.18826412308259)
('Scale-driven', 6.18826412308259)
('React', 6.18826412308259)
('AutoML', 6.18826412308259)
('library4', 6.18826412308259)
('fraudulent', 6.18826412308259)
('curate', 6.18826412308259)
('Bakshy', 6.18826412308259)
('rfk/pyenchant', 6.18826412308259)
('7.1x', 6.18826412308259)
('58.7', 6.18826412308259)
('unique_exp', 6.18826412308259)
('non-continuous', 6.18826412308259)
('Letham', 6.18826412308259)
('per-feature', 6.18826412308259)
('val1', 6.18826412308259)
("application's", 6.18826412308259)
('Chittilappilly', 6.18826412308259)
('Misra', 6.18826412308259)
('code-reviews', 6.18826412308259)
('psychometric', 6.18826412308259)
('CrowdFill', 6.18826412308259)
('Doc+Krause', 6.18826412308259)
('Solar-Lezama', 6.18826412308259)
('REF', 6.18826412308259)
('Valenti', 6.18826412308259)
('behind-the-enemy-lines.com/2011/04/want-to-improvesales-fix-grammar-and.html', 6.18826412308259)
('non-crowdsourced', 6.18826412308259)
('RecSys', 6.18826412308259)
('Siersdorfer', 6.18826412308259)
('Sf', 6.18826412308259)
('Chatterji', 6.18826412308259)
('categorizing', 6.18826412308259)
('Coder', 6.18826412308259)
('Textblob', 6.18826412308259)
('//www.reddit.com/r/askscience/', 6.18826412308259)
('Doc', 6.18826412308259)
('segment-specific', 6.18826412308259)
('reclassify', 6.18826412308259)
('Neri', 6.18826412308259)
('Segment-level', 6.18826412308259)
("feature's", 6.18826412308259)
('constraint3', 6.18826412308259)
('Barnhill', 6.18826412308259)
('predator', 6.18826412308259)
('it2', 6.18826412308259)
('rant', 6.18826412308259)
('pre-acquisition', 6.18826412308259)
('Crowdforge', 6.18826412308259)
('amazon.com', 6.18826412308259)
('re-ordering', 6.18826412308259)
('IRB', 6.18826412308259)
('foxtype.com/', 6.18826412308259)
('mis-', 6.18826412308259)
('institutionalization', 6.18826412308259)
('utility7', 6.18826412308259)
('Spirin', 6.18826412308259)
('Aral', 6.18826412308259)
('Savings', 6.18826412308259)
('Papotti', 6.18826412308259)
('maxiao.info', 6.18826412308259)
('Khamkar', 6.18826412308259)
('445-456', 6.18826412308259)
('-15.', 6.18826412308259)
('Off-Topic', 6.18826412308259)
('Im11', 6.18826412308259)
('Klemmer', 6.18826412308259)
('|Fe', 6.18826412308259)
('Peerstudio', 6.18826412308259)
('javascript', 6.18826412308259)
('documentlevel', 6.18826412308259)
('//www.zappos.com/premier-reviewers', 6.18826412308259)
('Whang', 6.18826412308259)
('Product-Review', 6.18826412308259)
('quarterly', 6.18826412308259)
('Ji-Wei', 6.18826412308259)
('click/participant', 6.18826412308259)
('//textblob.readthedocs.io/en/dev', 6.18826412308259)
('Mcauliffe', 6.18826412308259)
('Gulwani', 6.18826412308259)
('~e', 6.18826412308259)
('SMOG', 6.18826412308259)
('Nacke', 6.18826412308259)
('en.wikipedia.org/wiki/Wikipedia', 6.18826412308259)
('WSDM', 6.18826412308259)
('UNIQUE', 6.18826412308259)
('wikipedians', 6.18826412308259)
('HCOMP', 6.18826412308259)
('Whom', 6.18826412308259)
('Precog-provided', 6.18826412308259)
('pre-written', 6.18826412308259)
('ufi', 6.18826412308259)
('7,49,50', 6.18826412308259)
("worker's", 6.18826412308259)
('Kozlowski', 6.18826412308259)
('liwc2015', 6.18826412308259)
('Cruise', 6.18826412308259)
('Ansel', 6.18826412308259)
('reviews_rating_domain', 6.18826412308259)
('CONSTRAINT', 6.18826412308259)
('features/jargon', 6.18826412308259)
('indecipherable', 6.18826412308259)
('41.3', 6.18826412308259)
('Greenshpan', 6.18826412308259)
('Mingjie', 6.18826412308259)
('Pandey', 6.18826412308259)
('Yvon', 6.18826412308259)
('hovered', 6.18826412308259)
('auto-graders', 6.18826412308259)
('Neeraj', 6.18826412308259)
('Y.-D.', 6.18826412308259)
('Exchanges', 6.18826412308259)
('stackoverflow', 6.18826412308259)
('Lepkowski', 6.18826412308259)
('User-facing', 6.18826412308259)
('Drouin', 6.18826412308259)
('FOREIGN', 6.18826412308259)
('Camera', 6.18826412308259)
('Seg+TCruise', 6.18826412308259)
('dataquality', 6.18826412308259)
('good-faith', 6.18826412308259)
('Kittur', 6.18826412308259)
('Quora', 6.18826412308259)
('presidents', 6.18826412308259)
('Naaman', 6.18826412308259)
('notEnoughDetail', 6.18826412308259)
('key=topic.prob', 6.18826412308259)
('segmenters', 6.18826412308259)
('perturbe', 6.18826412308259)
('61.2', 6.18826412308259)
('perturbs', 6.18826412308259)
('Novgorodov', 6.18826412308259)
('subreddit5', 6.18826412308259)
('SCORE', 6.18826412308259)
('InfoLab', 6.18826412308259)
('badges', 6.18826412308259)
('AirbnB', 6.18826412308259)
('docs', 6.18826412308259)
('69.5', 6.18826412308259)
('SIGecom', 6.18826412308259)
('|yk', 6.18826412308259)
('quality-aware', 6.18826412308259)
('nfc', 6.18826412308259)
('=8.5', 6.18826412308259)
('\\w+', 6.18826412308259)
('macrotask', 6.18826412308259)
('Integrity-for', 6.18826412308259)
('72,87,91', 6.18826412308259)
('document-quality', 6.18826412308259)
('Schunn', 6.18826412308259)
("host's", 6.18826412308259)
('offTopic', 6.18826412308259)
("d's", 6.18826412308259)
('documents-using', 6.18826412308259)
('provement', 6.18826412308259)
('topic-based', 6.18826412308259)
('crowdbased', 6.18826412308259)
('sfi', 6.18826412308259)
('1|vij', 6.18826412308259)
('Precog1', 6.18826412308259)
('atypical', 6.18826412308259)
('Pennacchiotti', 6.18826412308259)
('Seg', 6.18826412308259)
('user-created', 6.18826412308259)
('up/down', 6.18826412308259)
('buyer', 6.18826412308259)
('topic-level', 6.18826412308259)
('window-based', 6.18826412308259)
('support.google.com/docs/answer/57859', 6.18826412308259)
('Rivadeneira', 6.18826412308259)
('Fayers', 6.18826412308259)
('Respondable', 6.18826412308259)
('Flesch', 6.18826412308259)
('44th', 6.18826412308259)
('Deterding', 6.18826412308259)
('DOMAINS', 6.18826412308259)
('Tukey', 6.18826412308259)
('Fedosejev', 6.18826412308259)
('Chalamalla', 6.18826412308259)
('data-collection', 6.18826412308259)
('//www.boomeranggmail.com/respondable/', 6.18826412308259)
('20-65', 6.18826412308259)
('20-62', 6.18826412308259)
('reclassified', 6.18826412308259)
('factual', 6.18826412308259)
('Sturm', 6.18826412308259)
('generic/static', 6.18826412308259)
('R|F|', 6.18826412308259)
('cream', 6.18826412308259)
('1-0', 6.18826412308259)
('Groves', 6.18826412308259)
('TextTiling', 6.18826412308259)
('ARI', 6.18826412308259)
('breaker', 6.18826412308259)
('Murry', 6.18826412308259)
('Trishala', 6.18826412308259)
('rubrics', 6.18826412308259)
('prefeedback', 6.18826412308259)
('Corley', 6.18826412308259)
('McCormick', 6.18826412308259)
('Mohanlal', 6.18826412308259)
('Topictiling', 6.18826412308259)
('Lorch', 6.18826412308259)
('Madden', 6.18826412308259)
('labelers', 6.18826412308259)
('mislabeled', 6.18826412308259)
('MSR', 6.18826412308259)
('CIS', 6.18826412308259)
('Darwin', 6.18826412308259)
('30-day', 6.18826412308259)
('helpful/unhelpful', 6.18826412308259)
('informativeness', 6.18826412308259)
('Amer-Yahia', 6.18826412308259)
('Spielberg', 6.18826412308259)
('topic_extractor', 6.18826412308259)
('Contributor', 6.18826412308259)
('Singh', 6.182084906716632)
('green', 6.089044875446846)
('resolve', 6.089044875446846)
('Below', 6.089044875446846)
('maximize', 6.089044875446846)
('regression', 6.089044875446846)
('extensible', 5.991464547107982)
('Linguistics', 5.991464547107982)
('Park', 5.991464547107982)
('Miller', 5.991464547107982)
('Reading', 5.991464547107982)
('Psychology', 5.991464547107982)
('blue', 5.8888779583328805)
('Mining', 5.8888779583328805)
('individually', 5.8888779583328805)
('displays', 5.8888779583328805)
('Kim', 5.8888779583328805)
('completion', 5.8888779583328805)
('54', 5.8377304471659395)
('52', 5.8377304471659395)
('commonly', 5.8377304471659395)
('Chen', 5.8377304471659395)
('applicable', 5.8377304471659395)
('select', 5.8377304471659395)
('MIT', 5.8377304471659395)
('services', 5.8377304471659395)
('80', 5.8377304471659395)
('48', 5.8377304471659395)
('93', 5.780743515792329)
('Feature', 5.780743515792329)
('Rather', 5.666426688112432)
('comparisons', 5.666426688112432)
('Wu', 5.666426688112432)
('heuristic', 5.666426688112432)
('pairwise', 5.666426688112432)
('aggregate', 5.666426688112432)
('subjective', 5.666426688112432)
('diversity', 5.666426688112432)
('compares', 5.666426688112432)
('extend', 5.545177444479562)
('technique', 5.545177444479562)
('These', 5.545177444479562)
('values', 5.545177444479562)
('efficient', 5.545177444479562)
('pages', 5.545177444479562)
('show', 5.545177444479562)
('enough', 5.545177444479562)
('E.', 5.545177444479562)
('information', 5.545177444479562)
('35', 5.545177444479562)
('train', 5.545177444479562)
('C', 5.545177444479562)
('i.e.', 5.545177444479562)
('1,2,3,4', 5.497168225293202)
('Harvey', 5.497168225293202)
('generalizability', 5.497168225293202)
('Adamic', 5.497168225293202)
('Kraut', 5.497168225293202)
('Two-Way', 5.497168225293202)
('Attali', 5.497168225293202)
('assesses', 5.497168225293202)
('one-hot', 5.497168225293202)
('Castillo', 5.497168225293202)
('NAME', 5.497168225293202)
('professionally', 5.497168225293202)
('valence', 5.497168225293202)
('Interpretable', 5.497168225293202)
('ice', 5.497168225293202)
('QUALITY', 5.497168225293202)
('Psychiatry', 5.497168225293202)
('Cahill', 5.497168225293202)
('Enough', 5.497168225293202)
('Agree', 5.497168225293202)
('persuasion', 5.497168225293202)
('C.-L.', 5.497168225293202)
('Rakesh', 5.497168225293202)
('js', 5.497168225293202)
('Carver', 5.497168225293202)
('Dick', 5.497168225293202)
('Hartmann', 5.497168225293202)
('Choudhury', 5.497168225293202)
('Latent', 5.497168225293202)
('Picking', 5.497168225293202)
('polarity', 5.497168225293202)
('adjectives', 5.497168225293202)
('Leskovec', 5.497168225293202)
('summarization', 5.497168225293202)
('passages', 5.497168225293202)
('Asking', 5.497168225293202)
('obligated', 5.497168225293202)
('pneumonia', 5.497168225293202)
('accuracies', 5.497168225293202)
('Responsibility', 5.497168225293202)
('Essentials', 5.497168225293202)
('sex', 5.497168225293202)
('jury', 5.497168225293202)
('Weblogs', 5.497168225293202)
('func', 5.497168225293202)
('pre-compute', 5.497168225293202)
('evaluators', 5.497168225293202)
('antecedents', 5.497168225293202)
('15.3', 5.497168225293202)
('lda', 5.497168225293202)
('competitively', 5.497168225293202)
('ill-defined', 5.497168225293202)
('Sarkar', 5.497168225293202)
('Pevzner', 5.497168225293202)
('Khaled', 5.497168225293202)
('Tt', 5.497168225293202)
('recruitment', 5.497168225293202)
('Biemann', 5.497168225293202)
('Recommending', 5.497168225293202)
('narratives', 5.497168225293202)
('customizing', 5.497168225293202)
('McKeown', 5.497168225293202)
('Ilyas', 5.497168225293202)
('inputted', 5.497168225293202)
('dirichlet', 5.497168225293202)
('slider', 5.497168225293202)
('EMNLP-CoNLL', 5.497168225293202)
('1-21', 5.497168225293202)
('bed', 5.497168225293202)
('Pushing', 5.497168225293202)
('CDF', 5.497168225293202)
('ETS', 5.497168225293202)
('Rmxn', 5.497168225293202)
('textbox', 5.497168225293202)
('submits', 5.497168225293202)
('561', 5.497168225293202)
('whose', 5.493061443340549)
('solution', 5.493061443340549)
('study', 5.493061443340549)
('algorithms', 5.493061443340549)
('already', 5.493061443340549)
('complex', 5.493061443340549)
('support', 5.493061443340549)
('multiple', 5.493061443340549)
('W.', 5.493061443340549)
('Note', 5.493061443340549)
('contains', 5.493061443340549)
('easily', 5.493061443340549)
('2010', 5.493061443340549)
('addition', 5.493061443340549)
('thus', 5.493061443340549)
('additional', 5.493061443340549)
('91', 5.41610040220442)
('sentence', 5.41610040220442)
('tuples', 5.41610040220442)
('sentences', 5.41610040220442)
('insight', 5.41610040220442)
('US', 5.41610040220442)
('49', 5.375278407684165)
('suggested', 5.375278407684165)
('learn', 5.375278407684165)
('statement', 5.375278407684165)
('optimization', 5.375278407684165)
('popular', 5.375278407684165)
('selection', 5.375278407684165)
('usage', 5.375278407684165)
('entropy', 5.278114659230517)
('97', 5.278114659230517)
('filter', 5.278114659230517)
('ultimately', 5.278114659230517)
('inserted', 5.278114659230517)
('poor', 5.278114659230517)
('optimize', 5.278114659230517)
('setup', 5.1298987149230735)
('Building', 5.1298987149230735)
('96', 5.1298987149230735)
('norm', 5.1298987149230735)
('returned', 5.1298987149230735)
('communities', 5.1298987149230735)
('74', 5.1298987149230735)
('expert', 5.1298987149230735)
('cell', 5.1298987149230735)
('89', 5.1298987149230735)
('red', 5.1298987149230735)
('incentives', 5.093750200806762)
('defer', 5.093750200806762)
('top-k', 5.093750200806762)
('fixation', 5.093750200806762)
('topical', 5.093750200806762)
('Vapnik', 5.093750200806762)
('Customized', 5.093750200806762)
('0.65', 5.093750200806762)
('stings', 5.093750200806762)
('Segments', 5.093750200806762)
('smarter', 5.093750200806762)
('groundwork', 5.093750200806762)
('turk', 5.093750200806762)
('Sarma', 5.093750200806762)
('borrow', 5.093750200806762)
('cancer', 5.093750200806762)
('11.1', 5.093750200806762)
('Fully', 5.093750200806762)
('Madigan', 5.093750200806762)
('Worker', 5.093750200806762)
('Dixon', 5.093750200806762)
('Saving', 5.093750200806762)
('parsimonious', 5.093750200806762)
('Intelligible', 5.093750200806762)
('naively', 5.093750200806762)
('transcripts', 5.093750200806762)
('Sheng', 5.093750200806762)
('google', 5.093750200806762)
('subjectively', 5.093750200806762)
('Fowler', 5.093750200806762)
('pretend', 5.093750200806762)
('Explaining', 5.093750200806762)
('Blue', 5.093750200806762)
('MIS', 5.093750200806762)
('|pi', 5.093750200806762)
('agglomerative', 5.093750200806762)
('sf', 5.093750200806762)
('Lou', 5.093750200806762)
('prose', 5.093750200806762)
('Justification', 5.093750200806762)
('demographic', 5.093750200806762)
('Kraft', 5.093750200806762)
('user-defined', 5.093750200806762)
('housing', 5.093750200806762)
('L2', 4.969813299576001)
('took', 4.969813299576001)
('extensively', 4.969813299576001)
('challenging', 4.969813299576001)
('suggestions', 4.969813299576001)
('78', 4.969813299576001)
('88', 4.969813299576001)
('descriptions', 4.969813299576001)
('covered', 4.969813299576001)
('vs.', 4.969813299576001)
('dataset', 4.969813299576001)
('example', 4.852030263919617)
('possible', 4.852030263919617)
('take', 4.852030263919617)
('many', 4.852030263919617)
('showed', 4.828313737302301)
('compare', 4.828313737302301)
('Model', 4.828313737302301)
('explicit', 4.828313737302301)
('continuous', 4.828313737302301)
('maximum', 4.828313737302301)
('lack', 4.828313737302301)
('fully', 4.828313737302301)
('factors', 4.828313737302301)
('Based', 4.828313737302301)
('index', 4.828313737302301)
('37', 4.828313737302301)
('36', 4.828313737302301)
('Technical', 4.828313737302301)
('computed', 4.828313737302301)
('variety', 4.828313737302301)
('42', 4.828313737302301)
('hospital', 4.804021044733257)
("world's", 4.804021044733257)
('10.2', 4.804021044733257)
('mine', 4.804021044733257)
('told', 4.804021044733257)
('Controlled', 4.804021044733257)
('declarative', 4.804021044733257)
('subjectivity', 4.804021044733257)
('snippet', 4.804021044733257)
('finegrained', 4.804021044733257)
('JMLR', 4.804021044733257)
('Detail', 4.804021044733257)
('deployments', 4.804021044733257)
('Riedl', 4.804021044733257)
('Scoring', 4.804021044733257)
('agnostic', 4.804021044733257)
('ym', 4.804021044733257)
('mentally', 4.804021044733257)
('Saito', 4.804021044733257)
('Heuristic', 4.804021044733257)
('Haas', 4.804021044733257)
('non-technical', 4.804021044733257)
('~s', 4.804021044733257)
('approved', 4.804021044733257)
('black-box', 4.804021044733257)
('persuasive', 4.804021044733257)
('Publ.', 4.804021044733257)
('Ooi', 4.804021044733257)
('Caruana', 4.804021044733257)
('Automatically', 4.804021044733257)
('multi-stage', 4.804021044733257)
('sourcing', 4.804021044733257)
('ITS', 4.804021044733257)
('Guestrin', 4.804021044733257)
('surveying', 4.804021044733257)
('DVD', 4.804021044733257)
('outliers', 4.804021044733257)
('preposition', 4.804021044733257)
('desirable', 4.795790545596741)
('executed', 4.795790545596741)
('Lee', 4.795790545596741)
('fourth', 4.795790545596741)
('entity', 4.795790545596741)
('settings', 4.795790545596741)
('Specifically', 4.795790545596741)
('69', 4.795790545596741)
('costs', 4.795790545596741)
('accept', 4.795790545596741)
('modeled', 4.795790545596741)
('Online', 4.795790545596741)
('concrete', 4.795790545596741)
('sent', 4.795790545596741)
('selecting', 4.795790545596741)
('leaves', 4.795790545596741)
('rank', 4.605170185988092)
('rates', 4.605170185988092)
('quantitative', 4.605170185988092)
('distributions', 4.605170185988092)
('standards', 4.605170185988092)
('structured', 4.605170185988092)
('nearly', 4.605170185988092)
('66', 4.605170185988092)
('68', 4.605170185988092)
('relies', 4.605170185988092)
('decisions', 4.605170185988092)
('72', 4.605170185988092)
('extracted', 4.605170185988092)
('sort', 4.605170185988092)
('tuple', 4.605170185988092)
('hierarchical', 4.605170185988092)
('replication', 4.584967478670572)
('0.07', 4.584967478670572)
('corresponded', 4.584967478670572)
('Recommender', 4.584967478670572)
('0.14', 4.584967478670572)
('punctuation', 4.584967478670572)
('Fei', 4.584967478670572)
('Tong', 4.584967478670572)
('Gehrke', 4.584967478670572)
('Assigning', 4.584967478670572)
('Tseng', 4.584967478670572)
('Sage', 4.584967478670572)
('premier', 4.584967478670572)
('Weston', 4.584967478670572)
('tackling', 4.584967478670572)
('readings', 4.584967478670572)
('bayesian', 4.584967478670572)
('html', 4.584967478670572)
('overlapped', 4.584967478670572)
('Scores', 4.584967478670572)
('Singer', 4.584967478670572)
('Ramesh', 4.584967478670572)
('Labels', 4.584967478670572)
('EXPERIMENTS', 4.584967478670572)
('Hard', 4.584967478670572)
('Ultimately', 4.584967478670572)
('Ltd', 4.584967478670572)
('passwords', 4.584967478670572)
('cardinalities', 4.584967478670572)
('reputation', 4.584967478670572)
('Datasets', 4.584967478670572)
('AV', 4.584967478670572)
('3x', 4.584967478670572)
('-20', 4.584967478670572)
('APPLICATION', 4.584967478670572)
('Normalization', 4.584967478670572)
('crowds', 4.584967478670572)
('qualification', 4.584967478670572)
('synthesizing', 4.584967478670572)
('cached', 4.584967478670572)
('pronoun', 4.584967478670572)
('discounted', 4.584967478670572)
('CSCW', 4.584967478670572)
('hosts', 4.584967478670572)
('Ribeiro', 4.584967478670572)
('Kulkarni', 4.584967478670572)
('Procedures', 4.584967478670572)
('classifies', 4.406719247264253)
('game-theoretic', 4.406719247264253)
('INSERT', 4.406719247264253)
('envision', 4.406719247264253)
('Wisdom', 4.406719247264253)
('chat', 4.406719247264253)
('tail', 4.406719247264253)
('Interacting', 4.406719247264253)
('Kelly', 4.406719247264253)
('differed', 4.406719247264253)
('essays', 4.406719247264253)
('Xin', 4.406719247264253)
('writer', 4.406719247264253)
('Blackburn', 4.406719247264253)
('enhancements', 4.406719247264253)
('0.55', 4.406719247264253)
('Supervised', 4.406719247264253)
('Inferring', 4.406719247264253)
('artificially', 4.406719247264253)
('Assessing', 4.406719247264253)
('user-friendly', 4.406719247264253)
('buy', 4.406719247264253)
('Liu', 4.394449154672439)
('end', 4.394449154672439)
('better', 4.394449154672439)
('coding', 4.394449154672439)
('needed', 4.394449154672439)
('contents', 4.394449154672439)
('implementation', 4.394449154672439)
('V.', 4.394449154672439)
('unique', 4.394449154672439)
('59', 4.394449154672439)
('58', 4.394449154672439)
('useful', 4.394449154672439)
('predict', 4.394449154672439)
('still', 4.394449154672439)
('returns', 4.394449154672439)
('future', 4.394449154672439)
('examples', 4.394449154672439)
('Similar', 4.394449154672439)
('ways', 4.394449154672439)
('s', 4.394449154672439)
('I.', 4.394449154672439)
('components', 4.394449154672439)
('otherwise', 4.394449154672439)
('complete', 4.394449154672439)
('list', 4.394449154672439)
('small', 4.394449154672439)
('28', 4.394449154672439)
('good', 4.394449154672439)
('idea', 4.394449154672439)
('Elsevier', 4.394449154672439)
('interactive', 4.394449154672439)
('evaluating', 4.394449154672439)
('methods', 4.394449154672439)
('processing', 4.394449154672439)
('within', 4.394449154672439)
('ACM', 4.394449154672439)
('primarily', 4.394449154672439)
('long', 4.394449154672439)
('e', 4.394449154672439)
('2002', 4.394449154672439)
('focuses', 4.394449154672439)
('static', 4.394449154672439)
('Association', 4.394449154672439)
('written', 4.394449154672439)
('2007', 4.394449154672439)
('featured', 4.248495242049359)
('binds', 4.248495242049359)
('Eighth', 4.248495242049359)
('critique', 4.248495242049359)
('model-based', 4.248495242049359)
('marginally', 4.248495242049359)
('stroke', 4.248495242049359)
('Generic', 4.248495242049359)
('NEW', 4.248495242049359)
('Inquiry', 4.248495242049359)
('jth', 4.248495242049359)
('Advancement', 4.248495242049359)
('seamlessly', 4.248495242049359)
('Custom', 4.248495242049359)
('tolerate', 4.248495242049359)
('nouns', 4.248495242049359)
('pricing', 4.248495242049359)
('Norman', 4.248495242049359)
('CIKM', 4.248495242049359)
('evenly', 4.248495242049359)
('Ghosh', 4.248495242049359)
('optimistic', 4.248495242049359)
('Gill', 4.248495242049359)
('constructor', 4.248495242049359)
('populated', 4.248495242049359)
('automatic', 4.1588830833596715)
('highly', 4.1588830833596715)
('It', 4.1588830833596715)
('root', 4.1588830833596715)
('combination', 4.1588830833596715)
('mean', 4.1588830833596715)
('Consider', 4.1588830833596715)
('person', 4.1588830833596715)
('Given', 4.1588830833596715)
('left', 4.1588830833596715)
('rely', 4.1588830833596715)
('databases', 4.1588830833596715)
('time', 4.1588830833596715)
('studied', 4.1588830833596715)
('main', 4.1588830833596715)
('queries', 4.1588830833596715)
('performance', 4.1588830833596715)
('summary', 4.1588830833596715)
('reading', 4.1588830833596715)
('65', 4.1588830833596715)
('6=', 4.1588830833596715)
('binary', 4.1588830833596715)
('develop', 4.1588830833596715)
('extensive', 4.1588830833596715)
('identifying', 4.1588830833596715)
('No', 4.1588830833596715)
('sophisticated', 4.1588830833596715)
('detailed', 4.1588830833596715)
('consider', 4.1588830833596715)
('full', 4.1588830833596715)
('tested', 4.1588830833596715)
('states', 4.1588830833596715)
('What', 4.1588830833596715)
('instances', 4.1588830833596715)
('immediate', 4.1588830833596715)
('combinations', 4.1588830833596715)
('Furthermore', 4.1588830833596715)
('significant', 4.1588830833596715)
('similar', 4.1588830833596715)
('defined', 4.1588830833596715)
('An', 4.1588830833596715)
('illustrates', 4.1588830833596715)
('results', 4.1588830833596715)
('Library', 4.1588830833596715)
('explore', 4.1588830833596715)
('larger', 4.1588830833596715)
('34', 4.1588830833596715)
('performed', 4.1588830833596715)
('process', 4.1588830833596715)
('parts', 4.1588830833596715)
('add', 4.1588830833596715)
('40', 4.1588830833596715)
('elaborates', 4.110873864173311)
('Gene', 4.110873864173311)
('6.8', 4.110873864173311)
('Predicting', 4.110873864173311)
('efficacy', 4.110873864173311)
('Investigating', 4.110873864173311)
('Timing', 4.110873864173311)
('Winning', 4.110873864173311)
('Mechanisms', 4.110873864173311)
('Day', 4.110873864173311)
('supplemented', 4.110873864173311)
('verbal', 4.110873864173311)
('2x2', 4.110873864173311)
('Grammar', 4.110873864173311)
('Truth', 4.110873864173311)
('Hawaii', 4.110873864173311)
('renders', 4.110873864173311)
('Fe', 4.110873864173311)
('healthcare', 4.110873864173311)
('optionally', 4.110873864173311)
('rooms', 4.110873864173311)
('Pedro', 4.110873864173311)
('Gu', 4.007333185232471)
('incur', 4.007333185232471)
('ran', 4.007333185232471)
('dm', 4.007333185232471)
('Simplified', 4.007333185232471)
('Rapid', 4.007333185232471)
('clinical', 4.007333185232471)
('rule-based', 4.007333185232471)
('rationale', 4.007333185232471)
('SYSTEM', 4.007333185232471)
('sketches', 4.007333185232471)
('Gilbert', 4.007333185232471)
('Companies', 4.007333185232471)
('Conditions', 4.007333185232471)
('invalid', 4.007333185232471)
('click', 4.007333185232471)
('Count', 4.007333185232471)
('augment', 4.007333185232471)
('negatively', 4.007333185232471)
('enumerating', 4.007333185232471)
('familiarity', 4.007333185232471)
('acquires', 4.007333185232471)
('sales', 4.007333185232471)
('trials', 4.007333185232471)
('changed', 3.8918202981106265)
('Estimating', 3.8918202981106265)
('judged', 3.8918202981106265)
('modeling', 3.8918202981106265)
('background', 3.8918202981106265)
('53', 3.8918202981106265)
('trustworthy', 3.8918202981106265)
('transform', 3.8918202981106265)
('tie', 3.8918202981106265)
('5.2', 3.8918202981106265)
('mechanisms', 3.8918202981106265)
('metric', 3.8918202981106265)
('Psychological', 3.8918202981106265)
('references', 3.8918202981106265)
('duplicates', 3.8918202981106265)
('creates', 3.8918202981106265)
('intended', 3.8918202981106265)
('rejects', 3.8918202981106265)
('KEY', 3.8918202981106265)
('70', 3.8918202981106265)
('2.5', 3.8918202981106265)
('customers', 3.8918202981106265)
('Management', 3.8918202981106265)
('Little', 3.8918202981106265)
('Wiley', 3.8918202981106265)
('analyze', 3.8918202981106265)
('aggregates', 3.8918202981106265)
('composed', 3.8918202981106265)
('Guy', 3.8918202981106265)
('cause', 3.8918202981106265)
('integrated', 3.8918202981106265)
('Review', 3.8918202981106265)
('constituent', 3.8918202981106265)
('hypothesis', 3.8918202981106265)
('subsets', 3.8918202981106265)
('web', 3.8918202981106265)
('Upon', 3.8918202981106265)
('trigger', 3.8066624897703196)
('Culture', 3.8066624897703196)
('simplifying', 3.8066624897703196)
('Double', 3.8066624897703196)
('modifies', 3.8066624897703196)
('assistant', 3.8066624897703196)
('Fox', 3.8066624897703196)
('analyzes', 3.8066624897703196)
('stick', 3.8066624897703196)
('visualizing', 3.8066624897703196)
('in-depth', 3.8066624897703196)
('Koch', 3.8066624897703196)
('his/her', 3.713572066704308)
('clarification', 3.713572066704308)
('ej', 3.713572066704308)
('violated', 3.713572066704308)
('Extensive', 3.713572066704308)
('Please', 3.713572066704308)
('empirically', 3.713572066704308)
('FUTURE', 3.713572066704308)
('Yin', 3.713572066704308)
('standing', 3.713572066704308)
('proposing', 3.713572066704308)
('Editor', 3.713572066704308)
('Category', 3.713572066704308)
('Compare', 3.713572066704308)
('Xiao', 3.6375861597263857)
('participated', 3.6375861597263857)
('dk', 3.6375861597263857)
('joins', 3.6375861597263857)
('Rm', 3.6375861597263857)
('relaxed', 3.6375861597263857)
('margin', 3.6375861597263857)
('HCI', 3.6375861597263857)
('deviations', 3.6375861597263857)
('readability', 3.6375861597263857)
('compose', 3.6375861597263857)
('clarify', 3.6375861597263857)
('optional', 3.6375861597263857)
('well-studied', 3.6375861597263857)
('neutral', 3.6375861597263857)
('consistent', 3.58351893845611)
('46', 3.58351893845611)
('similarly', 3.58351893845611)
('perspective', 3.58351893845611)
('explain', 3.58351893845611)
('5.1', 3.58351893845611)
('performing', 3.58351893845611)
('51', 3.58351893845611)
('Once', 3.58351893845611)
('characteristics', 3.58351893845611)
('changing', 3.58351893845611)
('reduces', 3.58351893845611)
('rate', 3.58351893845611)
('action', 3.58351893845611)
('American', 3.58351893845611)
('Report', 3.58351893845611)
('inputs', 3.58351893845611)
('closely', 3.58351893845611)
('community', 3.58351893845611)
('Learning', 3.58351893845611)
('desired', 3.58351893845611)
('Machine', 3.58351893845611)
('five', 3.58351893845611)
('44', 3.58351893845611)
('office', 3.5553480614894135)
('Evidence', 3.5553480614894135)
('time-consuming', 3.5553480614894135)
('normalize', 3.5553480614894135)
('lexical', 3.5553480614894135)
('scanned', 3.5553480614894135)
('finer', 3.5553480614894135)
('yk', 3.5553480614894135)
('motivates', 3.5553480614894135)
('revision', 3.5553480614894135)
('ontology', 3.5553480614894135)
('willing', 3.5553480614894135)
('em', 3.5553480614894135)
('Descriptive', 3.4965075614664802)
('ignoring', 3.4965075614664802)
('1-10', 3.4965075614664802)
('contributing', 3.4965075614664802)
('Approaches', 3.4965075614664802)
('RELATED', 3.4965075614664802)
('decomposes', 3.4965075614664802)
('leverage', 3.4965075614664802)
('Cheng', 3.4965075614664802)
('placement', 3.4965075614664802)
('synthesized', 3.4965075614664802)
('Let', 3.4657359027997265)
('applications', 3.4657359027997265)
('now', 3.4657359027997265)
('given', 3.4657359027997265)
('11', 3.4657359027997265)
('15', 3.4657359027997265)
('20', 3.4657359027997265)
('described', 3.4657359027997265)
('9', 3.4657359027997265)
('find', 3.4657359027997265)
('means', 3.4657359027997265)
('internally', 3.4339872044851463)
('Word', 3.4339872044851463)
('She', 3.4339872044851463)
('outperform', 3.4339872044851463)
('Individual', 3.4339872044851463)
('translating', 3.4339872044851463)
('Putting', 3.4339872044851463)
('numeric', 3.4339872044851463)
('chart', 3.4339872044851463)
('Statement', 3.4339872044851463)
('Green', 3.4339872044851463)
('retrieves', 3.4339872044851463)
('Community', 3.4339872044851463)
('restricts', 3.4339872044851463)
('mistakes', 3.367295829986474)
('Jose', 3.367295829986474)
('categorization', 3.367295829986474)
('assessing', 3.367295829986474)
('returning', 3.367295829986474)
('facilitates', 3.367295829986474)
('edit', 3.367295829986474)
('positively', 3.332204510175204)
('Gao', 3.332204510175204)
('Agrawal', 3.332204510175204)
('maybe', 3.332204510175204)
('enumeration', 3.332204510175204)
('Nelson', 3.332204510175204)
('Journal', 3.295836866004329)
('All', 3.295836866004329)
('linear', 3.295836866004329)
('X', 3.295836866004329)
('however', 3.295836866004329)
('k', 3.295836866004329)
('...', 3.295836866004329)
('Springer', 3.295836866004329)
('easy', 3.295836866004329)
('often', 3.295836866004329)
('E', 3.295836866004329)
('assume', 3.295836866004329)
('When', 3.295836866004329)
('space', 3.295836866004329)
('27', 3.295836866004329)
('elements', 3.295836866004329)
('J', 3.295836866004329)
('22', 3.295836866004329)
('might', 3.295836866004329)
('framework', 3.295836866004329)
('needs', 3.295836866004329)
('higher', 3.295836866004329)
('development', 3.295836866004329)
('Moreover', 3.295836866004329)
('2003', 3.295836866004329)
('2008', 3.295836866004329)
('respectively', 3.295836866004329)
('etc', 3.295836866004329)
('difficult', 3.295836866004329)
('sets', 3.295836866004329)
('details', 3.295836866004329)
('N', 3.295836866004329)
('phones', 3.258096538021482)
('consumer', 3.258096538021482)
('sorts', 3.258096538021482)
('targets', 3.258096538021482)
('List', 3.258096538021482)
('finish', 3.258096538021482)
('unsupervised', 3.258096538021482)
('helping', 3.258096538021482)
('insertion', 3.258096538021482)
('isolation', 3.258096538021482)
('soft', 3.258096538021482)
('recommendation', 3.258096538021482)
('selected', 3.2188758248682006)
('consisting', 3.2188758248682006)
('100', 3.2188758248682006)
('created', 3.2188758248682006)
('architecture', 3.2188758248682006)
('hierarchies', 3.2188758248682006)
('adding', 3.2188758248682006)
('accommodate', 3.2188758248682006)
('Personal', 3.2188758248682006)
('Second', 3.2188758248682006)
('groups', 3.2188758248682006)
('studies', 3.2188758248682006)
('map', 3.2188758248682006)
('name', 3.2188758248682006)
('allocation', 3.2188758248682006)
('running', 3.2188758248682006)
('rest', 3.2188758248682006)
('except', 3.2188758248682006)
('meaning', 3.2188758248682006)
('separate', 3.2188758248682006)
('websites', 3.2188758248682006)
('maps', 3.2188758248682006)
('beyond', 3.2188758248682006)
('classifiers', 3.2188758248682006)
('achieved', 3.2188758248682006)
('aggregation', 3.2188758248682006)
('towards', 3.2188758248682006)
('scale', 3.2188758248682006)
('camera', 3.2188758248682006)
('highlight', 3.2188758248682006)
('39', 3.2188758248682006)
('practice', 3.2188758248682006)
('matrix', 3.2188758248682006)
('defining', 3.2188758248682006)
('Both', 3.2188758248682006)
('almost', 3.2188758248682006)
('upon', 3.2188758248682006)
('effect', 3.2188758248682006)
('detail', 3.2188758248682006)
('reasons', 3.2188758248682006)
('avoid', 3.2188758248682006)
('real-world', 3.2188758248682006)
('previously', 3.2188758248682006)
('overlapping', 3.2188758248682006)
('45', 3.2188758248682006)
('43', 3.2188758248682006)
('41', 3.2188758248682006)
('adopting', 3.1780538303479458)
('Designing', 3.1780538303479458)
('sensitivity', 3.1780538303479458)
('Nov.', 3.1780538303479458)
('Wikipedia', 3.1780538303479458)
('supervised', 3.1780538303479458)
('adjust', 3.1780538303479458)
('iteratively', 3.1780538303479458)
('diffusion', 3.1780538303479458)
('classifications', 3.1780538303479458)
('friendly', 3.1780538303479458)
('gathered', 3.1780538303479458)
('benchmark', 3.1780538303479458)
('Pn', 3.1780538303479458)
('trust', 3.1780538303479458)
('validated', 3.1354942159291497)
('quantify', 3.1354942159291497)
('wireless', 3.1354942159291497)
('spanning', 3.1354942159291497)
('eye', 3.1354942159291497)
('lacks', 3.1354942159291497)
('writes', 3.1354942159291497)
('state-of-the-art', 3.1354942159291497)
('inspection', 3.1354942159291497)
('Tang', 3.1354942159291497)
('Solution', 3.1354942159291497)
('usefulness', 3.1354942159291497)
('7.2', 3.091042453358316)
('Write', 3.091042453358316)
('live', 3.091042453358316)
('sorted', 3.091042453358316)
('price', 3.091042453358316)
('money', 3.091042453358316)
('reject', 3.091042453358316)
('general-purpose', 3.091042453358316)
('costly', 3.091042453358316)
('consistently', 3.091042453358316)
('ranks', 3.091042453358316)
('conduct', 3.044522437723423)
('exposition', 3.044522437723423)
('Protocol', 3.044522437723423)
('5.5', 3.044522437723423)
('linguistic', 3.044522437723423)
('systematically', 3.044522437723423)
('Background', 3.044522437723423)
('varied', 3.044522437723423)
('T1', 3.044522437723423)
('slight', 3.044522437723423)
('4.', 3.044522437723423)
('d1', 2.995732273553991)
('fill', 2.995732273553991)
('controlling', 2.995732273553991)
('globally', 2.995732273553991)
('Sections', 2.995732273553991)
('educational', 2.995732273553991)
('insert', 2.995732273553991)
('star', 2.995732273553991)
('feasibility', 2.9444389791664403)
('net', 2.9444389791664403)
('plot', 2.9444389791664403)
('highlights', 2.9444389791664403)
('API', 2.9444389791664403)
('7.1', 2.9444389791664403)
('board', 2.9444389791664403)
('suggesting', 2.9444389791664403)
('decompose', 2.9444389791664403)
('discussing', 2.9444389791664403)
('Content', 2.9444389791664403)
('randomized', 2.9444389791664403)
('Fix', 2.9444389791664403)
('detected', 2.9444389791664403)
('association', 2.9444389791664403)
('spent', 2.9444389791664403)
('registered', 2.9444389791664403)
('began', 2.9444389791664403)
('leaf', 2.9444389791664403)
('indexes', 2.8903717578961645)
('answering', 2.8903717578961645)
('ranking', 2.8903717578961645)
('workshop', 2.8903717578961645)
('elimination', 2.8903717578961645)
('Huang', 2.8903717578961645)
('percentage', 2.8903717578961645)
('Features', 2.8903717578961645)
('recommendations', 2.8903717578961645)
('Taylor', 2.8903717578961645)
('promise', 2.8903717578961645)
('Lin', 2.833213344056216)
('Visual', 2.833213344056216)
('Moore', 2.833213344056216)
('website', 2.833213344056216)
('Finding', 2.833213344056216)
('branches', 2.833213344056216)
('paid', 2.833213344056216)
('Through', 2.833213344056216)
('combines', 2.833213344056216)
('coded', 2.833213344056216)
('2.0', 2.833213344056216)
('eliminate', 2.833213344056216)
('broader', 2.833213344056216)
('redundant', 2.833213344056216)
('preprint', 2.833213344056216)
('evident', 2.833213344056216)
('limited', 2.772588722239781)
('summarizes', 2.772588722239781)
('increasing', 2.772588722239781)
('machine', 2.772588722239781)
('description', 2.772588722239781)
('third', 2.772588722239781)
('operations', 2.772588722239781)
('sum', 2.772588722239781)
('solutions', 2.772588722239781)
('14', 2.772588722239781)
('terms', 2.772588722239781)
('nature', 2.772588722239781)
('player', 2.772588722239781)
('perform', 2.772588722239781)
('make', 2.772588722239781)
('independent', 2.772588722239781)
('Similarly', 2.772588722239781)
('33', 2.772588722239781)
('Are', 2.772588722239781)
('arbitrary', 2.772588722239781)
('advantage', 2.772588722239781)
('Computational', 2.772588722239781)
('following', 2.772588722239781)
('group', 2.772588722239781)
('forms', 2.772588722239781)
('discuss', 2.772588722239781)
('shows', 2.772588722239781)
('e1', 2.772588722239781)
('variables', 2.772588722239781)
('equipped', 2.772588722239781)
('case', 2.772588722239781)
('extended', 2.772588722239781)
('relevant', 2.772588722239781)
('generator', 2.772588722239781)
('rules', 2.772588722239781)
('output', 2.772588722239781)
('determine', 2.772588722239781)
('applying', 2.772588722239781)
('How', 2.772588722239781)
('important', 2.772588722239781)
('detecting', 2.772588722239781)
('short', 2.772588722239781)
('someone', 2.772588722239781)
('found', 2.772588722239781)
('probability', 2.772588722239781)
('assumption', 2.772588722239781)
('without', 2.772588722239781)
('While', 2.772588722239781)
('ranked', 2.772588722239781)
('corresponds', 2.772588722239781)
('create', 2.772588722239781)
('describes', 2.772588722239781)
('understand', 2.772588722239781)
('Q.', 2.772588722239781)
('range', 2.772588722239781)
('appropriate', 2.772588722239781)
('proportional', 2.772588722239781)
('repeatedly', 2.772588722239781)
('called', 2.772588722239781)
('As', 2.772588722239781)
('presenting', 2.772588722239781)
('classic', 2.772588722239781)
('38', 2.772588722239781)
('technical', 2.772588722239781)
('achieve', 2.772588722239781)
('account', 2.772588722239781)
('choose', 2.772588722239781)
('descriptive', 2.772588722239781)
('priority', 2.772588722239781)
('need', 2.772588722239781)
('mechanical', 2.772588722239781)
('local', 2.772588722239781)
('goal', 2.772588722239781)
('sufficient', 2.772588722239781)
('http', 2.772588722239781)
('qualitative', 2.772588722239781)
('deviation', 2.772588722239781)
('Microsoft', 2.772588722239781)
('metadata', 2.70805020110221)
('subjects', 2.70805020110221)
('economic', 2.70805020110221)
('Summary', 2.70805020110221)
('converge', 2.70805020110221)
('Publications', 2.70805020110221)
('Stanford', 2.70805020110221)
('correlated', 2.70805020110221)
('varies', 2.70805020110221)
('Sons', 2.70805020110221)
('Optimization', 2.70805020110221)
('Challenges', 2.70805020110221)
('press', 2.70805020110221)
('validation', 2.70805020110221)
('Annals', 2.6390573296152584)
('estimates', 2.6390573296152584)
('Support', 2.6390573296152584)
('classify', 2.6390573296152584)
('medical', 2.6390573296152584)
('faces', 2.6390573296152584)
('child', 2.6390573296152584)
('characters', 2.6390573296152584)
('opportunity', 2.6390573296152584)
('98', 2.6390573296152584)
('Experimental', 2.6390573296152584)
('arrive', 2.6390573296152584)
('Zhou', 2.6390573296152584)
('retrieve', 2.6390573296152584)
('iterative', 2.6390573296152584)
('reveals', 2.6390573296152584)
('Decision', 2.6390573296152584)
('irrelevant', 2.6390573296152584)
('constructs', 2.6390573296152584)
('explains', 2.6390573296152584)
('ith', 2.6390573296152584)
('manual', 2.6390573296152584)
('achieves', 2.6390573296152584)
('representative', 2.6390573296152584)
('300', 2.6390573296152584)
('anything', 2.6390573296152584)
('draw', 2.6390573296152584)
('Functions', 2.6390573296152584)
('spectrum', 2.6390573296152584)
('Though', 2.6390573296152584)
('intuitively', 2.6390573296152584)
('manually', 2.6390573296152584)
('analyses', 2.6390573296152584)
('optimized', 2.5649493574615367)
('di', 2.5649493574615367)
('checks', 2.5649493574615367)
('James', 2.5649493574615367)
('cardinality', 2.5649493574615367)
('Interaction', 2.5649493574615367)
('5.4', 2.5649493574615367)
('y1', 2.5649493574615367)
('option', 2.5649493574615367)
('implicitly', 2.5649493574615367)
('Fast', 2.5649493574615367)
('adaptive', 2.5649493574615367)
('phrases', 2.5649493574615367)
('occurrences', 2.5649493574615367)
('comparable', 2.5649493574615367)
('contexts', 2.5649493574615367)
('ever', 2.4849066497880004)
('assignment', 2.4849066497880004)
('ranging', 2.4849066497880004)
('syntax', 2.4849066497880004)
('rich', 2.4849066497880004)
('Overview', 2.4849066497880004)
('decided', 2.4849066497880004)
('rows', 2.4849066497880004)
('employ', 2.4849066497880004)
('experts', 2.4849066497880004)
('appearing', 2.4849066497880004)
('fraction', 2.4849066497880004)
('Publishing', 2.4849066497880004)
('Description', 2.4849066497880004)
('sake', 2.4849066497880004)
('fails', 2.4849066497880004)
('absence', 2.4849066497880004)
('500', 2.4849066497880004)
('Towards', 2.4849066497880004)
('status', 2.4849066497880004)
('ID', 2.4849066497880004)
('server', 2.4849066497880004)
('calls', 2.4849066497880004)
('Intuitively', 2.4849066497880004)
('lengths', 2.4849066497880004)
('clustering', 2.4849066497880004)
('Assuming', 2.4849066497880004)
('send', 2.4849066497880004)
('subsection', 2.4849066497880004)
('87', 2.4849066497880004)
('curves', 2.4849066497880004)
('v.', 2.4849066497880004)
('neural', 2.4849066497880004)
('CONCLUSION', 2.4849066497880004)
('recognize', 2.4849066497880004)
('unified', 2.3978952727983707)
('availability', 2.3978952727983707)
('integrate', 2.3978952727983707)
('Yang', 2.3978952727983707)
('gave', 2.3978952727983707)
('adopt', 2.3978952727983707)
('Education', 2.3978952727983707)
('inspired', 2.3978952727983707)
('analyzing', 2.3978952727983707)
('samples', 2.3978952727983707)
('guide', 2.3978952727983707)
('ready', 2.3978952727983707)
('signals', 2.3978952727983707)
('trends', 2.3978952727983707)
('processor', 2.3978952727983707)
('varying', 2.3978952727983707)
('reflects', 2.3978952727983707)
('normalized', 2.3978952727983707)
('1.5', 2.3978952727983707)
('phases', 2.3978952727983707)
('Despite', 2.3978952727983707)
('demonstrates', 2.3978952727983707)
('Additionally', 2.302585092994046)
('affect', 2.302585092994046)
('fit', 2.302585092994046)
('foundation', 2.302585092994046)
('messages', 2.302585092994046)
('responsible', 2.302585092994046)
('Available', 2.302585092994046)
('Nevertheless', 2.302585092994046)
('discovery', 2.302585092994046)
('argue', 2.302585092994046)
('extraction', 2.302585092994046)
('near', 2.302585092994046)
('Three', 2.302585092994046)
('encoded', 2.302585092994046)
('criterion', 2.302585092994046)
('Jan', 2.302585092994046)
('care', 2.302585092994046)
('intuition', 2.302585092994046)
('middle', 2.302585092994046)
('measuring', 2.302585092994046)
('trying', 2.302585092994046)
('students', 2.302585092994046)
('resolution', 2.302585092994046)
('requiring', 2.302585092994046)
('recursive', 2.302585092994046)
('Google', 2.302585092994046)
('empirical', 2.302585092994046)
('receive', 2.302585092994046)
('comprehensive', 2.302585092994046)
('..', 2.302585092994046)
('Not', 2.302585092994046)
('3.', 2.302585092994046)
('San', 2.302585092994046)
('Statistics', 2.302585092994046)
('numerous', 2.302585092994046)
('closer', 2.302585092994046)
('complement', 2.302585092994046)
('environments', 2.302585092994046)
('Center', 2.302585092994046)
('sizes', 2.302585092994046)
('accessible', 2.302585092994046)
('consists', 2.1972245773362196)
('risk', 2.1972245773362196)
('represented', 2.1972245773362196)
('methodology', 2.1972245773362196)
('less', 2.1972245773362196)
('classified', 2.1972245773362196)
('standard', 2.1972245773362196)
('observations', 2.1972245773362196)
('Press', 2.1972245773362196)
('They', 2.1972245773362196)
('effectiveness', 2.1972245773362196)
('best', 2.1972245773362196)
('drawn', 2.1972245773362196)
('Information', 2.1972245773362196)
('basic', 2.1972245773362196)
('proposed', 2.1972245773362196)
('D', 2.1972245773362196)
('properties', 2.1972245773362196)
('First', 2.1972245773362196)
('later', 2.1972245773362196)
('others', 2.1972245773362196)
('row', 2.1972245773362196)
('current', 2.1972245773362196)
('introduce', 2.1972245773362196)
('term', 2.1972245773362196)
('et', 2.1972245773362196)
('happen', 2.1972245773362196)
('language', 2.1972245773362196)
('size', 2.1972245773362196)
('require', 2.1972245773362196)
('Research', 2.1972245773362196)
('Systems', 2.1972245773362196)
('computing', 2.1972245773362196)
('t', 2.1972245773362196)
('International', 2.1972245773362196)
('power', 2.1972245773362196)
('al', 2.1972245773362196)
('strings', 2.1972245773362196)
('represent', 2.1972245773362196)
('difference', 2.1972245773362196)
('t.', 2.1972245773362196)
('method', 2.1972245773362196)
('answers', 2.1972245773362196)
('none', 2.1972245773362196)
('Conference', 2.1972245773362196)
('respective', 2.1972245773362196)
('5.3', 2.1972245773362196)
('25', 2.1972245773362196)
('26', 2.1972245773362196)
('23', 2.1972245773362196)
('Architecture', 2.1972245773362196)
('assign', 2.1972245773362196)
('become', 2.1972245773362196)
('prevent', 2.1972245773362196)
('double', 2.1972245773362196)
('respect', 2.1972245773362196)
('libraries', 2.1972245773362196)
('throughout', 2.1972245773362196)
('30', 2.1972245773362196)
('recent', 2.1972245773362196)
('game', 2.1972245773362196)
('2004', 2.1972245773362196)
('include', 2.1972245773362196)
('Related', 2.1972245773362196)
('31', 2.1972245773362196)
('makes', 2.1972245773362196)
('named', 2.1972245773362196)
('apply', 2.1972245773362196)
('instead', 2.1972245773362196)
('Smith', 2.1972245773362196)
('including', 2.1972245773362196)
('From', 2.1972245773362196)
('count', 2.1972245773362196)
('R', 2.1972245773362196)
('knowledge', 2.1972245773362196)
('missing', 2.1972245773362196)
('surface', 2.1972245773362196)
('largest', 2.1972245773362196)
('Third', 2.1972245773362196)
('works', 2.1972245773362196)
('goals', 2.1972245773362196)
('whether', 2.1972245773362196)
('j', 2.1972245773362196)
('right', 2.1972245773362196)
('investigation', 2.0794415416798357)
('specification', 2.0794415416798357)
('large', 2.0794415416798357)
('Work', 2.0794415416798357)
('restrict', 2.0794415416798357)
('attempts', 2.0794415416798357)
('execution', 2.0794415416798357)
('designing', 2.0794415416798357)
('discussions', 2.0794415416798357)
('quickly', 2.0794415416798357)
('split', 2.0794415416798357)
('several', 2.0794415416798357)
('Application', 2.0794415416798357)
('efforts', 2.0794415416798357)
('REFERENCES', 2.0794415416798357)
('removed', 2.0794415416798357)
('inside', 2.0794415416798357)
('bounds', 2.0794415416798357)
('reality', 2.0794415416798357)
('turns', 2.0794415416798357)
('uniform', 2.0794415416798357)
('goes', 2.0794415416798357)
('13', 2.0794415416798357)
('19', 2.0794415416798357)
('18', 2.0794415416798357)
('ratio', 2.0794415416798357)
('overview', 2.0794415416798357)
('dimensions', 2.0794415416798357)
('i=1', 2.0794415416798357)
('interval', 2.0794415416798357)
('general', 2.0794415416798357)
('corresponding', 2.0794415416798357)
('decide', 2.0794415416798357)
('Series', 2.0794415416798357)
('retrieval', 2.0794415416798357)
('paper', 2.0794415416798357)
('21', 2.0794415416798357)
('Due', 2.0794415416798357)
('2n', 2.0794415416798357)
('benefits', 2.0794415416798357)
('Communications', 2.0794415416798357)
('x', 2.0794415416798357)
('robust', 2.0794415416798357)
('statistics', 2.0794415416798357)
('single', 2.0794415416798357)
('functionality', 2.0794415416798357)
('P', 2.0794415416798357)
('dynamics', 2.0794415416798357)
('addresses', 2.0794415416798357)
('formally', 2.0794415416798357)
('meet', 2.0794415416798357)
('structure', 2.0794415416798357)
('light', 2.0794415416798357)
('perfect', 2.0794415416798357)
('mention', 2.0794415416798357)
('Science', 2.0794415416798357)
('hope', 2.0794415416798357)
('Handbook', 2.0794415416798357)
('extends', 2.0794415416798357)
('By', 2.0794415416798357)
('match', 2.0794415416798357)
('identical', 2.0794415416798357)
('Unfortunately', 2.0794415416798357)
('highest', 2.0794415416798357)
('record', 2.0794415416798357)
('simultaneously', 1.9459101490553132)
('involve', 1.9459101490553132)
('Control', 1.9459101490553132)
('reasonable', 1.9459101490553132)
('principles', 1.9459101490553132)
('service', 1.9459101490553132)
('Clearly', 1.9459101490553132)
('Advances', 1.9459101490553132)
('union', 1.9459101490553132)
('potentially', 1.9459101490553132)
('and/or', 1.9459101490553132)
('string', 1.9459101490553132)
('max', 1.9459101490553132)
('Applied', 1.9459101490553132)
('arguments', 1.9459101490553132)
('Is', 1.9459101490553132)
('act', 1.9459101490553132)
('ai', 1.9459101490553132)
('strategies', 1.9459101490553132)
('history', 1.9459101490553132)
('hierarchy', 1.9459101490553132)
('2.', 1.9459101490553132)
('ask', 1.9459101490553132)
('differ', 1.9459101490553132)
('store', 1.9459101490553132)
('behind', 1.9459101490553132)
('believe', 1.9459101490553132)
('dependent', 1.9459101490553132)
('else', 1.9459101490553132)
('Examples', 1.9459101490553132)
('Internet', 1.9459101490553132)
('location', 1.9459101490553132)
('Their', 1.9459101490553132)
('replace', 1.9459101490553132)
('contributions', 1.9459101490553132)
('produces', 1.9459101490553132)
('sufficiently', 1.9459101490553132)
('investigate', 1.9459101490553132)
('performs', 1.9459101490553132)
('interactions', 1.9459101490553132)
('viewed', 1.9459101490553132)
('min', 1.9459101490553132)
('INTRODUCTION', 1.9459101490553132)
('configuration', 1.9459101490553132)
('units', 1.9459101490553132)
('1988', 1.9459101490553132)
('demonstrate', 1.9459101490553132)
('machines', 1.791759469228055)
('never', 1.791759469228055)
('successful', 1.791759469228055)
('past', 1.791759469228055)
('flow', 1.791759469228055)
('testing', 1.791759469228055)
('John', 1.791759469228055)
('programs', 1.791759469228055)
('slightly', 1.791759469228055)
('statistical', 1.791759469228055)
('World', 1.791759469228055)
('significantly', 1.791759469228055)
('advantages', 1.791759469228055)
('1.', 1.791759469228055)
('typically', 1.791759469228055)
('precise', 1.791759469228055)
('observe', 1.791759469228055)
('former', 1.791759469228055)
('developing', 1.791759469228055)
('4.3', 1.791759469228055)
('storage', 1.791759469228055)
('valid', 1.791759469228055)
('experience', 1.791759469228055)
('occurs', 1.791759469228055)
('particularly', 1.791759469228055)
('matter', 1.791759469228055)
('wide', 1.791759469228055)
('creating', 1.791759469228055)
('generalized', 1.791759469228055)
('integer', 1.791759469228055)
('sections', 1.791759469228055)
('allowing', 1.791759469228055)
('noted', 1.791759469228055)
('purposes', 1.791759469228055)
('powerful', 1.791759469228055)
('Development', 1.791759469228055)
('Recall', 1.791759469228055)
('Design', 1.791759469228055)
('infinite', 1.791759469228055)
('identity', 1.791759469228055)
('patterns', 1.791759469228055)
('experimental', 1.791759469228055)
('likely', 1.6094379124341003)
('p.', 1.6094379124341003)
('Most', 1.6094379124341003)
('series', 1.6094379124341003)
('relatively', 1.6094379124341003)
('questions', 1.6094379124341003)
('essentially', 1.6094379124341003)
('core', 1.6094379124341003)
('differences', 1.6094379124341003)
('whereas', 1.6094379124341003)
('setting', 1.6094379124341003)
('node', 1.6094379124341003)
('global', 1.6094379124341003)
('upper', 1.6094379124341003)
('occur', 1.6094379124341003)
('fast', 1.6094379124341003)
('argument', 1.6094379124341003)
('ideas', 1.6094379124341003)
('satisfying', 1.6094379124341003)
("n't", 1.6094379124341003)
('specified', 1.6094379124341003)
('Society', 1.6094379124341003)
('straightforward', 1.6094379124341003)
('followed', 1.6094379124341003)
('fundamental', 1.6094379124341003)
('denotes', 1.6094379124341003)
('issue', 1.6094379124341003)
('base', 1.6094379124341003)
('introduction', 1.6094379124341003)
('Language', 1.6094379124341003)
('build', 1.6094379124341003)
('finding', 1.6094379124341003)
('underlying', 1.6094379124341003)
('recently', 1.6094379124341003)
('Processing', 1.6094379124341003)
('read', 1.6094379124341003)
('alternative', 1.6094379124341003)
('essential', 1.6094379124341003)
('per', 1.6094379124341003)
('minimal', 1.6094379124341003)
('illustrated', 1.6094379124341003)
('go', 1.6094379124341003)
('involves', 1.6094379124341003)
('obvious', 1.6094379124341003)
('lines', 1.6094379124341003)
('produced', 1.6094379124341003)
('keep', 1.6094379124341003)
('Other', 1.6094379124341003)
('optimal', 1.6094379124341003)
('greater', 1.6094379124341003)
('stored', 1.6094379124341003)
('extension', 1.6094379124341003)
('volume', 1.6094379124341003)
('Also', 1.3862943611198906)
('1994', 1.3862943611198906)
('Another', 1.3862943611198906)
('satisfies', 1.3862943611198906)
('represents', 1.3862943611198906)
('Y', 1.3862943611198906)
('second', 1.3862943611198906)
('expected', 1.3862943611198906)
('n', 1.3862943611198906)
('procedure', 1.3862943611198906)
('System', 1.3862943611198906)
('variable', 1.3862943611198906)
('choice', 1.3862943611198906)
('cost', 1.3862943611198906)
('appear', 1.3862943611198906)
('prove', 1.3862943611198906)
('cases', 1.3862943611198906)
('produce', 1.3862943611198906)
('definitions', 1.3862943611198906)
('1997', 1.3862943611198906)
('There', 1.3862943611198906)
('Such', 1.3862943611198906)
('Data', 1.3862943611198906)
('12', 1.3862943611198906)
('17', 1.3862943611198906)
('16', 1.3862943611198906)
('potential', 1.3862943611198906)
('solve', 1.3862943611198906)
('If', 1.3862943611198906)
('aspects', 1.3862943611198906)
('around', 1.3862943611198906)
('Since', 1.3862943611198906)
('refer', 1.3862943611198906)
('Sciences', 1.3862943611198906)
('4.1', 1.3862943611198906)
('4.2', 1.3862943611198906)
('follow', 1.3862943611198906)
('section', 1.3862943611198906)
('search', 1.3862943611198906)
('science', 1.3862943611198906)
('v', 1.3862943611198906)
('reason', 1.3862943611198906)
('determined', 1.3862943611198906)
('added', 1.3862943611198906)
('access', 1.3862943611198906)
('classes', 1.3862943611198906)
('whole', 1.3862943611198906)
('due', 1.3862943611198906)
('networks', 1.3862943611198906)
('source', 1.3862943611198906)
('like', 1.3862943611198906)
('either', 1.3862943611198906)
('run', 1.3862943611198906)
('code', 1.3862943611198906)
('issues', 1.3862943611198906)
('making', 1.3862943611198906)
('resulting', 1.3862943611198906)
('tools', 1.3862943611198906)
('comparison', 1.3862943611198906)
('purpose', 1.3862943611198906)
('Q', 1.3862943611198906)
('chosen', 1.3862943611198906)
('relations', 1.3862943611198906)
('One', 1.3862943611198906)
('ones', 1.3862943611198906)
('areas', 1.3862943611198906)
('construction', 1.3862943611198906)
('total', 1.0986122886681098)
('1998', 1.0986122886681098)
('complexity', 1.0986122886681098)
('points', 1.0986122886681098)
('initial', 1.0986122886681098)
('type', 1.0986122886681098)
('together', 1.0986122886681098)
('computation', 1.0986122886681098)
('interesting', 1.0986122886681098)
('question', 1.0986122886681098)
('open', 1.0986122886681098)
('say', 1.0986122886681098)
('note', 1.0986122886681098)
('considered', 1.0986122886681098)
('IEEE', 1.0986122886681098)
('L', 1.0986122886681098)
('real', 1.0986122886681098)
('area', 1.0986122886681098)
('start', 1.0986122886681098)
('field', 1.0986122886681098)
('At', 1.0986122886681098)
('i.e', 1.0986122886681098)
('via', 1.0986122886681098)
('taken', 1.0986122886681098)
('24', 1.0986122886681098)
('29', 1.0986122886681098)
('presented', 1.0986122886681098)
('definition', 1.0986122886681098)
('done', 1.0986122886681098)
('clear', 1.0986122886681098)
('2.1', 1.0986122886681098)
('various', 1.0986122886681098)
('available', 1.0986122886681098)
('let', 1.0986122886681098)
('computational', 1.0986122886681098)
('m', 1.0986122886681098)
('2006', 1.0986122886681098)
('2009', 1.0986122886681098)
('requires', 1.0986122886681098)
('Technology', 1.0986122886681098)
('element', 1.0986122886681098)
('able', 1.0986122886681098)
('Some', 1.0986122886681098)
('words', 1.0986122886681098)
('years', 1.0986122886681098)
('contain', 1.0986122886681098)
('computer', 1.0986122886681098)
('S', 1.0986122886681098)
('necessary', 1.0986122886681098)
('sequence', 1.0986122886681098)
('introduced', 1.0986122886681098)
('denote', 1.0986122886681098)
('every', 0.6931471805599453)
('result', 0.6931471805599453)
('way', 0.6931471805599453)
('particular', 0.6931471805599453)
('even', 0.6931471805599453)
('another', 0.6931471805599453)
('since', 0.6931471805599453)
('On', 0.6931471805599453)
('next', 0.6931471805599453)
('fact', 0.6931471805599453)
('much', 0.6931471805599453)
('made', 0.6931471805599453)
('all', 0)
('under', 0)
('above', 0)
('would', 0)
('until', 0)
('me', 0)
('how', 0)
('after', 0)
('over', 0)
('before', 0)
('then', 0)
('them', 0)
('they', 0)
('do', 0)
('against', 0)
('been', 0)
('have', 0)
('is', 0)
('it', 0)
('in', 0)
('if', 0)
('the', 0)
('had', 0)
('has', 0)
('for', 0)
('was', 0)
('more', 0)
('no', 0)
('when', 0)
('did', 0)
('be', 0)
('only', 0)
('by', 0)
('most', 0)
('such', 0)
('so', 0)
('not', 0)
('down', 0)
('where', 0)
('a', 0)
('that', 0)
('than', 0)
('were', 0)
('and', 0)
('any', 0)
('between', 0)
('those', 0)
('these', 0)
('same', 0)
('being', 0)
('each', 0)
('on', 0)
('of', 0)
('or', 0)
('your', 0)
('there', 0)
('with', 0)
('as', 0)
('at', 0)
('to', 0)
('very', 0)
('further', 0)
('what', 0)
('through', 0)
('too', 0)
('during', 0)
('are', 0)
('both', 0)
('while', 0)
('itself', 0)
('some', 0)
('into', 0)
('up', 0)
('we', 0)
('from', 0)
('themselves', 0)
('this', 0)
('own', 0)
('our', 0)
('out', 0)
('could', 0)
('their', 0)
('which', 0)
('who', 0)
('but', 0)
('why', 0)
('its', 0)
('should', 0)
("it's", 0)
('an', 0)
('i', 0)
('you', 0)
('because', 0)
('does', 0)
('about', 0)
('below', 0)
('other', 0)
['precog:', 'improving', 'crowdsourced', 'data', 'quality']
====================
To this end, we present Precog1 , a crowdsourced data acquisition system that supports pre-hoc quality control for both simple data types and multi-paragraph text attributes.

104737.525966

====================
We further show that Precog's unique approach to combining prescriptive explanations and segment-level feedback improves text quality by 14.3%, and over 3x better than a state-of-the-art feedback system [50].

81268.6630781

====================
To build high-quality models, we survey and categorize features from the writing analysis literature into 5 categories  1. user input  2. segment by topic  3. estimate quality  4. targeted feedback  Figure 3: The Segment-Predict-Explain pattern: Precog splits user input into coherent segments; estimates the quality of each segment and the text as a whole; and generates and shows suggested improvements to the user.

33563.7640884

====================
In addition to evaluating Precog for hard constraints and simple data types, we evaluate Precog's text feedback through extensive MTurk experiments on two real application domains--product reviews and rental host profiles.

27218.8837323

====================
In this paper, we argue for pre-hoc quality control systems.

19583.0114652

====================
The fourth FEF for product reviews was mapped to Subjectivity features in (Table 1) and the fourth host profiles FEF was mapped to Friendliness LIWC features shown in [94], with each returning text suggesting that the user improves the respective facet of their submission (i.e., "Please make your writing more balanced and neutral").

15786.9001911

====================
Our experiments and prior work [52] show that this is less effective than a more customized approach.

14722.0535258

====================
Experimental Conditions: The purpose of experiments is to both show the Cost Saving benefits of Precog as well as to evaluate the effectiveness of it's two main features (segment-level feedback and TCruise explanation generation).

14690.810719

====================
NEW APPLICATION DOMAINS  EXPERIMENTS  We now evaluate how Precog improves high-quality data acquisition using live Mechanical Turk deployments.

10248.1637602

====================
Precog, which is complementary to post-hoc quality control techniques, collects >= 2x high-quality documents for the same budget as no feedback, and improves text quality by 14.3% on average.

10037.642065

====================
For explanation functions, prior work showed that 75% of reasons for unhelpful reviews were covered by (in priority order) overly emotional/biased opinions, lack of information/not enough detail, irrelevant comments, and poor writing style [18].

9509.10683352

====================
For example, task replication [43, 80] assigns the same task to multiple workers and aggregates them into a single result; multi-stage workflow design [6, 48] uses additional crowd tasks to (iteratively) refine previously submitted tasks; in text acquisition, filtering/ranking [1, 37, 67, 82, 84, 86, 90, 95] uses crowd tasks to assess each document's quality and either rank them by quality or filter out low-quality documents.

7035.52653519

====================
The first category, Informativeness, highlights trends across existing literature that show that both general length measures [4, 50, 55, 57, 82] as well as domain-specific jargon are highly predictive of quality [55, 57, 60].

6847.4150952

====================
Through extensive MTurk experiments, we find that Precog collects >= 2x more high-quality documents and improves text quality by 14.3% compared to not using pre-hoc techniques.

6525.28197944

====================
We directly address this problem by selecting multi-feature explanation functions to prescribe improvements to the user's text.

5836.61029511

====================
We believe our assumption about the availability of a training corpus is reasonable in data acquisition settings, because such quality labels are already gathered in order to rank documents (e.g., Amazon helpful/unhelpful reviews, Reddit comment up/down votes).

5735.67427915

====================
Although crowdsourcing is used to collect labels and simple data for machine learning applications, many popular online communities such as Amazon, AirBnB, Quora, Reddit, and others also rely on collecting and presenting high quality, open-ended content that is crowdsourced from their users.

5319.9256257

====================
Furthermore, while most approaches simply use the distribution of topics as a feature [57, 62], Precog computes several summary statistics (entropy, topic ID and probability of top-K topics, ranked by probability) not used in prior work that prove highly predictive in our experiments.

5258.51157194

====================
To this end, we performed a survey of literature spanning of social media text analysis [32, 55, 57, 82, 85], essay grading [4,25,58,89], deception detection [23,60], and information retrieval [64, 84].

5195.83533571

====================
We describe our experiments that show that it is possible to use these labels as a proxy for individual segments.

4842.44069027

====================
We validated generalizability of the model to domains not covered in prior work by evaluating it on reddit comments from the AskScience subreddit5 and predicted comment helpfulness on an evenly balanced sample with 80% accuracy6 .

4790.83999066

====================
In this section, we first describe how users express Precog quality control for common data integrity constraints, as well as quality scores on a crowd-sourced table.

4754.07407758

====================
For example, Amazon crowdsources product reviews by asking customers to rate products and write reviews for them; rental services (e.g., AirbnB) relies on rental hosts to describe their rental properties in quantitative (e.g., number of bed rooms, wireless) as well as qualitative terms (e.g., textual description).

4200.48356283

====================
* Extensive MTurk experiments on two real-world domains with different quality measures: helpfulness for Amazon product reviews and trustworthiness for AirBnB housing profiles.

3880.26805559

====================
These plots show the effect size across all measures, and that the largest improvements were due to the combination of segmentation and TCruise-based explanation.

3594.00140097

====================
Since good feedback can help the worker improve the text, it naturally improves the quality of the acquired data, and can reduce data acquisition costs.

3559.59280826

====================
Most studies focus on post-hoc quality control, often using additional crowdsourced tasks to assess and improve the quality.

3483.92813494

====================
def offTopic(topics, text="", feats=[]): if len(topics) < 5: sortedTopics = sorted(topics, key=topic.prob) return "Try discussing some of these topics: " + topK(sortedTopics, 5)  We used a similar process for host profiles and found that research emphasizes trustworthiness as the key quality metric [57, 94].

3417.3009893

====================
Precog takes long form text from a crowd worker, decomposes it into coherent portions (segments) based on their topics, predicts the quality of each segment, and automatically generates immediate feedback to explain how these segments can be improved.

3282.10605217

====================
We define this as the Prescriptive Explanation problem, and find that the search space of solutions for the problem is exponential in the number of model features.

3101.15716585

====================
The consistent results between all three comparisons suggest the efficacy of the segment-level classifier, and our end-to-end experimental results suggest that the predictive model is effective at providing segment level feedback.

3058.33052891

====================
We showed this to be sufficient by testing on crowd-sourced labels; however more sophisticated techniques to classify segments could improve feedback.

3045.33360441

====================
The problem is exponential and we present an efficient solution that leverages the structure of random forest models to generate high-quality feedback in interactive time.

2982.54178089

====================
The only change is the beige component, which augments the data collection interface (task interface) to estimate the quality of the user's (in this case) text, and automatically provide feedback if the predicted quality is low.

2977.79814186

====================
We describe our process to extend Precog to two domains with different quality measures: product reviews that care about helpfulness to a shopper [3], and then host profiles that are judged by trustworthiness to renters [57].

2975.23470694

====================
Fp is the subset of features that p perturbs:  Sfd  We are now ready to present the key technical problem for text acquisition feedback:  5.4  U (vij ) - U (M (d))  Our implementation indexes all paths in the random forest by their utility.

2962.31888687

====================
As illustrated in Figure 3, we employ a novel SegmentPredict-Explain pattern to generate customized feedback on an individual segment (rather than document) level.

2851.45361755

====================
To summarize our contributions: * We present the argument for pre-hoc quality control and present its unique advantages as well as the challenges for multi-paragraph text.

2808.20029323

====================
count) LDA topic distribution and top topics [8], entropy across topic distribution opinion sentence distribution stats [64], valence, polarity, and subjectivity scores and distribution across sentences [32, 34, 56], % upper case characters, first person usage, adjectives spelling errors [45], ARI, Gunning index, Coleman-Liau index, Flesch Reading tests, SMOG, punctuation, parts of speech distribution, lexical diversity measures, LIWC grammar features various TF-IDF and top parts of speech comparisons with sample of low and high utility documents  Table 1: Summary of feature library for text quality.

2641.2590496

====================
We then computed pairwise accuracies between the document labels, classifier predictions, and crowd labels: 71.1% (Classifier predicting Crowd Label), 72.5% (Classifier predicting Document label), and 69.5% (Document label predicting Crowd Label).

2625.96928984

====================
To this end, we define the responsibility Sfdi of a feature fi for input point d as the sum of all maximum influence perturbations that involve fi (e.g., the perturbation pi 6= 0): X  Sfdi =  I(d, p)  I(d, qij ) =  p[?

2594.73450762

====================
Second, we evaluate Precog's Segment-Predict-Explain pattern for text acquisition in two domains--acquiring customer reviews for Amazon products [61] and acquiring profile descriptions for AirBnB host profiles [94].

2556.7728259

====================
def notEnoughDetail(topics, featureCnt, textLen, text="", feats=[]): if featureCnt < 10 and textLen < threshold: return "Try adding information about: " + suggest_new_prod_feats(topics, text, feats) ...  We note that existing feedback systems [7,49,50] implicitly follow this model, however they bind individual features to static strings.

2486.32982486

====================
All participants were US Residents with > 90% HIT accept rates.

2440.94871151

====================
Quality scores are intended for attribute values for which the definition of quality defined as a continuous measure to be improved, rather than a boolean constraint, and provides the framework for which we implement a model-based feedback system for performing Precog on text attributes (Section 3).

2361.29884278

====================
def numeric_exp(att, val, err): return "%s: '%s' should be a number" % (att, val) CREATE EXPLANATION ON reviews(rating) FOR reviews_rating_domain USING numeric_exp; CREATE EXPLANATION ON users(age) FOR users_age_domain USING numeric_exp;  Similar functions can easily be written for the foreign-key and uniqueness constraints in Figure 4: def product_exp(att, val, err): return "%s is not a product" % val def unique_exp(att, val, err): return "%s has been taken" % val  For text attributes, the explanation function is slightly different, which is defined on a FEATURE table.

2356.51238407

====================
To understand the contributing factors towards the quality improvements, we compared four feedback systems that varied along two dimensions: granularity varies the feedback to be at the document level (Doc), or at the document and segment level (Seg); explanation selection compares the single-feature outlier technique from [50] (Krause) with TCruise.

2286.19062645

====================
2.1  Pushing Data Constraints to the Interface  Precog extends existing crowdsourced databases that contain crowdsourced and non-crowdsourced base relations; a crowdsourced table [28] represents a subset of all possible records that may be stored in the table and the task is to acquire records to insert into the table.

2284.60986431

====================
Figure 1 illustrates a typical text acquisition workflow: the crowd generates text documents, more tasks are used to estimate the text quality, low-quality documents are removed, and this may ultimately trigger the need to collect more data.

2274.98427098

====================
Precog is easily extended to new domains, and increases the number of high-quality documents by >= 2x compared to not using pre-hoc techniques.

2173.42921441

====================
Third, it's unclear how to automatically generate the appropriate feedback text to show the user.

2170.06473615

====================
Precog: A PRECOG SYSTEM  As described in the introduction, Precog seeks to optimize the data collection interface in order to improve the quality of the collected data and ensure data quality constraints.

2088.42440696

====================
When we consider a user's edits, they are desirable if the edits will improve the document's quality--in other words, if it will cause the document to be reclassified as high quality.

2059.69867101

====================
We first describe our extensible feature library that consolidates text features across literature in social media text analysis, essay grading, language psychology, and data mining research communities.

2057.82879191

====================
The prior work predicts the quality of Amazon DVD, AV player and Camera reviews with 83% accuracy; Precog's default model on the same setup predicts at 85% accuracy--the slight improvement is due to the additional features in the topic and similarity categories from other literature (Table 1).

1892.05364311

====================
To this end, we use a technique called TopicTiling [77], an extension to TextTiling [40].

1877.41537302

====================
Pre-hoc quality control occurs before data acquisition and naturally complements many existing post-hoc techniques to further improve the final data quality.

1874.06712811

====================
To ensure fair comparison, we supplemented their features with domain-specific features for Informativeness (# of product features/jargon), Readability (Coleman-Liau index), and Friendliness (LIWC features related to friendliness) so that their features are comparable to those used in our feature library.

1862.1099959

====================
In contrast, Precog supports feature combinations and can dynamically generate feedback based on the  Responsibility: Our goal is to identify feature subsets of the test data point d that, if perturbed, will most improve 7  d's utility7 .

1803.61740165

====================
A developer first defines an explanation function that takes as input the list of attribute names and values for which the constraint is defined for (in order to support multi-attribute constraints) and the error message, and returns a string that is shown as feedback.

1793.83755532

====================
For this, we use TopicTiling [77], a sliding window-based segmentation algorithm that computes the dominant topics within the window using LDA [8].

1791.37130773

====================
Pre-hoc methods improve quality before the data is acquired (submitted); Post-hoc methods improve quality after data acquisition (i.e., after submission).

1776.27530373

====================
We first introduce the Prescriptive Explanation problem, which assigns responsibility to each model feature proportional to the amount that it will contribute to improving the predicted text quality.

1721.37413647

====================
It can be integrated seamlessly into existing crowdsourcing applications or systems with post-hoc quality control, helping them to further improve quality.

1718.42066862

====================
Furthermore, controlling for the other variable, TCruise showed a statistically significant difference in improvement, while segmentation did not.

1656.0449677

====================
Our contribution is to curate the subset of these features that can be generalized across text domains to improve writing quality, categorize them (Table 1), and integrate them into an open source feature library4 .

1652.16739079

====================
Finally, we asked coders to subjectively rate their agreement from 1-7 to the statement "The post-feedback revisions improved on the pre-feedback document.

1623.29734072

====================
These statements complement existing task interface specifications that prior crowdsourcing systems [28, 59, 71] use for task generation by providing a way to augment them for data integrity constraints.

1604.54238987

====================
We compute a variety of similarity measures between the input document and a sample of high and low quality documents-using both the simple TF-IDF measure used in prior work [47] as well as occurrences of popular parts of speech appearing in a document (i.e top-K nouns in unhelpful documents that appear).

1587.46677379

====================
A dominant use case for crowdsourcing is to collect data-- labels, opinions, text extraction, ratings--from large groups of workers.

1586.82048469

====================
Existing approaches (surveyed in Related Work) focus on syntactic errors such as grammatical mistakes, which cannot help improve the text content, or overly simple models for picking feedback text [50].

1586.19621558

====================
8  We added LIWC API calls to Precog; the model tested on a balanced set of 300 AirBnB host profiles was competitive (79% accuracy) at predicting if a profile was >= median trustworthiness.

1578.89665223

====================
7.2  Precog for Text Acquisition  Setup and Datasets: Precog is setup as described in Section 6: we train Precog using the laptop category of the Amazon product reviews corpus [61], and the AirBnb profile corpus [94] for their corresponding experiments.

1577.46694219

====================
Readability/Grammar is an aggregate of syntactic features shown predictive across multiple domains [23, 50, 60, 82].

1573.99119658

====================
For this, we next introduce DDL statements to specify custom interfaces.

1556.12099287

====================
We first present the results of the fully featured Precog condition (Section 7.2.1) and then demonstrate the contribution of each Precog component (in Section 7.2.2).

1501.93801599

====================
Below, we describe how developers can express the three levels of Precog quality control for domain, foreign-key, uniqueness, and quality score constraints in Figure 4.

1484.90125532

====================
This problem is challenging because we must analyze potentially arbitrary text content.

1484.00093575

====================
However, recent study shows the promise of translating semantic features to textual feedback [50].

1465.39565769

====================
CONCLUSION AND FUTURE WORK  This paper presented the design, implementation and evaluation of Precog, a pre-hoc quality control system.

1456.78956576

====================
Krause [50] was shown to outperform static explanations of important components of a helpful review (similar to a rubric) for students performing peer code-reviews and uses an outlier based approach described in Section 5.1.

1454.84063667

====================
Specifically, we ran a crowdsourced study to label 500 Amazon segments (250 drawn from helpful reviews, and 250 from unhelpful reviews), with human helpfulness labels (the median segment length of a review is 3).

1432.52578035

====================
First, we validate the value of pre-hoc quality control by running a crowdsourced data acquisition experiment with different Precog optimizations for foreign key and domain constraints.

1422.28306524

====================
In this work, we restrict the analysis to perturbations that have the maximal influence.

1415.31244828

====================
To do so, we first define the impact I(d, p) for an individual perturbation p as the amount that it improves the utility function discounted by the amount of the perturbation [?

1393.71871486

====================
To do so, we develop a novel perturbation-based analysis to identify the combination of features that, when changed, will most likely reclassify the text as high quality.

1385.1526998

====================
Although it's possible to automatically perform pre-hoc quality control for simple constraints over simple data types, it is still unclear how this can be achieved for more complex data integrity constraints and data types.

1321.28705223

====================
Companies (e.g., Amazon, Zappos) use this post-hoc technique by asking users to assess whether a product review is "helpful" or "not helpful", and ranks and displays reviews based on this measure.

1318.4762827

====================
We implement a variety of length measures, and use the Apriori algorithm [75] to mine jargon based on the training data inputted into Precog, and identify its distribution across the sentences of an input document.

1316.49142032

====================
We learn this quality measure by training a random forest model that predicts the quality of individual text segments.

1304.49698147

====================
5.3  Problem Statement  Intuition: Figure 6 depicts the main intuition behind the problem and our approach.

1304.34730602

====================
* The design and implementation of Precog, which supports pre-hoc quality control for constraints over simple data types and quality measures over text and open-ended attributes.

1291.4116914

====================
To address this issue, we present a Segment-Predict-Explain pattern that  Architecture: Figure 5 depicts the system architecture.

1290.74367103

====================
In contrast, we generate prescriptive, actionable explanations that, if followed, are expected to improve the text.

1242.91465874

====================
It does so by generating feedback or interface changes to help workers improve their data pre-submission.

1226.99325302

====================
We choose a random forest classifier, which has been shown effective in existing work [32], and select features using the recursive feature elimination algorithm [38].

1216.99576676

====================
We then performed pairwise Tukey HSD post-hoc tests between each of the four conditions.

1209.78762835

====================
Each rubric rated documents on a 1-7 Likert scale using three specific aspects identified by prior work--Informativity, Subjectivity, Readability--for reviews--Ability, Benevolence, Integrity-for profile trustworthiness, as well as a holistic overall score.

1206.52972566

====================
Precog also achieves 79% accuracy at predicting if an Airbnb profile is above or below median trustworthiness, using trustworthiness data from [94].

1196.61158183

====================
However, the combination of segmentation and TCruise consistently produced larger effect sizes than all other conditions across both Host Profiles and Product Reviews: for Product Reviews Precog, which combines segmentation and TCruise, improved the overall measure (bottom left facet) by nearly 3.9x over the baseline (0.55 vs. 0.14 increase), and a 2.4x improvement over the next-best Doc+TCruise condition.

1186.82618702

====================
def exp_func(att1, val1, ..., attn, valn, err=None): return "custom error message" CREATE EXPLANATION <func> ON <table>(<att1>,..<attn>) FOR <CONSTRAINT NAME> USING <explanation function>;  Below is the specification to customize the feedback for a numeric domain constraint3 .

1181.39441492

====================
We then map these feature combinations to explanation functions that are executed to generate the final set of feedback text (Section 5).

1158.77834077

====================
Specifically, we develop effective approaches to measure text quality at both document and segment levels, present an efficient technique to solve the prescriptive explanation problem, and discuss how to extend Precog to new domains.

1155.54744668

====================
CREATE CROWD TABLE users ( id autoincrement primary key, username text UNIQUE, age int CHECK age > 0 AND age < 100, CHECK(username matches \w+) ); CREATE CROWD TABLE reviews( id autoincrement primary key, product_id text, rating int CHECK rating > 0 AND rating <= 5, review text, QUALITY SCORE qualreview qual_udf(review), FOREIGN KEY product_id REF products(id) ); CREATE FEATURE TABLE review_feats( review text primary key references reviews.review, topics FEATURE topic_extractor, len FEATURE len_extracton, ... );  Generic Feedback: Precog automatically generates feedback based on the error message that the underlying database generates when the INSERT violates a constraint.

1154.51039846

====================
Figure 2 augments this workflow with pre-hoc quality control.

1130.43828854

====================
Product-Review Participants: For the laptop review experiment, we recruited 85 workers on Amazon's Mechanical Turk (61.2% male, 38.8% female, ages 20-65 uage =32, sage =8.5).

1127.71686392

====================
We then randomly assigned each worker 50 segments to label, and collected labels until each segment had >= 3 labels, and determined the final label of each segment using the Get Another Label algorithm [81].

1127.05008298

====================
We address these challenges by proposing a novel segment-predict-explain pattern for detecting lowquality text and generating prescriptive explanations to help the user improve their text.

1117.28663515

====================
Our goal is to provide the foundation for such content-specific semantic feedback by surveying and categorizing features from the writing analysis literature.

1115.33792459

====================
Host-Profile Participants: For the profile description experiment, we recruited 92 workers on Amazon's Mechanical Turk (58.7% male, 41.3% female, ages 20-62 uage =33, sage =8.2); all completed the task.

1113.77230327

====================
Our design is informed by the writing analysis and feedback literature, which emphasizes the value of providing immediate feedback [51], as well as finegrained feedback for specific portions of the text [17, 78, 83], as is common in coding environments.

1113.16938573

====================
In summary, we find that TCruise is essential to improving document quality; combining TCruise with Segmentation empirically produces the best results across the board.

1069.58540966

====================
* We define the Prescriptive Explanation Problem to provide actionable feedback for text acquisition.

1063.17611873

====================
Cost Savings  Figure 10: Improvement on Likert scores for both domains (reviews and profiles) and four quality criteria per domain.

1046.89083716

====================
We are optimistic about the Segment-Predict-Explain pattern, because adopting to new domains is simply a matter synthesizing existing research by adding features and creating simple explanation functions.

1040.88304783

====================
By default, Precog provides optimizations for constraints over numerical and categorical data types, and can be extended with custom optimizations.

1033.2280947

====================
Finally, we perform a detailed analysis of how segmentation and TCruise each contribute to improving the quality of the acquired text.

1030.84362812

====================
The final FEATURE table review_feats is used in the later sections to represent the features extracted from the value of the primary key (review).

1020.3060548

====================
Nevertheless, more studies are needed to fully evaluate this hypothesis across other text domains and document lengths.

996.929363604

====================
In future work, we hope to explore a broader range of applications (e.g., different social media domains or user contexts), and study how to optimize data-collection interfaces to meet more complex application needs.

970.716285801

====================
The document-level feedback is shown to the user, and the low-quality segments are highlighted as light red in the interface.

969.076233101

====================
1 Similar to precogs in Minority Report [22], who identify and help "resolve" low-quality human action in the future, Precog identifies and helps resolve low-quality data before it is submitted in the future.

968.528508128

====================
We tested this hypothesis by running an experiment, using an existing corpus of Amazon reviews [61].

964.34450368

====================
In the rest of this paper, we use the term document to refer to the value of the acquired text attribute.

948.148660614

====================
I(d, p) =  We instead present a heuristic solution called TCruise whose complexity is linear in the number of paths in the random forest model.

939.196292108

====================
Upon pressing the I'm Done Writing button, the interface displayed our document-level feedback under the text field; for users in the segmentation condition, low quality segments were highlighted red and the related feedback displayed when users hovered over the segment.

934.77701256

====================
We then sort the FEFs by their average scores and take the top k with a score above the threshold t.  7.

931.460394755

====================
Quality control for crowdsourcing has been extensively studied [54] and can be modeled in two phases.

926.963938158

====================
This can be achieved by dynamically identifying these constraint violations and providing feedback to the user.

926.864140156

====================
Thus, three of the FEFs, Informativeness, Topic, and Readability/Grammar, overlapped between the two domains.

905.551185154

====================
Finally, Precog explains why segments were predicted as low quality by selecting the feedback that is most relevant to changing the segment into a high quality prediction.

904.38503678

====================
Our efficient solution called TCruise leverages the structure of random forest models to generate explanations in interactive time.

897.060777233

====================
Quality Control in Crowdsourcing: Quality control is an important research topic in crowdsourced data management [16, 30, 54].

896.591190249

====================
We now describe related work in terms of data acquisition interface optimizations, quality control in crowdsourcing and other post-hoc quality mechanisms specific for text acquisition.

883.273867352

====================
F |pi 6= 0}  Finally, Sfdi computes the responsibility for fi as the sum of all maximal influence paths in all decision trees that improve the predicted utility U ().

877.253196831

====================
The rest of this subsection describes the DDL statements that users can use to specify feedback and interfaces for Precog quality control.

864.494325277

====================
Based on this library, we develop document-level and segment-level prediction models.

859.256186671

====================
Furthermore, in some settings where collecting more data is not an option (e.g., less popular products may not have enough users that are willing to, or equipped to, write reviews), it will be more important to apply pre-hoc quality control.

854.499602623

====================
Our technical contribution is a pre-hoc feedback system for multi-paragraph text.

853.736798766

====================
INTRODUCTION Figure 2: Text acquisition with pre-hoc (beige background) and post-hoc quality control.

823.365752941

====================
By default we use this library for learning quality measures from a corpus.

817.125388233

====================
This results in a 2x2 between-subjects design.

799.007267693

====================
In addition, rather than compute the impact for all possible perturbations, we only consider the minimal perturbation with respect to each path in the tree.

797.196249473

====================
We now formally define these feature-oriented explanation functions (FEFs) and provide examples used in the experiments.

788.631210673

====================
In this section, we describe our approach towards in-depth semantic feedback.

770.644101212

====================
Thus, we decompose the text into segments, and for each low-quality segment predicted by the model, we generate segment-specific feedback.

766.239260301

====================
Overview: In contrast to naive form validation, which simply rejects user inputs with an error message, Precog seeks to accommodate iterative improvements through feedback interfaces.

755.4489487

====================
However, it leaves it up to the user to infer specific improvements to make.

749.924387057

====================
Our approach is inspired by existing feedback systems--model features act as signals to identify text characteristics that the worker should change.

730.07528102

====================
As compared to other features libraries such as LIWC, Precog's main advantage is a high-concentration of data-driven features (topic modeling,  4  5  Available at http://cudbg.github.io/Dialectic  Category Informativeness Topic  # 8 5  Subjectivity  15  Readability and Grammar  15  Similarity  4  Description mined jargon word and named entity stats [64], length measures (word, sentence, etc.

729.230364708

====================
Similarly, auto-complete may be used to provide feedback about existing categories in order to avoid duplicates when collecting categorical text [28, 71] (e.g., ice cream flavors, presidents).

700.703382805

====================
This provides the functionality for our automatic pre-hoc quality control system for free-form text attributes.

693.340395295

====================
For instance, multi-paragraph text attributes such as product reviews, forum comments, or rental descriptions are particularly challenging for several reasons.

692.532632941

====================
A detailed explanation of the four conditions is shown in Section 7.2.2.

690.980578641

====================
Feature Library for Text Quality  PREDICT  Precog takes as input a training corpus of documents and document-level quality labels, and trains two models-- document-level and segment-level prediction models--in order to provide document-level and fine-grained segment-level feedback.

685.901665488

====================
](minp(d, qij ))  If two paths within a tree perturb the same set of features, we only consider the path with the maximal impact score.

683.41850916

====================
Figure 11 shows a similar chart for the coder's subjective opinion of the improvement.

671.808950791

====================
Segment-Predict-Explain: Based on these observations, Precog automatically identifies low-quality portions of a document, and generates feedback to help improve the identified issues.

661.782654679

====================
One solution is 5 6  EXPLAIN  5.1  Problem Background  Our problem is closely related to model explanation, which generates explanations for a model's (mis-)prediction.

660.246468603

====================
(e.g., readability, informativeness, etc), and implement a representative and extensible library of 47 text quality features.

650.720446441

====================
We then synthesized existing research to write 4 explanation functions for each domain, with 3 overlapping between the two.

642.674079715

====================
The third coder was trained by being shown the Amazon or Airbnb corpus, examples across the quality spectrum, and the other two coders.

633.812260052

====================
Protocol and Rubric for Assessing Quality: Three independent evaluators (non-authors) coded the pre and post-feedback documents using a rubric based on prior work on review quality [18, 55, 67] and Airbnb profile quality [57].

612.509387914

====================
reduces the developer's efforts by allowing them to express the quality score in terms of model features by defining a FEATURE table, and to define explanation functions over features of the text attribute.

609.39423669

====================
In addition to boolean constraints such as domain, foreign key, and uniqueness constraints, Precog also supports quality scores.

601.299486651

====================
]Rn  P(d) =  [  Rather than examining all possible perturbations, our heuristic to compute Sfdi restricts the set of perturbations with respect to the decision paths in the trees that increase d's utility.

597.379618602

====================
For instance, Amazon product reviews and users may be modeled using the following crowdbased DDL statements.

585.20553951

====================
The second states that a review is written for a given product in the products table, and contains a numerical rating as well as the text of the review.

580.781675484

====================
Additionally, our Segment-Predict-Explain pattern addresses on free-form text entry that complements their focus on simple data types.

576.182728734

====================
The offline components (blue arrows) take as input a corpus of training data in the form of user generated text documents and their labels--for instance, Amazon product reviews may be labeled by the ratio of "helpful" and "unhelpful" votes.

574.421432695

====================
2 +15 However, there can be an infinite number of perturbations that all improve the utility--which should be selected?

570.663183603

====================
3  function is used for domain constraints on reviews.rating and users.age.

562.207350892

====================
For instance, Amazon already has a corpus of high and low-quality reviews, and similarly for other applications.

561.660202813

====================
Although developers can easily implement their own FEFs, Precog is pre-populated with 5 FEFs that work across the two application domains used for evaluation.

555.520200413

====================
For both Product Review and Host Profiles, we performed Two-Way ANOVAs with both the Overall Quality Im11  knowledge, Precog is the first system that systematically supports Precog for a wide range of data types and quality specifications (constraints and quality scores).

552.761036436

====================
The primary features that we do not include are those that rely on application metadata such as the worker's history or location, which may be predictive of quality but not related to the writing content, and cannot be mapped to actionable writing feedback.

550.016373778

====================
The left column shows the feedback interface generated by default.

544.946871535

====================
]P(d),pi 6=0  Putting this together, we can define the responsibility score Sed of a feature explanation function (FEF) e as the average of its bound features; where Fei [?]

543.849169458

====================
Although they are interpretable for simple constraints such as domain violations, the language for the uniqueness violation requires database familiarity and may not be accessible to non-technical experts.

543.071096258

====================
We then gave participants the opportunity to revise their submission; to avoid bias, we noted that they were not obligated to.

540.068310401

====================
Segmentation: Contributor rubrics across many social media services are structured around topics [2, 92, 96], and psychology research suggests that mentally processing the topical hierarchy of text is fundamental to the reading process [41].

540.042147824

====================
The key challenge is that training data only contains quality labels for entire documents (e.g., helpfulness for the full review), and it is unclear how to leverage them for training a segment-level model.

528.297933681

====================
Rather than define a concrete quality measure, Precog automatically learns the quality measure from a training corpus that contains documents along with their quality labels (for the entire document, not each segment).

521.302722701

====================
We address the former challenge using a data-driven approach that learns a quality measure from data that has already been acquired.

510.526174828

====================
The basic idea is to push data-quality constraints down to the data collection interface rather than validate them after data acquisition.

507.714443639

====================
We then normalize a feature's responsibility Sfdi by computing Snormdfi =  d Sf -uf  i  i  sf  .

504.282761451

====================
We found that combining segmentation and TCruise-based explanation outperformed all other conditions by a statistically significant margin for Product Reviews, and outperformed all but the next-best Doc+TCruise condition for Host Profiles.

500.911138743

====================
The key insight is to take advantage of the structure of the random forest model to constrain the types of perturbations and feature subsets to consider.

498.263920198

====================
While such approaches are often supervised in nature, requiring a manual topic ontology [57, 62], we use LDA [8] because it is unsupervised and can be quickly trained on any corpus without any cost to the developer.

492.89301592

====================
However, such systems would not recognize that the review can be most improved by simultaneously reducing the emotion in the text and including more product details that ultimately increase the length.

488.455645003

====================
Section 3 describes the Segment-Predict-Explain pattern that helps developers easily customize interface for text attributes.

483.185835193

====================
Unfortunately, this procedure is not effective for non-continuous or low cardinality features such as one-hot encoded features (e.g., each word is represented as a separate binary feature) common in text analysis.

482.513107378

====================
For instance, the following defines the function for Off-Topic text:  7.1  Precog for Hard Constraints  Although it is intuitively obvious that form feedback and custom interfaces should improve quality, we quantify the amount using the example from Section 2.

480.671471854

====================
For example, the following specify the star interface for rating and the autocomplete interface for product: CREATE INTERFACE ON reviews(rating) USING "stars" FROM "interfaces.js" AND explanation_function; CREATE INTERFACE ON reviews(product_id) USING "autocomplete" FROM "interfaces.js" AND explanation_function;  It addition, custom interfaces can be used to provide feedback that goes beyond textual feedback (e.g., visualizing distributions of common numerical values), or that is at a finer granularity than for the entire attribute.

476.89869329

====================
SEGMENT-PREDICT-EXPLAIN  The challenge with directly developing Precog quality control for text is that the quality score and explanation function is difficult to express as a concrete function, and they must be customized for the application domain.

474.851525772

====================
For instance, we might replace the rating domain constraint with five stars similar to Yelp and other social websites.

473.368994055

====================
Post-hoc Approaches for Text Acquisition: A dominant approach is to filter poor content [84] such as spam; sort and surface higher quality content [1, 37, 86] such as product reviews [67], answers to user comments [90, 95], or forum comments [82]; or edit user reviews for clarification or grammatical purposes [6, 42, 48].

470.893259041

====================
We evaluate Precog for product_id (foreign key constraint) and rating (domain constraint) from the reviews table.

464.781241234

====================
1  In fact, instances of pre-hoc quality control are already commonly used in practice, both in the survey design literature [36] and as form design throughout the Internet.

462.325965649

====================
We assume that the interface is a javascript function (say, as an AngularJS [19] or ReactJS [26] component); the constructor takes as input a Precog-provided getFeedback method that retrieves feedback from the Precog server.

460.80847353

====================
Procedures: Participants writing product reviews were asked to write a review of their most recently owned laptop computer "as if they are trying to help someone else decide to buy that laptop or not and are writing on a review website like the Amazon store".

460.173781389

====================
Crowd-based feedback is effective, but can take 20 minutes to generate feedback [52] and are essentially posthoc because they create new crowd tasks to refine previously submitted ones.

458.472269819

====================
behind-the-enemy-lines.com/2011/04/want-to-improvesales-fix-grammar-and.html, 2016.

456.748899477

====================
Precog is able to adopt to the domains' different quality measures (helpfulness vs trustworthiness) with small configuration changes.

454.702219535

====================
* A data-driven approach to estimate quality for text attributes, including a categorization and implementation of 47 text quality features from a survey of the literature.

453.54934037

====================
To summarize, each participant was randomly assigned to one of four conditions: Doc+Krause, Seg+Krause, Doc+TCruise and Precog (Seg+TCruise ).

453.031498757

====================
The review rubric asks coders to scores reviews on helpfulness to laptop shoppers, and the host profile rubric asks coders to score profiles based on trustworthiness to potential tenants.

444.258285576

====================
We identify five main categories across the existing literature (Table 1).

441.260439977

====================
We conduct statistical tests to further investigate the results.

424.698595498

====================
The main idea is to scan each tree in the random forest and compute responsibility scores local to the tree.

420.518618807

====================
In general, we must account for the amount that a feature must be perturbed, and the number of other features that must also be perturbed, in order to improve the classification.

419.651750967

====================
al describe the meaning of the three Airbnb criteria in [57]: Ability "refers to the host's domain specific skills or competence."

408.974736432

====================
Participants writing Airbnb profiles were asked to "pretend that [they] are interesting in being a host on Airbnb" and to "write an Airbnb profile for [themselves]".

403.464244567

====================
Each worker was randomly assigned to one of three conditions, one for each of the interfaces shown in Figure 7.

398.137654304

====================
For Host Profiles Precog improved the overall measure by nearly 7.1x over the baseline (0.65 vs. 0.07 increase), and a 1.7x improvement over the next-best Doc+TCruise condition.

396.526960501

====================
This groundwork reduces the task of applying Precog to new domains.

396.02458607

====================
We then use explanation functions to transform the most responsible features into prescriptive feedback for the user.

394.739618338

====================
Crowddb: answering queries with crowdsourcing.

394.217567409

====================
We trained workers on a separate sample of segments, along with explanations of why each segment was helpful or unhelpful.

393.28696135

====================
These include guidelines and constraints on form elements [36, 69], as well as interface techniques such as double entry [20] commonly used for picking passwords.

391.74775989

====================
The general approach is to survey quality assessment research in a domain to borrow useful features and explanations.

387.654101696

====================
In order to generate targeted feedback, Precog automatically identifies topically coherent portions and segments the document in order to analyze each segment individually.

386.85602426

====================
Further, review hierarchies were proposed for hierarchical crowdsourced quality control using expert crowds [39].

386.132678508

====================
By tackling low-quality data pre-acquisition, it can reduce or eliminate the need for post-hoc quality control.

381.317786585

====================
The classic approach is to use simple, interpretable models [13, 53, 88] or to learn an interpretable model using the training  https://www.reddit.com/r/askscience/ We define > 1 net up-votes as helpful and <= 1 as unhelpful.

379.407671526

====================
Figure 10 plots the mean change and 95% boostrap confidence interval for the four rubric scores.

378.253940559

====================
Thus, we wrote a friendliness explanation function that suggested writing more friendly and inclusive prose, and bound it to the relevant LIWC features (social, inclusive, etc).

371.623241848

====================
The online components (green arrows) send the contents of a text input widget, along with an optional corpus name, to the webserver.

367.975780505

====================
For quantitative attributes, a common dataquality constraint is to ensure values are not out of bounds (e.g., human age should be above 0).

367.742529844

====================
[6] M. S. Bernstein, G. Little, R. C. Miller, B. Hartmann, M. S. Ackerman, D. R. Karger, D. Crowell, and K. Panovich.

364.94242526

====================
Each facet defines high quality at a different threshold; product reviews and host profiles are shown as the top and bottom rows, respectively.

362.499512894

====================
Finally, when the user hovers over a highlighted segment, more targeted feedback helps explain why it was identified as low quality and how it could be improved.

358.630287321

====================
Figure 4: Examples of three levels of Precog quality control for four classes of data integrity constraints.

358.517452103

====================
provement and Subjective Coder Improvement Scores as the dependent variables, and TCruise and segmentation as the independent variables.

347.639750151

====================
The Model Generator then trains two classification models to predict the quality of a user's overall text submission as well as its constituent segments; these are cached in the Model Store.

344.651200054

====================
Each measure is rated on a scale from 1 (Strongly Disagree) to 7 (Strongly Agree) based on coder agreement with a set of statements mapped to each criterion (i.e., "This person will stick to his/her word, and be there when I arrive instead of standing me up" for integrity).

344.606708115

====================
Automated approaches such as auto-graders primarily focus on predicting quality rather than generating feedback [4, 25, 58, 89]; others are limited to syntactic analysis [27, 35, 63], or generate overly simple writing feedback [7, 10, 49].

342.972777086

====================
Feature Explanation Functions  Section 2 introduced explanation functions that can take as input features in a FEATURE table whose primary key references the desired text attribute.

339.878724795

====================
The impact function I() is identical, however it takes a path qij as input and internally computes the minimum perturbation minp(d, qij ).

337.985713122

====================
Finally, the Similarity category reflects how many quality prediction approaches compare the input document to a gold-standard of text [47, 50].

333.961116148

====================
A similar approach is applicable for regression models as well, where increasing the continuous prediction assigns the perturbation more responsibility.

325.030954822

====================
Consider a single tree in a random forest, consisting of decisions on two features, len and emotion.

318.778688438

====================
i  Picking FEFs: Once the feature scores have been computed, identifying the top-k FEFs is straightforward, and we compute each FEF's average impact score using a series of fast matrix operations.

317.795212469

====================
We then select the maximal  No feedback needed if data point already has high utility.

311.631466641

====================
We created a simple Mechanical Turk task that asked workers to submit the product model of their cell phone along with a 1 to 5 rating for the phone's quality; each 9  worker was paid $0.05 to complete the task.

310.795756146

====================
Once a library of features are given, the document-level prediction turns to be a typical classification problem.

310.309544924

====================
Document Labels for Segments: Despite generating topically coherent segments, we lack quality labels for training the predictive model at the segment level.

307.774261278

====================
We describe this in Section 4.

303.879445996

====================
This means that for n features there are 2n possible sets of (maximal influence) perturbations to naively explore.

301.814080398

====================
impact paths for each tree; for each path, we add the responsibility score of all features perturbed in its minimum perturbation p. The final scores are used to select from the library of explanation functions.

299.511994975

====================
Finally, the most sophisticated may change the input element itself in order to constrain or fully customize the feedback (right column).

297.391614196

====================
For instance, len FEATURE len_extracton defines the feature returned by the user-defined function len_extracton.

296.66334947

====================
For instance, consider a document that contains a single segment--the segment may be high quality but the overall document is too short and is missing text for other topics.

295.47844632

====================
We compared a segment binary classifier trained under this assumption with human evaluation.

292.039875452

====================
We observe that document quality is sufficiently correlated with segment quality, and a document's label can be used to label its segments as training data for a segment classifier.

290.461770555

====================
For hard constraints (Purple), user inputs are sent to the  4  jargon usage, text similarity measures) that are trained to fit each developer's unique corpus.

288.71669833

====================
[36] R. M. Groves, F. J. Fowler Jr, M. P. Couper, J. M. Lepkowski, E. Singer, and R. Tourangeau.

286.614314616

====================
The backend splits the review into coherent segments, identifies the low-quality segments, and generates document-level feedback.

282.635875089

====================
The core challenges are to (1) identify a proxy for text quality that is consistent with the downstream application's needs, and (2) to generate effective feedback text.

281.573732028

====================
Participants were randomly assigned to one condition group; with (21,26,22,23) participants in conditions (1,2,3,4), respectively.

280.146899581

====================
The final submission was considered the post-feedback submission, and the initial submission upon pressing the I'm Done Writing was the pre-feedback submission.

279.296549641

====================
]E  Sfdi =  The TCruise Heuristic Solution  X  X  I(d, qij ) if U (vij ) > U (M (d))  Ti [?

271.880360256

====================
For the reviews and profiles experiments, Precog acquires >= 2x and >= 2.6x more high quality documents than the baseline for thresholds of 5.5 and 6, respectively.

270.72976941

====================
An alternative is to use existing model explanation algorithms [76] to describe the prediction.

269.822957852

====================
Normalization: We find that features closer to the root will happen to occur in more feature sets and have artificially higher scores, thus we need to adjust feature impact scores to reduce bias.

269.080708857

====================
However, it still leaves it up to the user to infer specific improvements to make.

266.368349669

====================
Note that the same explanation 2  Note that the developer may express a CHECK constraint and the database can generate an (indecipherable) error message.

265.705561442

====================
In this example, there are two ways to perturb the feature vector: by reducing the emotion feature by at least 20, or by increasing the length by at least 10 and reducing the emotion by at least 15.

262.38571636

====================
One approach is to simply highlight the low-quality segment and provide generic/static feedback.

255.142641126

====================
At this point, users could click the Recompute Text Feedback button (median 1 click/participant), or press Submit to submit and finish the task.

253.008515184

====================
Peerstudio: Rapid peer feedback emphasizes revision and improves performance.

252.793053326

====================
For this reason, we first define the maximum influence perturbation set PF of a given subset of features F [?]

247.22633487

====================
In practice, an FEF takes as input a list of features, as well as the text document and the full feature vector, and returns feedback text.

247.185310286

====================
Although these user defined functions are powerful enough to support arbitrary analysis of an attribute value, such an approach is difficult to compose and extend, and the feedback is still limited to the entire attribute value.

245.520623561

====================
If the features topics, featureCnt, and textLen have high responsibility, then it will be called to recommend new product features that the worker should mention in the review; the recommendations are dynamically selected based on the text's topic distribution (topics) and the number of product features detected (featureCnt < 10):  Setup: Let d [?]

242.690665892

====================
A closely related work from the database community is Usher [15], which have similar goals to improve data collection quality.

240.866592015

====================
Our model performs competitively with prior work [32].

238.936341545

====================
In these examples, we simply define a python function.

238.691756961

====================
The resulting model (85% accuracy, balanced test set) was competitive with existing work [31].

236.318236701

====================
]Q (d) i i  The space of solutions for Problem 1 relies on enumerating all possible elements in the power set of the feature set F, which is exponential in size: 2|F | .

235.869096316

====================
Though Precog demonstrates the feasibility of such automated interfaces, it also reveals several areas of improvement.

235.392882822

====================
When the topic within the window changes significantly, then TopicTiling creates a new segment.

234.90614957

====================
Precog uses existing techniques to generate forms for crowd workers to fill out, and the form contents are inserted as new records into the corresponding crowd table.

234.834814825

====================
We did not require new features for product reviews; we simply label reviews with >= 60% helpful votes as high quality and low otherwise.

233.767190952

====================
Given the feature vector of a data point d, prediction model M , a set of FEFs E = {e1 , * * * , em }, return the top k FEFs whose responsibility is above a threshold t:  Fp = {fi [?]

232.106216077

====================
The first states that user information is collected from the crowd (of Amazon users) and that the username must be unique.

232.079109689

====================
Figure 11: Subjective agreement to: "The post-feedback revisions improved on the pre-feedback review."

231.859608395

====================
Further, the set of maximum influence perturbations is the union of PF for all feature sets:  minp(d, qij ) = arg min |p|2 s.t.

230.802072467

====================
Indirect Quality Mechanisms: Indirect methods such as community standards and guidelines [2, 5, 70] help clarify quality standards, while up-votes and ratings provide social incentives [11, 66].

226.273711351

====================
Survey Design and Optimization: The survey design literature has studied ways to re-ordering, and designing survey forms in order to reduce data entry errors.

223.487369678

====================
4.2  Document-level Prediction  to manually label the generated segments, but this will be very costly and time-consuming.

221.351955595

====================
The Journal of Forensic Psychiatry & Psychology, pages 1-21, 2017.

220.809908907

====================
To contrast, we focus on using explicit constraints and ambiguous quality measures (for text) and provide explicit DDL statements to push them to the input interface.

220.760577456

====================
We define Qi as the set of maximal impact paths of a tree Ti , with at most one path for a given subset of features.

219.704648805

====================
Let minp(d, qij ) return the minimum perturbation p (based on its L2 norm) such that d matches path qij .

217.238532385

====================
We assume that the domains of the features have been normalized between [0, 1].

216.495441878

====================
However this work either focuses on a particular application [91], or not intended to support custom interfaces [72].

214.686389132

====================
TKDE, 2016.

214.27489995

====================
Further, developers can easily extend the library with custom features.

213.978464031

====================
Fminp(d,q) = Fminp(d,q0 ) }  Problem 1 (Prescriptive Explanation).

213.474512201

====================
We thus assign each participant to one of four conditions.

210.616687153

====================
In contrast to typical integrity constraints, which will reject an inserted record that violates the constraint, Precog seeks to maximize its value.

208.26502883

====================
Although there are numerous segmentation algorithms, we describe the rationale for the choice of using a topic-based segmentation algorithm.

208.078393687

====================
These naturally map to 4 of our feature categories, so we wrote explanation functions for each and bound them to the features in the corresponding category.

207.965950501

====================
Customized Feedback: Precog provides a DDL for developers to customize feedback.

207.576629399

====================
Rmxn represent the features bound to each of the m FEFs, where Aji = 1 if feature fi is bound to FEF ej , ~ e otherwise 0.

206.711594271

====================
The full set of coder statements is described at length in [57].

205.14177991

====================
An example will be shown in Section 5.2.

203.623392868

====================
Argonaut: macrotask crowdsourcing for complex data processing.

203.5521634

====================
4.3  Segment-level Prediction  There are two challenges in training a segment-level prediction model.

202.68087151

====================
Precog is agnostic to the specific segmentation algorithm, and developers can use their own.

202.161571754

====================
As constraints become more complex, there is a need for customized messages.

199.454625213

====================
For instance, the bottom row of Figure 4 illustrates fine-grained feedback in the form of both highlighted text and text feedback for individual segments that the user has written for reviews.review.

196.779074493

====================
Figure 8 plots the number of high quality tuples that were collected as a function of the number of completed tasks; we define a tuple as high quality if no constraints were violated.

195.671089215

====================
Participants were randomly assigned to one condition group; all conditions had 21 subjects except the Precog condition which had 22.

193.108926443

====================
Estimating the helpfulness and economic impact of product reviews: Mining text and reviewer characteristics.

192.951588685

====================
Although there might be a number of segments mislabeled, the model can tolerate their impact well and achieve good performance.

188.958202514

====================
[38] I. Guyon, J. Weston, S. Barnhill, and V. Vapnik.

186.664051892

====================
Intuitively, the FEF should be executed if its list of features F can take "highly responsibility" for improving the quality score.

186.430069648

====================
Their work identified a subset of the Linguistic Inquiry and Word Count (LIWC) features [73] and other features as useful for measuring trustworthiness.

185.160833429

====================
The Segment-PredictExplain component has a beige background: Blue arrows depict the offline training and storage process and Green arrows depict the online execution flow when a user submits.

184.206576389

====================
Developers commonly implement explanation functions to generate more user-friendly feedback (middle column).

183.773939298

====================
support.google.com/docs/answer/57859, 2016.

183.772287743

====================
Figure 4 summarizes Precog into three levels based on the amount of customization needed by the developer.

182.661862462

====================
Dij ), and the output of the random forest M (d) = arg maxv |{1|vij = v}| is the majority vote of its trees.

181.833012083

====================
71.3% had written a prior product review; all had read a product review in the past.

178.54160687

====================
Given d and predicted utility U (M (d)), we retrieve and scan the paths with higher utility.

177.241587991

====================
Second, it is ill-defined and applicationdependent, thus difficult to specify as a constraint.

175.718139116

====================
Overall Quality is the holistic helpfulness of the review for prospective buyers.

174.745935881

====================
First, the quality measure is continuous (there is no "perfect document") and thus hard to identify a "violation".

173.076679777

====================
Truth discovery and crowdsourcing aggregation: A unified perspective.

173.037117494

====================
5.2  Figure 6: Assigning responsibility to perturbations.

172.982224801

====================
4.1  Existing automated writing feedback tools primarily focus on syntactic, simple errors [27, 35, 63].

170.636074381

====================
They pre-compute the "typical" values of each feature in the high quality corpus, then identify the "atypical" outliers in the test data's feature vector (e.g., a feature whose value is 1.5 standard deviations from the mean).

168.52358803

====================
Subjectivity assesses user bias using a variety of features ranging from sentiment analysis [32, 34, 56] to pronoun usage [73].

166.857842483

====================
Thus, it is clear that the emotion should be assigned a greater responsibility because there are more branches for which changing its value will contribute to a better classification.

165.997033242

====================
For instance, qualreview seeks to maximize the quality score as defined by qual_udf.

165.677696678

====================
Precog denotes the segment-level TCruise-based system.

164.70152969

====================
[28] M. J. Franklin, D. Kossmann, T. Kraska, S. Ramesh, and R. Xin.

164.106976002

====================
Subjectivity is the extent that the review is fair and balanced but with enough helpful opinions for the buyer to make an informed decision: 1 means the review is an angry rant or lacks any opinions while 7 means it is a fair and balanced opinion.

162.709099027

====================
Purple arrows show the feedback process for hard constraints.

162.431034188

====================
Challenges in data crowdsourcing.

161.948291901

====================
For each scanned path q, we compute the change in the utility function, discount its value by the minimum perturbation p as well as the path's confidence.

158.600795718

====================
](p)  C can be chosen based on the model--for a random forest, we define C as the percentage of trees that vote for the majority label.

157.142030254

====================
, qik ; each path qij matches a subset of the training dataset Dij [?]

155.26061676

====================
The green path (p1 ) must at least reduce emotion by -20; the blue path (p2 ) must at least increase length by 10 and at least reduce emotion by -15.  input text.

154.615395199

====================
We used a qualification task to ensure participants had ever owned a laptop.

154.09819431

====================
TopicTiling outperformed other topic segmenters [44, 65] in terms of their WindowDiff score [74] as compared to a hand-segmented test corpus of 40 documents.

153.905493956

====================
Other explanation functions (Topic, Informativeness) suggested specific content for the user to write about, mined from high-quality documents from each corpus (i.e., topics, jargon).

152.112421576

====================
Custom Interface: Fully customizing the interface component is useful in order to directly prevent users from submitting invalid attribute values.

151.49761344

====================
Consider the perturbations p1 , p2 in Figure 6.

149.9654788

====================
Participants were told that upon submitting their writing, they may receive feedback and could optionally revise.

147.45093652

====================
Some constraints, such as domain constraints, are registered as syntax errors.

146.905791499

====================
All trustworthiness factors except friendliness directly corresponded to existing explanation functions.

144.939499351

====================
It will cause the impact function to converge to 0 as the perturbations become larger.

142.80785989

====================
On violations, the feedback generator creates custom feedback (if specified in a DDL statement) and the default or customized interface displays the feedback.

142.391702749

====================
It uses a sliding window to compute the LDA [8] topic distribution within each window and create a new segment when the distribution changes beyond a threshold.

141.99963222

====================
Moreover, there have been many successful attempts to use topic distributions to predict quality [55, 57, 57].

140.857652717

====================
In many cases, such as text attributes, it is desirable to provide feedback for specific segments of the text value.

140.550494065

====================
However, Precog is more effective when the threshold increases.

140.376031298

====================
[44] J. C. T. Ji-Wei Wu.

139.609845878

====================
[9] R. Boim, O. Greenshpan, T. Milo, S. Novgorodov, N. Polyzotis, and W. C. Tan.

139.344739606

====================
The developer then binds an explanation fuction to the appropriate constraint.

138.851769054

====================
The second challenge is to determine how the available document-level labels can be used for training segment-level quality.

137.619399929

====================
Each measure is the average of the ratings from two coders--if they differed by >= 3, a third expert coder was used as the tie breaker and decided the final value.

137.167794979

====================
The default simply renders feedback generated from database constraint violations on tuple insertion (left column).

136.16585034

====================
For the foreign key constraint, we populated a products table with all cell phone product models from the Amazon product corpus and a comprehensive list of phone models [93].

135.316589211

====================
[30] H. Garcia-Molina, M. Joglekar, A. Marcus, A. G. Parameswaran, and V. Verroios.

135.021493076

====================
For these, Precog generates default names of the form <table>_<attribute>_<type>.

134.005157749

====================
The feedback literature suggests that precise, local feedback is effective [68].

133.219180733

====================
Figure 7 depicts the three interfaces that are created--naive with no Precog, customized feedback, and customized interface optimizations.

133.200228613

====================
For the sake of exposition, product_id is the textual name of the product.

133.160262901

====================
For product reviews, Informativity is the extent that the review provides detailed information about the product, where 7 means that the review elaborates on all or almost all of the specifications of a product while 1 means that it states an opinion but fails to provide factual details (e.g., laptop specifications).

132.974826026

====================
Such latency difference is relatively small if we compare the end-to-end time of two systems since the majority of the time was spent on worker recruitment.

130.000271239

====================
This can be directly computed by examining the decision points along the path.

126.486967058

====================
Thus, the output of Ti (d) is the vote vij of the path that matches d (e.g., d [?]

125.469589354

====================
User-facing Interface: The custom interface column for the quality score in Figure 4 depicts the Precog interface in action.

125.015008684

====================
Designing novel review ranking systems: predicting the usefulness and impact of reviews.

124.42267873

====================
Journal of Language and Social Psychology, 35(4):435-445, 2016.

123.626493274

====================
The Segment-Predict-Explain component consists of offline and online components.

122.528274983

====================
An overview of current research on automated essay grading.

122.342691084

====================
Similarly, Airbnb profiles took an average of 10.2 minutes to complete without Precog and 15.3 minutes to complete with Precog.

121.838656827

====================
Each defines the three main measures, and provides examples that contribute positively and negatively to each criteria.

121.664654482

====================
Precog uses the feature library to transform the input text into a feature vector of (len=10, emotion=30), and is thus classified as low quality.

121.65093232

====================
The Feedback Generator then constructs feedback explanations for the low quality text, which are returned and displayed in the widget.

120.832285613

====================
Usher analyzes an existing corpus of collected data to dynamically learn soft constraints on data values, and focuses on input placement, re-asking, and some interface enhancements.

120.386076716

====================
For instance, in a binary classification problem U may return 1 if the input is "high quality" and 0 otherwise; in a regression model, U may be the identity function.

120.015208544

====================
[43] P. G. Ipeirotis, F. Provost, and J. Wang.

119.80391732

====================
Rn be a data point (text document or segment) represented as a feature vector, where di corresponds to the value of fi .

119.572900576

====================
Figure 7: Worker interfaces to evaluate no optimization, custom feedback Precog, and custom interface Precog for hard constraints.

118.908161858

====================
An FEF e : R|F| - text maps the feature vector for a subset of features F [?]

117.483782198

====================
[39] D. Haas, J. Ansel, L. Gu, and A. Marcus.

114.981833096

====================
In Eighth International AAAI Conference on Weblogs and Social Media, 2014.

114.066617524

====================
Reading through their table of features, we also found that writing style and friendliness features were common.

113.54768763

====================
Precog uses the models in the Model Store to identify whether the entire document and/or segments generated by the Segmenter are low quality.

113.263229136

====================
[47] S.-M. Kim, P. Pantel, T. Chklovski, and M. Pennacchiotti.

113.205667005

====================
Moreover, Precog also makes it easy for developers to add custom segmentation algorithms.

112.585796393

====================
However, we may use a slider if for larger cardinalities.

111.746011698

====================
Assuming that C() = 1, p1 's impact on the input document is I(d, p1 ) = 1-0 x1= 20 0.05, whereas p2 's impact is I(d, p2 ) = 1021-0 x 1 = 0.055.

111.198860432

====================
Developers can bind the interface to an attribute using a CREATE INTERFACE statement.

109.387871657

====================
Feedback and interface customization acquire 1.7x and 1.9x more high quality tuples than no Precog optimization.

109.340187578

====================
For each feature fi , we compute the responsibility for each low quality text, and aggregate their values to compute the sample mean ufi and standard deviation sfi .

109.251445746

====================
]Fe  C(d) =  i  |Fe |  x C(d + minp(d, qij ))  |{dk [?]

108.838076252

====================
A tree Ti is composed of a set of k decision paths qi1 , .

108.576826148

====================
The confidence C(d) is the fraction of samples in Dij whose labels yk match the path's prediction vij .

107.99254074

====================
[13] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad.

106.114740139

====================
Ability "refers to the host's domain specific skills or competence."

105.798630133

====================
Feedback and interface customization acquire 1.7x and 1.9x more valid records than no Precog optimization.

104.236223835

====================
[48] A. Kittur, B. Smus, S. Khamkar, and R. E. Kraut.

104.079990395

====================
[32] A. Ghose and P. G. Ipeirotis.

103.874881673

====================
Since the quality score is not a boolean constraint, feedback is simply not generated for it2 .

102.690873532

====================
3 Note that databases automatically generate names for almost all integrity constraints.

101.948466

====================
Consider a review consisting of a long, angry diatribe about customer service.

99.7341406617

====================
[31] A. Ghose and P. G. Ipeirotis.

99.4804325187

====================
[41] J. Hyona, R. F. Lorch Jr, and J. K. Kaakinen.

99.2170136929

====================
We used a post-study survey to collect demographic information as well as their subjective experience.

98.9755870611

====================
The basic idea is to push data-quality constraints down to the data collection interface and improve data quality before acquisition.

98.6544061543

====================
REFERENCES  [25] N. Farra, S. Somasundaran, and J. Burstein.

98.0202491263

====================
The key insight is that the predictive model is robust to noisy labels.

97.6968604462

====================
We now describe the prediction model we use for documentlevel prediction.

97.5958932136

====================
[1] E. Agichtein, C. Castillo, D. Donato, A. Gionis, and G. Mishne.

97.0279201227

====================
In the long term, we envision Precog as an example of automatically applying pre-hoc quality control (e.g., writing feedback) based on downstream application needs (e.g., quality reviews).

96.7890256237

====================
F is the set of features bound to an FEF: P Sed =  fi [?

96.2923251978

====================
[3] N. Archak, A. Ghose, and P. G. Ipeirotis.

95.742621076

====================
[71] A. G. Parameswaran, H. Park, H. Garcia-Molina, N. Polyzotis, and J. Widom.

94.771002263

====================
We describe how Precog automatically generates feedback text for low-quality text.

94.714289553

====================
[11] A. Bosu, C. S. Corley, D. Heaton, D. Chatterji, J. C. Carver, and N. A. Kraft.

94.1572532637

====================
Recall the feedback in the custom Precog interface in Figure 4, it identifies that the segment is short on details and suggests new topics.

93.5426277071

====================
Overall Quality is the holistic trustworthiness of the host for prospective tenants.

93.4956250225

====================
Benevolence "refers to the host's domain specific skills or competence."

93.4221018865

====================
[57] X. Ma, J. T. Hancock, K. L. Mingjie, and M. Naaman.

93.1116279331

====================
F as the set of perturbations that only perturbe features in F and have the maximal influence.

92.5658505987

====================
Moreover, none focus on multi-paragraph text attributes such as product reviews or forum comments.

92.0683311782

====================
The following snippet sketches the Not Enough Detail function in our evaluation.

91.5064340794

====================
The user writes a product review in the textbox; the content is sent to the Precog backend via getFeedback().

91.3725880761

====================
The change in these measures between pre and post-feedback suggests the utility of the feedback.

89.8264506694

====================
D and its vote vij is the majority label in Dij .

89.4336569152

====================
In isolation, existing approaches may find that the length is large and suggest reducing it, and that the emotion is high and suggest reducing it.

89.0760638853

====================
Dij |yk = vij }| |Dij |  Qi (d) = {q [?]

88.4497896098

====================
In addition, we do not compare paths across trees.

88.4060721407

====================
Texttiling: Segmenting text into multi-paragraph subtopic passages.

88.0145780681

====================
Clearly, document quality assessment is a well-studied area.

86.3814677868

====================
html?nodeId=201929730, 2016.

86.1244308407

====================
quora.com/What-percentageof-questions-on-Quora-have-no-answers, 2016.

85.7917004702

====================
Automatically assessing review helpfulness.

85.0755391661

====================
[29] J. Gao, Q. Li, B. Zhao, W. Fan, and J. Han.

84.835854732

====================
For instance, F may be the text features described above, and a data point corresponds to the extracted text feature vector.

84.7470201913

====================
These methods focus more on finding good contributors and lack content-specific feedback (e.g., discuss camera quality for a phone).

84.5488213025

====================
Feedback systems are typically based on outlier detection [50].

84.4637710623

====================
Fan, G. Li, B. C. Ooi, K. Tan, and J. Feng.

83.7159895203

====================
qij matches d + p p[?

83.3456335437

====================
](p) = |p|2 , the L2 norm of the perturbation vector.

82.3673118913

====================
Ultimately, existing feedback and explanation approaches are descriptive of the prediction, rather than prescriptive of the changes that must be made.

82.3139543419

====================
Crowdsourced data management: A survey.

82.1726228026

====================
[69] K. Norman, S. Lee, P. Moore, G. Murry, W. Rivadeneira, B. Smith, and P. Verdines.

81.4840301729

====================
: analyzing and predicting youtube comments and comment ratings.

81.0814309681

====================
We relaxed the foreign key constraint by ignoring case sensitivity of the product names.

81.0232948342

====================
Precog can automatically control the generated feedback by reallocating responsibility.

79.9604063516

====================
The average task completion time was 11 minutes, and payment was $2.5 (~ $13.6/hr).

78.5560713525

====================
[53] B. Letham, C. Rudin, T. H. McCormick, D. Madigan, et al.

78.4891623381

====================
We plot CDF curves for the number of high quality documents as the task budget increases.

77.9601977213

====================
[81] V. S. Sheng, F. Provost, and P. G. Ipeirotis.

77.5733055147

====================
[8] D. M. Blei, A. Y. Ng, and M. I. Jordan.

77.2251103362

====================
In contrast, segment level feedback is needed in order to provide specific, actionable suggestions that may not be evident at the document level.

76.5081365107

====================
[18] L. Connors, S. M. Mudambi, and D. Schuff.

75.9958873518

====================
The average host profile took 6.8 minutes to complete without Precog, and 11.1 minutes with the additional feedback from Precog.

75.7482108281

====================
The average task completion time was 14 minutes, and payment was $2.5 (~ $10/hr).

75.4268076863

====================
Crowdsourced enumeration queries.

75.4152937426

====================
Crowdforge: Crowdsourcing complex work.

74.1754503024

====================
Survey on web spam detection: principles and algorithms.

73.9577309576

====================
The coders labeled documents in random order and did not have access to any other information about the documents.

73.5597943164

====================
Features are individually mapped to pre-written feedback text [7, 10, 49].

73.551589922

====================
The experiment was run until 100 workers had participated in each condition.

73.4339636785

====================
The paths go from the document's current low quality classification to a high quality classification.

72.7415963159

====================
database, which checks that the input satisfies the integrity constraints.

71.8223697653

====================
[14] A. Chalamalla, I. F. Ilyas, M. Ouzzani, and P. Papotti.

71.4972019784

====================
A method to automatically choose suggestions to improve perceived quality of peer reviews based on linguistic features.

71.2724046061

====================
for product reviews, and "The post-feedback revisions are more trustworthy than the prefeedback profile."

71.1400180244

====================
[49] J. Krause, A. Perer, and K. Ng.

70.3274902067

====================
Although the data cleaning literature has proposed ways to prescribe data cleaning operations [14], they are not applicable for text attributes.

69.5003596839

====================
We also used document-quality labels to train the segment classifier.

68.1797236871

====================
Scoring persuasive essays using opinions and their targets.

67.9383026525

====================
[90] G. Wang, K. Gill, M. Mohanlal, H. Zheng, and B. Y. Zhao.

67.9120644177

====================
The random forest model M = {T1 , .

67.7681927096

====================
]F  Based on these definitions, the total responsibility of a given feature fi [?]

67.2652097249

====================
[23] M. Drouin, R. L. Boyd, J. T. Hancock, and A. James.

66.9117127374

====================
What in the hay is a zappos premier reviewer?

66.9060008014

====================
jury selection for decision making tasks on micro-blog services.

66.7620841803

====================
In SIGMOD, pages 445-456, 2014.

66.7515655568

====================
improving data quality and data mining using multiple, noisy labelers.

65.4624851756

====================
[54] G. Li, J. Wang, Y. Zheng, and M. J. Franklin.

64.8522777608

====================
http://www.zappos.com/premier-reviewers, 2016.

64.1334120792

====================
When the threshold is low, it is easy to acquire low-quality text and both approaches are the same.

63.9471161728

====================
Pn j Aji is the average i=1 impact score of all features mapped to the jth FEF.

63.7954997289

====================
[21] S. Deterding, D. Dixon, R. Khaled, and L. Nacke.

63.1699831447

====================
In System Sciences (HICSS), 2011 44th Hawaii International Conference on, pages 1-10.

62.8285456276

====================
Given a small test corpus of pre-segmented documents, Precog can benchmark the algorithms and recommend the one with the highest WindowDiff score.

62.7383672077

====================
A path is the sequence of decisions from the root of a tree to a leaf node.

62.3797149252

====================
Quality management on amazon mechanical turk.

62.2103995403

====================
In SIGMOD, 2015.

61.9193829984

====================
Incentive mechanisms such as badges, scores [21, 33], status [97], or even money [42, 46] have also been used to keep good contributors.

60.8827557086

====================
In KDD, 2015.

59.9726129293

====================
In Review of educational research, 1988.

59.5911597014

====================
[60] D. M. Markowitz and J. T. Hancock.

59.4875845812

====================
Readability is the extent that the review facilitates or obfuscates the writer's meaning.

59.2764420649

====================
[73] J. W. Pennebaker, R. L. Boyd, K. Jordan, and K. Blackburn.

59.0981455298

====================
How useful are your comments?

59.0592430406

====================
F is based on the responsibility of each perturbation that involves the feature.

58.9429892079

====================
[59] A. Marcus, E. Wu, D. Karger, S. Madden, and R. Miller.

58.0808721402

====================
[15] C. C. Chen and Y.-D. Tseng.

57.506645702

====================
Recommending the world's knowledge: Application of recommender systems at quora.

57.475723175

====================
http://www.boomeranggmail.com/respondable/, 2016.

56.0948611234

====================
[40] M. A. Hearst.

56.0448006214

====================
[16] A. I. Chittilappilly, L. Chen, and S. Amer-Yahia.

55.8797725149

====================
An explicit feedback system for preposition errors based on wikipedia revisions.

55.5852917475

====================
[87] B. Trushkowsky, T. Kraska, M. J. Franklin, and P. Sarkar.

55.4761010944

====================
Individual differences in reading to summarize expository text: Evidence from eye fixation patterns.

55.4141346745

====================
Descriptive and prescriptive data cleaning.

55.379293878

====================
While the idea is easy to achieve for simple data types and constraints, it faces significant challenges for text documents.

54.955108213

====================
These approaches incur additional quality control costs and are complementary to Precog.

54.6275080224

====================
A perturbation p [?]

54.2498757478

====================
There are some works that apply pre-hoc quality control to improving crowd quality [72,87,91].

54.0296563825

====================
In Computational Linguistics.

53.8181487617

====================
[42] P. Ipeirotis.

53.7414005453

====================
foxtype.com/, 2016.

53.3222724012

====================
iCrowd: an adaptive crowdsourcing framework.

52.9222269615

====================
Deriving the pricing power of product features by mining consumer reviews.

52.8966195979

====================
Due to a small number of explanation functions, study participants found that repeatedly using the system began to provide redundant feedback; simplifying the development of more explanation functions may help the system produce more nuanced feedback.

52.8762796461

====================
Human-powered sorts and joins.

52.4848984897

====================
Figure 9: # of documents where quality >= thresh, for varying thresholds; product reviews (top), host profiles (bottom).

52.4656922347

====================
[91] S. E. Whang, J. McAuley, and H. Garcia-Molina.

52.4319398045

====================
[98] Y. Zheng, J. Wang, G. Li, R. Cheng, and J. Feng.

52.3733491052

====================
pi 6= 0 if fi is perturbed, otherwise pi = 0.

51.8804029122

====================
The Segmenter first splits each document into segments.

51.1390063932

====================
Social influence and the diffusion of user-created content.

50.8580232852

====================
Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model.

50.8165692776

====================
In HCI, 2016.

50.7715944378

====================
https://www.nfcworld.com/nfc-phones-list/, 2016.

50.7382371422

====================
In ITS, 2016.

50.5517349617

====================
[86] J. Tang, X. Hu, and H. Liu.

50.4560688044

====================
Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions.

50.4474145736

====================
In ACM SIGKDD workshop on human computation, 2010.

50.0741036783

====================
Finding high-quality content in social media.

49.8514973141

====================
]Rn  PF (d) = arg max I(d, p) s.t.

49.7618344413

====================
Packt Publishing Ltd, 2015.

49.6707472802

====================
The interface was the same for all conditions--only the feedback content changed.

49.5353022128

====================
Unanswered quora.

49.5061129847

====================
Linguistic analysis of chat transcripts from child predator undercover sex stings.

49.3601742633

====================
[65] H. Misra, F. Yvon, O. Cappe, and J. Jose.

49.1895168857

====================
[82] S. Siersdorfer, S. Chelaru, W. Nejdl, and J. San Pedro.

49.0943247352

====================
Social influence bias: A randomized experiment.

48.7044771937

====================
Check spelling and grammar in office 2010 and later.

48.662769273

====================
Rn is a vector that modifies a data point.

48.019406757

====================
Note that the quality criteria differ across domains.

47.7049768029

====================
In NAACL, 2015.

47.6160275913

====================
[22] P. K. Dick, S. Spielberg, T. Cruise, and S. Morton.

47.5362282655

====================
AngularJS web application development.

47.4461369873

====================
Existing feedback approaches are not directly applicable for Precog.

47.1705433268

====================
PVLDB, 2015.

47.0326952767

====================
Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission.

46.6975828782

====================
[5] E. Bakshy, B. Karrer, and L. A. Adamic.

46.3062819078

====================
[80] A. D. Sarma, A. G. Parameswaran, and J. Widom.

45.9877776931

====================
Sections 4 and 5 surveyed work related to text quality prediction and writing feedback.

45.9141925916

====================
Vader: A parsimonious rule-based model for sentiment analysis of social media text.

45.8628157689

====================
Figure 9 compares Precog against the baseline of not using Precog (naive review collection).

45.7567322286

====================
Note that the baseline does not acquire any high quality reviews when thresh >= 6.

45.6510932771

====================
Double data entry: what value, what price?

45.5678065373

====================
The institutionalization of youtube: From user-generated content to professionally generated content.

45.2355838828

====================
[85] C. Tan, V. Niculae, C. Danescu-Niculescu-Mizil, and L. Lee.

45.1320173955

====================
https://www.amazon.com/gp/help/customer/display.

45.0663618413

====================
81 completed the task.

44.8325516985

====================
Social computing and user-generated content: a game-theoretic approach.

44.5628340225

====================
Interacting with predictions: Visual inspection of black-box machine learning models.

44.3269688847

====================
The primary groups of features related to absence of detail and low topic diversity.

44.1786623099

====================
[55] J. Liu, Y. Cao, C.-Y.

43.9047583795

====================
CrowdFill: collecting structured data from the crowd.

43.8096074335

====================
[64] B. L. Minqing Hu.

43.7495459424

====================
Check spelling and grammar in google docs.

43.2019812895

====================
Rn where ~si = Snormdi , and matrix A [?]

43.1959577057

====================
Towards globally optimal crowdsourcing quality management: The uniform worker setting.

43.0219505743

====================
In TKDE, 2011.

42.5007521478

====================
[94] M. N. Xiao Ma, Trishala Neeraj.

42.3899334373

====================
62% had used AirBnb before.

42.330853111

====================
It has been extensively studied in recent years [9,12,24,29,39,80,98].

42.2097460788

====================
A. Kulik and C.-L. C. Kulik.

42.1338477911

====================
, Tt } is composed of a set of trees.

41.6290591563

====================
In reality, there is often a long tail of topics without sufficient content for such approaches to be effective [61, 79].

41.477241681

====================
In Advances in neural information processing systems, pages 121-128, 2008.

41.4187899724

====================
To do so, we draw a sample of text from the corpus that has been labeled as low quality.

41.1665999268

====================
Automated essay scoring with R v. 2.0.

41.1587380972

====================
Wisdom in the social crowd: an analysis of quora.

40.8891063088

====================
E * = topk Sed s.t.

40.7156102295

====================
Inferring networks of substitutable and complementary products.

40.5016173737

====================
Automated semantic grading of programs.

40.0186879302

====================
is assigned 1 as it might require multiple readings to understand.

39.9305957041

====================
Further, their analyses are per-feature and don't account for multi-feature interactions.

39.7502816481

====================
en.wikipedia.org/wiki/Wikipedia: Policies_and_guidelines, 2016.

39.5959537392

====================
[19] P. B. Darwin and P. Kozlowski.

39.4228193214

====================
Gene selection for cancer classification using support vector machines.

39.3160568651

====================
[50] M. Krause.

39.1342853315

====================
[76] M. T. Ribeiro, S. Singh, and C. Guestrin.

39.1178617401

====================
Both are important because they address different text quality factors.

38.1472689687

====================
We defer this to future work.

37.9527974219

====================
Justification narratives for individual classifications.

37.8071085381

====================
Overall, each explanation function was 3-20 lines of python code.

37.7374881117

====================
N, and a utility function U : N - R maps a label to a utility value.

37.6103901961

====================
[70] O. Nov. What motivates wikipedians?

37.4291807655

====================
She, Y. Tong, and L. Chen.

37.4236892694

====================
An efficient linear text segmentation algorithm using hierarchical agglomerative clustering.

37.3738201214

====================
Figure 8: # records satisfying both constraints vs budget.

37.2655764024

====================
[46] J. Kim.

37.1982841192

====================
In SIGMOD, 2011.

37.0609506047

====================
Survey methodology, volume 561.

36.9699045633

====================
[58] N. Madnani and A. Cahill.

36.8402940038

====================
QASCA: A quality-aware task assignment system for crowdsourcing applications.

36.6543415975

====================
For instance, a review that consists of many ambiguous phrases like "I have never done anything crazy with it and it still works."

36.4205616254

====================
Low-quality product review detection in opinion summarization.

36.2514997217

====================
Fix reviews' grammar, improve sales.

36.0842541067

====================
[34] C. H. E. Gilbert.

35.892103491

====================
Mining opinion features in customer reviews.

35.6063624849

====================
Textblob: Simplified text processing.

35.3844618798

====================
From game design elements to gamefulness: defining gamification.

35.3704252671

====================
a multi-method approach to determine the antecedents of online review helpfulness.

35.3319521644

====================
These ideas can be viewed as instances of Precog.

35.307715488

====================
Scale-driven automatic hint generation for coding style.

35.2387234429

====================
https://textblob.readthedocs.io/en/dev, 2014.

35.1129749261

====================
[72] H. Park and J. Widom.

34.7127583951

====================
[61] J. McAuley, R. Pandey, and J. Leskovec.

34.4591683029

====================
[67] S. M. Mudambi and D. Schuff.

34.3446375835

====================
The Annals of Applied Statistics, 2015.

34.339308755

====================
": Explaining the predictions of any classifier.

34.188026719

====================
[17] R. R. Choudhury, H. Yin, and A.

34.1640387922

====================
Compare me maybe: Crowd entity resolution interfaces.

34.049276793

====================
VLDB, 2015.

33.9589172844

====================
[7] O. Biran and K. McKeown.

33.7510326973

====================
No participant had used Precog before.

33.7421968095

====================
[26] A. Fedosejev.

33.298941292

====================
[84] N. Spirin and J. Han.

33.2037197507

====================
A critique and improvement of an evaluation metric for text segmentation.

32.9161634138

====================
Automating hint generation with solution space path construction.

32.8953163554

====================
[4] Y. Attali and J. Burstein.

32.8352523713

====================
http://www.imdb.com/title/tt0181689/, 2002.

32.6245323919

====================
Are both Segment and Explain necessary in the SegmentPredict-Explain pattern?

32.3735644801

====================
A model M : Rn - N classifies a data point as M (d) [?]

31.9053074206

====================
The nature of feedback: Investigating how different types of feedback affect writing performance.

31.6679905632

====================
[78] K. Rivers and K. R. Koedinger.

31.6283012984

====================
PVLDB, 2012.

31.5478912331

====================
Social recommender systems.

31.4643423004

====================
[89] S. Valenti, F. Neri, and R. Cucchiarelli.

31.3849771048

====================
a study of customer reviews on amazon.com.

31.3387730095

====================
Supersparse linear integer models for optimized medical scoring systems.

30.9285413066

====================
Technical report, Stanford InfoLab, 2012.

30.7791765364

====================
A survey of general-purpose crowdsourcing techniques.

30.691353331

====================
List of nfc phones.

30.3812342504

====================
[52] C. E. Kulkarni, M. S. Bernstein, and S. R. Klemmer.

30.1708058639

====================
Springer, 2015.

30.0544458688

====================
These can be integrated as feedback and interface customizations in Precog.

30.0451566942

====================
Packt Publ., 2013.

29.8803420923

====================
[83] R. Singh, S. Gulwani, and A. Solar-Lezama.

29.7596321565

====================
Wiley e-rater Online Library, 2004.

29.7087704043

====================
We start with the feature library of 47 features and no explanation functions.

29.6898027552

====================
For such cases, improving quality during user input process may be more effective.

29.5673927994

====================
In VLDB, 1994.

29.521476232

====================
In ETS Research Report Series.

29.4872952878

====================
In HCOMP, 2015.

29.481137223

====================
John Wiley & Sons, 2011.

29.4351624899

====================
7.2.1  Segment, Explain, or Both?

29.3972034681

====================
10  7.2.2  Ma et.

29.3568367433

====================
The document level feedback provides a global quality assessment.

29.2959489931

====================
In SIGMOD, 2014.

29.017315477

====================
Precog is more effective than no Precog when the desired quality is high.

28.7272146838

====================
Is it the review or the reviewer?

28.5570634832

====================
In Learning Research and Development Center, 2007.

28.5390744654

====================
INFORMS, 2011.

28.3873958646

====================
[20] S. Day, P. Fayers, and D. Harvey.

28.2729554626

====================
In KDD, 2012.

28.2273805127

====================
Linguistic obfuscation in fraudulent science.

28.0160234207

====================
Precog only marginally increases latency of each worker.

27.9197138775

====================
Controlled clinical trials, 19(1):15-24, 1998.

27.868585136

====================
Technical report, MIT, 2012.

27.7205926594

====================
6  data near the test point [76].

27.5071973161

====================
Lin, Y. Huang, and M. Zhou.

27.1953993423

====================
In NAACL, 2014.

27.0957432135

====================
Self-disclosure and perceived trustworthiness of airbnb host profiles.

27.0644324014

====================
American Association for the Advancement of Science, 2013.

27.0056976783

====================
In Machine learning.

26.7802765224

====================
Social recommendation: a review.

26.707772468

====================
[62] J. D. Mcauliffe and D. M. Blei.

25.971498883

====================
In SIGKDD, 2016.

25.9531948942

====================
Respondable: Personal ai assistant for writing better emails.

25.8299993207

====================
[33] A. Ghosh.

25.7360578394

====================
The development and psychometric properties of liwc2015.

25.6532302857

====================
yelp.com/guidelines, 2016.

25.6508095751

====================
]Ti I(d, q) >= I(d, q 0 ) [?]

25.4909714523

====================
Ti |[?

25.4909714523

====================
In UIST, 2011.

25.2762962033

====================
They also assume a large corpus that contains high quality content for every topic (e.g., product or question).

25.176148791

====================
[95] L. Yang and X. Amatriain.

25.117459727

====================
[12] C. C. Cao, J.

25.1123201102

====================
Sed > t e[?

24.7530564923

====================
In Journal of Information Technology Education, 2003.

24.5708117416

====================
Online survey design guide, 2003.

24.4713778446

====================
Text segmentation: A topic modeling perspective.

24.11087157

====================
Topictiling: a text segmentation algorithm based on lda.

24.0180539409

====================
In ACM SIGecom Exchanges.

23.7024492064

====================
[45] R. Kelly.

23.567980225

====================
In L@S, 2015.

23.2928731

====================
A computational approach to perceived trustworthiness of airbnb host profiles.

23.0733928557

====================
Elsevier, 2011.

23.070858062

====================
[74] L. Pevzner and M. A. Hearst.

23.0035951864

====================
Amazon: Community guidelines.

22.8965326565

====================
How much work does it take to add rich feedback support for text in a new domain?

22.8874079919

====================
Asking the right questions in crowd data sourcing.

22.8853746082

====================
Soylent: A word processor with a crowd inside.

22.8716735831

====================
rfk/pyenchant, Jan 2011.

22.7728089688

====================
can be similarly defined in multiple ways.

22.4819428837

====================
[88] B. Ustun and C. Rudin.

22.1524138732

====================
Building reputation in stackoverflow: an empirical investigation.

22.0769164206

====================
Deco: declarative crowdsourcing.

21.9845703356

====================
Timing of feedback and verbal learning.

21.6442156982

====================
In KDD, 2008.

21.6357067807

====================
Editor guidelines.

21.5666796063

====================
In WWW, 2013.

21.0632518929

====================
Content guidelines.

20.7975465188

====================
Quality evaluation of product reviews using an information quality framework.

20.7621243774

====================
In ICITS, 2014.

20.6963456957

====================
In CIS, 2011.

20.4702238758

====================
PF (d)  F[?

20.3750008032

====================
preprint maxiao.info, 2017.

19.9419333193

====================
[66] L. Muchnik, S. Aral, and S. J. Taylor.

19.87207019

====================
In SIGMOD, 2016.

19.3132549492

====================
[96] Yelp.

19.1158648735

====================
In ACL, 2012.

19.0574455554

====================
In ICDE, 2012.

19.0574455554

====================
American Psychological Association, 2002.

19.0368262682

====================
In MSR, 2013.

18.8880569245

====================
Fast algorithm for mining association rules.

18.8382063773

====================
In AutoML, 2014.

18.6649133732

====================
Latent dirichlet allocation.

18.6440290743

====================
Sage Publications, 2012.

18.5668226389

====================
[93] N. World.

18.5586258717

====================
In ICDE, 2013.

18.1808483046

====================
Minority report.

18.1613743275

====================
Let F be the set of n model features, and fi denote the ith feature.

18.1396097302

====================
[77] M. Riedl and C. Biemann.

17.7559092194

====================
[97] Zappos.

17.6546429054

====================
MIT Press, 1997.

16.7788055865

====================
In MIS quarterly, 2010.

16.7750757672

====================
In Recommender Systems Handbook.

16.6856796085

====================
In UIST, 2010.

16.4873978939

====================
Write smarter emails.

16.4065403825

====================
In WWW, 2010.

16.1591056278

====================
Springer, 2013.

15.9956296674

====================
In Management Science.

15.7455514539

====================
[75] R. S. Rakesh Agrawal.

15.7371280145

====================
ACM, 2012.

15.6682541138

====================
In CIKM, 2012.

15.5223002012

====================
In CSCW, 2017.

15.5054233308

====================
[79] G. Saito.

15.0638184746

====================
Thus, Precog segments documents at topic-level units.

14.7258480041

====================
Rm = A~s.

14.6298713275

====================
[68] M. Nelson and C. Schunn.

14.1256388192

====================
In EC, 2007.

13.564384112

====================
[27] FoxType.

13.2907634789

====================
](p) and the model's prediction confidence C(d + p) [?]

13.0323861521

====================
, dm } be the training dataset and Y = {y1 , .

12.9283902034

====================
[63] Microsoft.

12.6223589923

====================
MIT Press, 2002.

12.4294041792

====================
[56] S. Loria.

12.4265887481

====================
Technical report, 2015.

11.9953516142

====================
In Media, Culture & Society.

11.7722080629

====================
[92] Wikipedia.

11.6776938625

====================
The first one is how to split a document into segments.

11.090354889

====================
js Essentials.

10.9943364506

====================
The experiment was IRB approved.

10.9922851678

====================
In Communications of the ACM, 2007.

10.868339851

====================
In WWW, 2016.

10.6660441845

====================
VLDB, 2011.

10.6660441845

====================
The discount function [?]

10.4189723057

====================
In JMLR, 2003.

10.4024430037

====================
In EC, 2009.

10.268547246

====================
In EMNLP-CoNLL, 2007.

9.89161737997

====================
RELATED WORK  9.

9.76749599332

====================
support.office.com, 2016.

9.74361218457

====================
In WSDM, 2008.

9.48410098909

====================
In AAAI, 2004.

9.47239689679

====================
[37] I.

9.22276289197

====================
What makes a helpful review?

9.12869638294

====================
In ACL, 2006.

8.88225288489

====================
In Decision Support Systems.

8.86163359769

====================
Get another label?

8.70781355102

====================
Also, let ~e [?]

8.67317077287

====================
For instance, consider [?

8.31776616672

====================
Let ~s [?]

8.26975694753

====================
Guy.

7.89915348334

====================
[35] Google.

7.84776253747

====================
In Information Processing & Management.

7.69848278788

====================
Springer, 2002.

7.69028602068

====================
To the best of our 12  10.

7.16703787691

====================
Machine Learning, 2016.

7.16703787691

====================
Let D = {d1 , .

6.46146817635

====================
]q0 [?

6.43775164974

====================
[10] Boomerang.

6.18826412308

====================
In SNAM.

6.18826412308

====================
React.

6.18826412308

====================
In MindTrek, 2011.

6.18826412308

====================
In RecSys, 2016.

6.18826412308

====================
Whom to ask?

6.18826412308

====================
13  [51] J.

5.66296048014

====================
, ym } be their labels.

4.80402104473

====================
Supervised topic models.

4.40671924726

====================
Fox.

3.80666248977

====================
Figure 5: Precog architecture.

3.21887582487

====================
4.

3.04452243772

====================
3.

2.30258509299

====================
In Science.

2.07944154168

====================
2  2.

1.94591014906

====================
IEEE, 2011.

1.09861228867

====================
[24] J.

1.09861228867

====================
"why should I trust you?

0.0

====================
U (M (d + p)) - U (M (d)) x C(d + p) [?

0.0

====================
7  [?

0.0

====================
8.

0.0

====================
for host profiles.

0.0

====================
[2] Amazon.

0.0

====================
14

0.0

====================
", or 0 if the document did not change.

0.0

====================
F to feedback text.

0.0

====================
6.

0.0

====================
]fi [?

0.0

====================
.

0.0

====================
]M q j [?

0.0

====================
5.

0.0

====================
[0, 1].

0.0

====================
]F / (pi = 0) p[?

0.0

====================
[?

0.0

To this end, we present Precog1 , a crowdsourced data acquisition system that supports pre-hoc quality control for both simple data types and multi-paragraph text attributes. We further show that Precog's unique approach to combining prescriptive explanations and segment-level feedback improves text quality by 14.3%, and over 3x better than a state-of-the-art feedback system [50]. To build high-quality models, we survey and categorize features from the writing analysis literature into 5 categories  1. user input  2. segment by topic  3. estimate quality  4. targeted feedback  Figure 3: The Segment-Predict-Explain pattern: Precog splits user input into coherent segments; estimates the quality of each segment and the text as a whole; and generates and shows suggested improvements to the user. In addition to evaluating Precog for hard constraints and simple data types, we evaluate Precog's text feedback through extensive MTurk experiments on two real application domains--product reviews and rental host profiles. In this paper, we argue for pre-hoc quality control systems. The fourth FEF for product reviews was mapped to Subjectivity features in (Table 1) and the fourth host profiles FEF was mapped to Friendliness LIWC features shown in [94], with each returning text suggesting that the user improves the respective facet of their submission (i.e., "Please make your writing more balanced and neutral"). Our experiments and prior work [52] show that this is less effective than a more customized approach. Experimental Conditions: The purpose of experiments is to both show the Cost Saving benefits of Precog as well as to evaluate the effectiveness of it's two main features (segment-level feedback and TCruise explanation generation). NEW APPLICATION DOMAINS  EXPERIMENTS  We now evaluate how Precog improves high-quality data acquisition using live Mechanical Turk deployments. Precog, which is complementary to post-hoc quality control techniques, collects >= 2x high-quality documents for the same budget as no feedback, and improves text quality by 14.3% on average.
